<?xml version="1.0"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook45-profile.xsl"
                 type="text/xml"
                 title="Profiling step"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<book lang="en" id="rnotes">
 <bookinfo>
  <title>Release Notes for SUSE Linux Enterprise Server 11 SP4 <phrase os="s4v">for VMware</phrase></title>
  <releaseinfo>@VERSION@</releaseinfo>
  <date><?dbtimestamp format="Y-m-d"?></date>
  <abstract>
<!-- <para><emphasis>Product to be released: Q3 CY 2015</emphasis></para> -->
<!-- msvec and marketing, 2013-05-13 -->
<!-- new initial para -->
   <para>
    This document provides guidance and an overview to high level general
    features and updates for SUSE Linux Enterprise Server 11 Service
    Pack 4 (SP4). Besides architecture or product-specific information, it
    also describes the capabilities and limitations of SLES 11 SP4. General
    documentation may be found at:
    <ulink url="https://documentation.suse.com/sles/11-SP4/"/>.
   </para>

   <para os="s4v">
    This product is version of SUSE Linux Enterprise Server tailored for
    VMware. Features related to Xen and KVM virtualization cannot be used in
    VMware environments and are therefore not part of the delivery.
   </para>
   <para os="s4v">
    To not affect the consistency of the release notes these are the same as
    the regular SUSE Linux Enterprise Server. They may contain information
    regarding the features mentioned above. Such information does not apply
    to SUSE Linux Enterprise Server 11 SP4 for VMware.
   </para>
  </abstract>
 </bookinfo>
 <chapter id="rnotes-source-code">
  <title>How to Obtain Source Code</title>
<!-- msvec and legal (ciaran), 2013-05-13 -->
<!-- moved from the abstract to this location as the first chapter -->
  <para>
   This SUSE product includes materials licensed to SUSE under the GNU
   General Public License (GPL). The GPL requires SUSE to provide the source
   code that corresponds to the GPL-licensed material. The source code is
   available for download at
   <ulink url="https://www.suse.com/download-linux/source-code.html"/>. Also,
   for up to three years after distribution of the SUSE product, upon
   request, SUSE will mail a copy of the source code. Requests should be
   sent by e-mail to <ulink url="mailto:sle_source_request@suse.com"/> or as
   otherwise instructed at
   <ulink url="https://www.suse.com/download-linux/source-code.html"/>. SUSE
   may charge a reasonable fee to recover distribution costs.
  </para>
 </chapter>
 <chapter id="rnotes-purpose">
  <title>SUSE Linux Enterprise Server</title>
<!-- Marketing, Kerry Kim, 2009-02-09 -->
<!-- Changed by MgE, 2012-02-02 -->
<!-- Feedback by Robert, 2012-02-27 -->
  <para>
   SUSE Linux Enterprise Server is a highly reliable, scalable, and secure
   server operating system, built to power mission-critical workloads in
   both physical and virtual environments. It is an affordable,
   interoperable, and manageable open source foundation. With it,
   enterprises can cost-effectively deliver core business services, enable
   secure networks, and simplify the management of their heterogeneous IT
   infrastructure, maximizing efficiency and value.
  </para>
  <para>
   The only enterprise Linux recommended by Microsoft and SAP, SUSE Linux
   Enterprise Server is optimized to deliver high-performance
   mission-critical services, as well as edge of network, and web
   infrastructure workloads.
  </para>
  <para>
   Designed for interoperability, SUSE Linux Enterprise Server integrates
   into classical Unix as well as Windows environments, supports open
   standard CIM interfaces for systems management, and has been certified
   for IPv6 compatibility,
  </para>
  <para>
   This modular, general purpose operating system runs on five processor
   architectures and is available with optional extensions that provide
   advanced capabilities for tasks such as real time computing and high
   availability clustering.
  </para>
  <para>
   SUSE Linux Enterprise Server is optimized to run as a high performing
   guest on leading hypervisors and supports an unlimited number of virtual
   machines per physical system with a single subscription, making it the
   perfect guest operating system for virtual computing.
  </para>
  <para>
   SUSE Linux Enterprise Server is backed by award-winning support from
   SUSE, an established technology leader with a proven history of
   delivering enterprise-quality support services.
  </para>
<!-- bnc#821338 -->
<!-- bnc#828478 -->
  <para>
   With the release of SUSE Linux Enterprise Server 11 Service Pack 4 the
   former SUSE Linux Enterprise Server 11 Service Pack 3 enters the 6
   month migration window, during which time SUSE will continue to provide
   security updates and full support and maintenance. At the end of the
   six-month parallel support period, on 2016-01-31, general support for
   SUSE Linux Enterprise Server 11 Service Pack 3 will be discontinued.
   Long Term Service Pack Support (LTSS) for SUSE Linux Enterprise
   Server 11 Service Pack 3 is available as a separate add-on.
  </para>
 </chapter>
 <chapter id="mustread">
<!-- FATE#312947 -->
  <title>Important Upgrade Information</title>
  <section>
   <title>What's New in SUSE Linux Enterprise Server 11 SP4</title>
   <itemizedlist>
    <listitem>
     <para>
      New CPU enablement, such as Intel® Xeon® processor E7-8800/4800 v3
      product family, IBM z13™ (z13), and IBM POWER8 BE.
     </para>
    </listitem>
    <listitem>
     <para>
      Public Cloud module and Security module are now available for SP4.
      These modules are independent repository channels and are included in
      subscription without additional cost:
     </para>
     <variablelist>
      <varlistentry>
       <term>Public Cloud Module</term>
       <listitem>
        <para>
         The Public Cloud Module is a collection of tools that enables you
         to create and manage cloud images from the command line on SUSE
         Linux Enterprise Server. When building your own images with KIWI or
         SUSE Studio, initialization code specific to the target cloud is
         included in that image. The tools and initialization code in this
         module will be updated whenever a new version is ready, always
         giving you the freshest.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>Security Module</term>
       <listitem>
        <para>
         The Security Module adds support for TLS 1.2 to the applications in
         the Security Module repository. This allows customers and partners
         to build TLS-1.2 compliant infrastructures beyond the HTTPS
         protocol.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </listitem>
   </itemizedlist>
  </section>
  <section>
   <title>Upgrade Information</title>
   <para>
    For users upgrading from a previous SUSE Linux Enterprise Server release
    it is recommended to review:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <xref linkend="Support"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="Update"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <xref linkend="TechInfo"/>
     </para>
    </listitem>
   </itemizedlist>
<!-- msvec and marketing, 2013-05-13 -->
<!-- moved from the abstract to this location -->
   <para>
    Installation Quick Start and Deployment Guides can be found in the
    <filename>docu</filename> language directories on the media.
    Documentation (if installed) is available below the
    <filename>/usr/share/doc/</filename> directory of an installed system.
   </para>
   <para>
    These Release Notes are identical across all architectures, and the most
    recent version is always available online at
    <ulink url="https://www.suse.com/releasenotes/"/>. Some entries are
    listed twice, if they are important and belong to more than one section.
   </para>
  </section>
 </chapter>
 <chapter id="Support">
  <title>Support Statement for SUSE Linux Enterprise Server</title>
  <para>
   To receive support, customers need an appropriate subscription with SUSE.
   For more information, see
   <ulink url="https://www.suse.com/support/"/>.
  </para>
  <section id="Support.General" remap="Support:General">
   <title>General Support Statement</title>
   <para>
    The following definitions apply:
   </para>
   <variablelist>
<!-- Now using http://support.novell.com/products/server/supported_packages/ -->
    <varlistentry>
     <term>L1</term>
     <listitem>
      <para>
       Problem determination, which means technical support designed to
       provide compatibility information, usage support, on-going
       maintenance, information gathering and basic troubleshooting using
       available documentation.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>L2</term>
     <listitem>
      <para>
       Problem isolation, which means technical support designed to analyze
       data, duplicate customer problems, isolate problem area and provide
       resolution for problems not resolved by Level 1 or alternatively
       prepare for Level 3.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>L3</term>
     <listitem>
      <para>
       Problem resolution, which means technical support designed to resolve
       problems by engaging engineering to resolve product defects which
       have been identified by Level 2 Support.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <para>
    For contracted customers and partners, SUSE Linux Enterprise Server 11
    will be delivered with L3 support for all packages, except the
    following:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      technology previews
     </para>
    </listitem>
    <listitem>
     <para>
      sound, graphics, fonts and artwork
     </para>
    </listitem>
    <listitem>
     <para>
      packages that require an additional customer contract
     </para>
    </listitem>
    <listitem>
     <para>
      packages provided as part of the Software Development Kit (SDK)
     </para>
    </listitem>
   </itemizedlist>
   <para>
    SUSE will only support the usage of original (e.g., unchanged or
    un-recompiled) packages.
   </para>
<!-- taken from SP2 doc; was id="fate-306585" -->
<!-- bnc#732564 -->
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-314687" remap="Support:General">
<!-- sort_key="None"; non-rn-fate-cats="Services and Support"; -->
<!-- href="https://fate.novell.com/314687" -->
    <title>Supportconfig Includes dmidecode Output</title>
    <para>
     On the i586 and x86_64 platforms, the supportconfig tool now includes
     the output of <literal>dmidecode</literal>.
    </para>
    <para>
     On the System z and POWER platforms, <literal>dmidecode</literal> is
     not shipped, so supportconfig does not include its output.
    </para>
   </section>
   <section role="notoc" id="fate-314463" remap="Support:General">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization"; -->
<!-- href="https://fate.novell.com/314463" -->
    <title>lxc-attach Is Not Supported on SLES 11 (Any Service Pack)</title>
    <para>
     <literal>lxc-attach</literal> is not functional and not supported under
     SLES 11 (any Service Pack).
    </para>
    <para>
     <literal>lxc-attach</literal> is looking for
     <literal>/proc/[0-9]+/ns/{pid|mnt}</literal> which have only been
     available since Linux kernel 3.8. However, SLES 11 uses Linux kernel
     3.0.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>Support for the btrfs File System</title>
    <para>
     <emphasis>Btrfs is a copy-on-write (CoW) general purpose file system.
     Based on the CoW functionality, btrfs provides snapshotting. Beyond
     that data and metadata checksums improve the reliability of the file
     system. btrfs is highly scalable, but also supports online shrinking to
     adopt to real-life environments. On appropriate storage devices btrfs
     also supports the TRIM command.</emphasis>
    </para>
    <para>
     <emphasis>Support</emphasis>
    </para>
    <para>
     With SUSE Linux Enterprise 11 SP2, the btrfs file system joins ext3,
     reiserfs, xfs and ocfs2 as commercially supported file systems. Each
     file system offers distinct advantages. While the installation default
     is ext3, we recommend xfs when maximizing data performance is desired,
     and btrfs as a root file system when snapshotting and rollback
     capabilities are required. Btrfs is supported as a root file system
     (i.e. the file system for the operating system) across all
     architectures of SUSE Linux Enterprise 11 SP2. Customers are advised to
     use the YaST partitioner (or AutoYaST) to build their systems: YaST
     will prepare the btrfs file system for use with subvolumes and
     snapshots. Snapshots will be automatically enabled for the root file
     system using SUSE's snapper infrastructure. For more information about
     snapper, its integration into ZYpp and YaST, and the YaST snapper
     module, see the SUSE Linux Enterprise documentation.
    </para>
    <para>
     <emphasis>Migration from "ext" File Systems to btrfs</emphasis>
    </para>
    <para>
     Migration from existing "ext" file systems (ext2, ext3, ext4) is
     supported "offline" and "in place". Calling "btrfs-convert [device]"
     will convert the file system. This is an offline process, which needs
     at least 15% free space on the device, but is applied in place. Roll
     back: calling "btrfs-convert -r [device]" will roll back. Caveat: when
     rolling back, all data will be lost that has been added after the
     conversion into btrfs; in other words: the roll back is complete, not
     partial.
    </para>
    <para>
     <emphasis>RAID</emphasis>
    </para>
    <para>
     Btrfs is supported on top of MD (multiple devices) and DM (device
     mapper) configurations. Please use the YaST partitioner to achieve a
     proper setup. Multivolume/RAID with btrfs is not supported yet and will
     be enabled with a future maintenance update.
    </para>
    <para>
     <emphasis>Future Plans</emphasis>
    </para>
    <itemizedlist>
     <listitem>
      <para>
       We are planning to announce support for btrfs' built-in multi volume
       handling and RAID in a later version of SUSE Linux Enterprise.
      </para>
     </listitem>
     <listitem>
      <para>
       Starting with SUSE Linux Enterprise 12, we are planning to implement
       bootloader support for /boot on btrfs.
      </para>
     </listitem>
     <listitem>
      <para>
       Compression and Encryption functionality for btrfs is currently under
       development and will be supported once the development has matured.
      </para>
     </listitem>
     <listitem>
      <para>
       We are committed to actively work on the btrfs file system with the
       community, and we keep customers and partners informed about progress
       and experience in terms of scalability and performance. This may also
       apply to cloud and cloud storage infrastructures.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     <emphasis>Online Check and Repair Functionality</emphasis>
    </para>
    <para>
     Check and repair functionality ("scrub") is available as part of the
     btrfs command line tools. "Scrub" is aimed to verify data and metadata
     assuming the tree structures are fine. "Scrub" can (and should) be run
     periodically on a mounted file system: it runs as a background process
     during normal operation.
    </para>
<!-- bnc#861869 -->
    <para>
     The "fsck.btrfs" tool is available in the SUSE Linux Enterprise update
     repositories.
    </para>
    <para>
     <emphasis>Capacity Planning</emphasis>
    </para>
    <para>
     If you are planning to use btrfs with its snapshot capability, it is
     advisable to reserve twice as much disk space than the standard storage
     proposal. This is automatically done by the YaST2 partitioner for the
     root file system.
    </para>
    <para>
     <emphasis>Hard Link Limitation</emphasis>
    </para>
    <para>
     In order to provide a more robust file system, btrfs incorporates back
     references for all file names, eliminating the classic "lost+found"
     directory added during recovery. A temporary limitation of this
     approach affects the number of hard links in a single directory that
     link to the same file. The limitation is dynamic based on the length of
     the file names used. A realistic average is approximately 150 hard
     links. When using 255 character file names, the limit is 14 links. We
     intend to raise the limitation to a more usable limit of 65535 links in
     a future maintenance update.
    </para>
    <note>
<!-- bnc#732564 -->
     <para>
      With SLE 11 SP3 you can now raise this limitation. The so-called
      <quote>extended inode refs</quote> are not turned on by default in the
      SUSE kernels. This is because enabling them involves turning on an
      incompat bit in the file system which would make it unmountable by old
      versions of SLE.
     </para>
     <para>
      If you want extended inode refs on though use 'btrfstune' to turn them
      on. There is no way to turn them off so it is a 1-way conversion. The
      command is (replace /PATH/TO/DEVICE with your device):
     </para>
<screen>btrfstune -r /PATH/TO/DEVICE</screen>
    </note>
    <para>
     <emphasis>Other Limitations</emphasis>
    </para>
    <para>
     At the moment, btrfs is not supported as a seed device.
    </para>
    <para>
     <emphasis>For More Information</emphasis>
    </para>
    <para>
     For more information about btrfs, see the SUSE Linux Enterprise 11
     documentation.
    </para>
   </section>
   <section>
<!-- fate#312717 c3-->
    <title>Tomcat6 and Related Packages</title>
    <para>
     Tomcat6 and related packages are fully supported on the Intel/AMD x86
     (32bit), AMD64/Intel64, IBM POWER, and IBM System z architectures.
    </para>
   </section>
   <section>
    <title>SELinux</title>
    <para>
     The SELinux subsystem is supported. Arbitrary SELinux policies running
     on SLES are not supported, though. Customers and Partners who have an
     interest in using SELinux in their solutions, are encouraged to contact
     SUSE to evaluate the level of support that is needed, and how support
     and services for the specific SELinux policies will be granted.
    </para>
   </section>
  </section>
  <section id="Support.Software" remap="Support:Software">
   <title>Software Requiring Specific Contracts</title>
   <para>
    The following packages require additional support contracts to be
    obtained by the customer in order to receive full support:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      BEA Java (Itanium only)
     </para>
    </listitem>
    <listitem>
     <para>
      MySQL Database
     </para>
    </listitem>
    <listitem>
     <para>
      PostgreSQL Database
     </para>
    </listitem>
<!-- bnc#836418 -->
<!-- WebSphere CE Application Server -->
   </itemizedlist>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-314834" remap="Support:Software">
<!-- sort_key="None"; non-rn-fate-cats="High Performance Computing"; -->
<!-- href="https://fate.novell.com/314834" -->
    <title>openMPI Support</title>
    <para>
     <literal>openMPI</literal> is used in HPC as a standard for
     communication. It is now supported in SLE 11 SP4.
    </para>
    <para>
     The libraries are now in a separate RPM package (<literal>openmpi-libs</literal>). The library name has been changed
     from <literal>libmpi.so.0</literal> to <literal>libmpi.so.1</literal>.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="Support.TechPreviews" remap="Support:TechPreviews">
   <title>Technology Previews</title>
<!-- bnc#662712 -->
   <para>
    Technology previews are packages, stacks, or features delivered by SUSE.
    These features are not supported. They may be functionally incomplete,
    unstable or in other ways not suitable for production use. They are
    mainly included for customer convenience and give customers a chance to
    test new technologies within an enterprise environment.
   </para>
   <para>
    Whether a technical preview will be moved to a fully supported package
    later, depends on customer and market feedback. A technical preview does
    not automatically result in support at a later point in time. Technical
    previews could be dropped at any time and SUSE is not committed to
    provide a technical preview later in the product cycle.
   </para>
   <para>
    Please, give your SUSE representative feedback, including your
    experience and use case.
   </para>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-323709" remap="Support:TechPreviews">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/323709" -->
    <title>XEN: Support for xl/libxl and libvirt/libxl toolstacks</title>
    <para>
     The upstream Xen community has deprecated the aging xm/xend toolstack
     and replaced it with xl/libxl. SUSE will maintain the xm/xend toolstack
     for the life of SUSE Linux Enterprise 11, but will switch to the
     xl/libxl toolstack in SLE 12. Although there has been much effort to
     ensure compatibility between the toolstacks, some domain configuration
     formats and management commands may not be identical. For example, in
     the xl/libxl toolstack, the SXP configuration format is deprecated and
     receives no active development.
    </para>
    <para>
     To ensure a smooth transition to xl/libxl in SLE 12, SUSE provides the
     toolstack in SLE 11 as a technology preview. A libvirt libxl driver is
     also provided as technology preview. It can be enabled by stopping xend
     and restarting libvirtd.
    </para>
   </section>
   <section role="notoc" id="fate-319064" remap="Support:TechPreviews">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319064" -->
    <title>Support for the z Systems 10GbE RoCE Express</title>
    <para>
     Support for the z Systems 10GbE RoCE Express feature can be used on
     zEC12, zBC12, z13 via the TCP/IP layer without restrictions. SLES 11
     SP4 includes RDMA enablement and DAPL/OFED for IBM z Systems as a
     technology preview but these can only be used on LPAR when running on
     IBM z Systems zEC12, zBC12 and cannot be used on IBM z Systems z13.
    </para>
   </section>
   <section role="notoc" id="fate-317450" remap="Support:TechPreviews">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization,Xen Virtual Machine Monitor"; -->
<!-- href="https://fate.novell.com/317450" -->
    <title>XEN: VMCS Shadowing support for Xen</title>
    <para>
     VMCS Shadowing is a VT-x feature that allows software in VMX non-root
     operation to execute the VMREAD and VMWRITE instructions. Such
     executions do not read from the current VMCS (the one supporting VMX
     non-root operation) but instead from a shadow VMCS. This feature
     improve nested virtualization performance.
    </para>
   </section>
   <section role="notoc" id="fate-316660" remap="Support:TechPreviews">
<!-- sort_key="None"; non-rn-fate-cats="Interoperability,Virtualization"; -->
<!-- href="https://fate.novell.com/316660" -->
    <title>Libvirt: VMware vpx and esx drivers</title>
    <para>
     Libvirt will now be shipped with the VMware ESX hypervisor driver,
     allowing limited management of ESX hosts and vCenter environments. See
     <ulink url="https://libvirt.org/drvesx.html">https://libvirt.org/drvesx.html</ulink>
     for more details.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>Technology Preview: Hot-Add Memory</title>
<!-- bnc#877693 -->
    <para>
     Hot-add memory is currently only supported on the following hardware:
    </para>
    <itemizedlist>
<!-- bnc#810756 -->
<!-- bnc#819950 -->
     <listitem>
      <para>
       IBM x3800, x3850, single node x3950, x3850 M2, single node x3950 M2,
      </para>
     </listitem>
<!-- FATE#304276: RAS features for x86_64: Memory hot-add, IOH hot-add -->
     <listitem>
      <para>
       certified systems based on recent Intel Xeon Architecture,
      </para>
     </listitem>
<!-- FATE#304275: RAS features for IPF: Memory hotadd, IOH offline/hot-remove, IOH online/hot-add -->
     <listitem>
      <para>
       certified systems based on recent Intel IPF Architecture,
      </para>
     </listitem>
<!-- bnc#600361 mge@novell.com, 20100508 -->
<!-- bnc#810575 ke@suse.com, 20130321    -->
     <listitem>
      <para>
       all IBM servers and blades with POWER5, POWER6, POWER7, or POWER7+
       processors and recent firmware. (This requires the Power Linux
       service and productivity tools available at
       <ulink url="https://www14.software.ibm.com/webapp/set2/sas/f/lopdiags/yum.html"/>.)
      </para>
     </listitem>
    </itemizedlist>
    <para>
     If your specific machine is not listed, please call SUSE support to
     confirm whether or not your machine has been successfully tested. Also,
     regularly check our maintenance update information, which will
     explicitly mention the general availability of this feature.
    </para>
    <para>
     Restriction on using IBM eHCA InfiniBand adapters in conjunction with
     hot-add memory on IBM Power:
    </para>
    <para>
     The current eHCA Device Driver will prevent dynamic memory operations
     on a partition as long as the driver is loaded. If the driver is
     unloaded prior to the operation and then loaded again afterwards,
     adapter initialization may fail. A Partition Shutdown / Activate
     sequence on the HMC may be needed to recover from this situation.
    </para>
   </section>
   <section>
    <title>Technology Preview: Internet Storage Naming Service (iSNS)</title>
    <para>
     The Internet Storage Naming Service (iSNS) package is by design
     suitable for secure internal networks only. SUSE will continue to work
     with the community on improving security.
    </para>
   </section>
<!-- see fate-311111 -->
<!--
  <listitem>
    <para>Ext4 Filesystem</para>
    <para>
      The Ext4 kernel modules and userland tools
      shipped with &sles; 11 are a preview of a new filesystem for Linux.
    </para>
  </listitem>
  -->
<!-- bnc#441079 -->
<!-- see fate-311333 -->
<!--
  <listitem>
    <para>biosdevname</para>
    <para>
      biosdevname in its simplest form takes a kernel name as
      an argument and returns the BIOS-given name it "should"
      be. This is necessary on systems where the BIOS name for
      a given device (e.g., the label on the chassis is "Gb1")
      doesn't map directly and obviously to the kernel name
      (e.g., eth0).
    </para>
  </listitem>
  -->
<!-- FATE XXX/agruen -->
<!-- bnc#652349 -->
   <section>
    <title>Technology Preview: Read-Only Root File System</title>
    <para>
     It is possible to run SUSE Linux Enterprise Server 11 on a shared
     read-only root file system. A read-only root setup consists of the
     read-only root file system, a scratch and a state file system. The
     <filename>/etc/rwtab</filename> file defines which files and
     directories on the read-only root file system are replaced by which
     files on the state and scratch file systems for each system instance.
    </para>
    <para>
     The <filename>readonlyroot</filename> kernel command line option
     enables read-only root mode; the <filename>state=</filename> and
     <filename>scratch=</filename> kernel command line options determine the
     devices on which the state and scratch file systems are located.
    </para>
    <para>
     In order to set up a system with a read-only root file system, set up a
     scratch file system, set up a file system to use for storing persistent
     per-instance state,
     <remark>emap: Is this correct? Should the dash be deleted or the space?</remark>
     <remark>ke: I'd say, the space is superfluous.  Fixed.</remark>
     adjust <filename>/etc/rwtab</filename> as needed, add the appropriate
     kernel command line options to your boot loader configuration, replace
     <filename>/etc/mtab</filename> with a symlink to
     <filename>/proc/mounts</filename> as described below, and (re)boot the
     system.
    </para>
    <remark>emap: Confusing paragraph. Should be broken into steps like
below (where it's not really necessary.</remark>
    <remark>ke: I'd say, as an overview it is probably ok--at least, for the
moment.</remark>
    <para>
     To replace <filename>/etc/mtab</filename> with the appropriate
     symlinks, call:
    </para>
<screen>ln -sf /proc/mounts /etc/mtab</screen>
    <para>
     See the rwtab(5) manual page for further details and
     <ulink url="https://www.redbooks.ibm.com/abstracts/redp4322.html"/> for
     limitations on System z.
    </para>
   </section>
  </section>
 </chapter>
 <chapter id="Installation" remap="Installation">
  <title>Installation</title>
  <para/>
<!--v Items below imported from FATE-->
  <section role="notoc" id="fate-319239" remap="Installation">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319239" -->
   <title>Installing the open-fcoe Package Manually</title>
   <para>
    Manually installing the open-fcoe package on a system without FCoE cards
    can disrupt the boot process.
   </para>
   <para>
    Install open-fcoe only if your system has FCoE cards (in which case the
    installer would install it for you automatically).
   </para>
   <para>
    An upcoming maintenance update will address this issue in the open-fcoe
    package.
   </para>
  </section>
  <section role="notoc" id="fate-319097" remap="Installation">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319097" -->
   <title>Detecting FCoE Storage During Installation or Booting</title>
   <para>
    An FCoE storage device is not detected or not properly coming up during
    installation or booting.
   </para>
   <para>
    If an FCoE storage device is not detected or not properly coming up
    during installation or booting, it is recommended to add the following
    parameter to the kernel boot parameters.
   </para>
<screen>with_fcoe=1</screen>
  </section>
  <section role="notoc" id="fate-319076" remap="Installation">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319076" -->
   <title>Standard Installation with DHCPv4 and DHCPv6</title>
   <para>
    If you configure both DHCPv4 and DHCPv6 during the second stage of a
    standard installation, only DHCPv4 is enabled when calling 'rcnetwork
    restart'.
   </para>
   <para>
    Make sure that the "dhcp-client" package is installed. Then call
    'rcnetwork restart' again.
   </para>
  </section>
  <section role="notoc" id="fate-319050" remap="Installation">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319050" -->
   <title>Top Level Domain ".site" No Longer Available for Private Use</title>
   <para>
    Until SLE 11 SP4, when no hostname was provided by the user or DHCP, the
    installer was generating a hostname ending with <literal>.site</literal>. Since 2015, the top level domain (tld) ".site" is officially
    registered and should no longer be used for private purposes.
   </para>
   <para>
    We recommend to rename the system using a proper fully qualified
    resolvable domain name. If impossible, use <literal>.test</literal> (or
    <literal>.invalid</literal>) as the domain name instead of
    <literal>.site</literal> (for more information, see RFC 6761). A new
    installation done with the SLE 11 SP4 installer will default to
    "linux.suse" instead of "linux.site", when none is provided.
   </para>
  </section>
  <section role="notoc" id="fate-319031" remap="Installation">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319031" -->
   <title>Running SMT on SLES 11 SP4</title>
   <para>
    SMT 11 SP3 can run on top of SLES 11 SP4. In order to make it possible,
    it is necessary to install the latest maintenance updates of SMT 11 SP3.
    This needs to be done before SLES is updated from version 11 SP3 to
    version 11 SP4. After the update of SLES, SMT keeps running as-is.
   </para>
   <para>
    In order to install SMT 11 SP3 on top of SLES 11 SP4, use the latest
    media available from
    <ulink url="https://download.suse.com/index.jsp">download.suse.com</ulink>.
   </para>
  </section>
  <section role="notoc" id="fate-319000" remap="Installation">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319000" -->
   <title>Booting i586 Machines</title>
   <para>
    The provided ISO image is able to boot i586 machines if burnt on a DVD
    medium. It does not work to dump it on a USB device and use it for
    booting.
   </para>
   <para>
    The x86_64 architecture is not affected by this limitation. On x86_64
    booting from a USB device is supported.
   </para>
  </section>
  <section role="notoc" id="fate-314681" remap="Installation">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/314681" -->
   <title>AutoYaST Installation and Multipath</title>
   <para>
    During AutoYaST installations, it is now possible to enable multipath.
   </para>
  </section>
<!--^ End of Items imported from FATE-->
  <section id="Installation.Deployment">
   <title>Deployment</title>
   <remark>emap: hope the ids I make up are okay.</remark>
   <remark>ke: In the long run, we probably must add them to fate, too.  jw will work it out eventually :)</remark>
   <para>
    SUSE Linux Enterprise Server can be deployed in three ways:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Physical Machine,
     </para>
    </listitem>
    <listitem>
     <para>
      Virtual Host,
     </para>
    </listitem>
    <listitem>
     <para>
      Virtual Machine in paravirtualized environments.
     </para>
    </listitem>
   </itemizedlist>
  </section>
  <section id="Installation.CJK">
   <title>CJK Languages Support in Text-mode Installation</title>
   <para>
    CJK (Chinese, Japanese, and Korean) languages do not work properly
    during text-mode installation if the framebuffer is not used (Text Mode
    selected in boot loader).
   </para>
   <para>
    There are three alternatives to resolve this issue:
   </para>
   <orderedlist>
    <listitem>
     <para>
      Use English or some other non-CJK language for installation then
      switch to the CJK language later on a running system using
      <menuchoice> <guimenu>YaST</guimenu> <guimenu>System</guimenu>
      <guimenu>Language</guimenu> </menuchoice>.
     </para>
    </listitem>
    <listitem>
     <para>
      Use your CJK language during installation, but do not choose
      <guimenu>Text Mode</guimenu> in the boot loader using <guimenu>F3
      Video Mode</guimenu>. Select one of the other VGA modes instead.
      Select the CJK language of your choice using <guimenu>F2
      Language</guimenu>, add <command>textmode=1</command> to the boot
      loader command-line and start the installation.
     </para>
    </listitem>
    <listitem>
     <para>
      Use graphical installation (or install remotely via SSH or VNC).
     </para>
    </listitem>
   </orderedlist>
  </section>
  <section id="Installation.BootGrub2TB">
<!-- bnc#719429 -->
   <title>Booting from Hard Disks larger than 2 TiB in Non-UEFI Mode</title>
   <para>
    Booting from hard disks larger than 2 TiB in non-UEFI mode (but with GPT
    partition table) fails.
   </para>
   <para>
    To successfully use hard disks larger than 2 TiB in non-UEFI mode, but
    with GPT partition table (i.e., grub bootloader), consider one of the
    following options:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Use a 4k sector hard disk in 4k mode (in this case, the 2 TiB limit
      will become a 16 TiB limit).
     </para>
    </listitem>
    <listitem>
     <para>
      Use a separate <filename>/boot</filename> partition. This partition
      must be one of the first 3 partitions and end below the 2 TiB limit.
     </para>
    </listitem>
    <listitem>
     <para>
      Switch from legacy mode to UEFI mode, if this is an option for you.
     </para>
    </listitem>
   </itemizedlist>
  </section>
  <section id="Installation.PerstDevNames">
   <title>Installation Using Persistent Device Names</title>
   <para>
    The installer uses persistent device names by default. If you plan to
    add storage devices to your system after the installation, we strongly
    recommend you use persistent device names for all storage devices.
   </para>
<!-- bnc#732999 -->
   <para>
    To switch to persistent device names on a system that has already been
    installed, start the YaST2 partitioner. For each partition, select
    <guimenu>Edit</guimenu> and go to the <guimenu>Fstab Options</guimenu>
    dialog. Any mount option except <guimenu>Device name</guimenu> provides
    you persistent device names. In addition, rerun the Boot Loader module
    in YaST and select <guimenu>Propose New Config</guimenu> to switch the
    boot loader to using the persistent device name, or manually adjust all
    boot loader sections. Then select <guimenu>Finish</guimenu> to write the
    new proposed configuration to disk. Alternatively, edit
    <filename>/boot/grub/menu.lst</filename> and
    <filename>/boot/grub/device.map</filename> according to your needs.
   </para>
   <para>
    This needs to be done before adding new storage devices.
   </para>
<!-- Old entry:
     To switch to persistent device names on a system that has already
     been installed, start the YaST2 partitioner. For each partition,
     select <guimenu>Edit</guimenu> and go to the <guimenu>Fstab
     Options</guimenu> dialog. Any mount option except <command>Device
     name</command> provides you persistent device names. In addition,
     rerun the boot loader module in YaST to switch the bootloader to
     using the persistent device name. Start the module <guimenu>Boot
     Loader</guimenu> and select <guilabel>Finish</guilabel> to write
     the new proposed configuration to disk. This needs to be done
     before adding new storage devices.
     -->
<!-- Do not refer opensuse.org -->
   <para>
    For further information, see the <quote>Storage Administration
    Guide</quote> about "Device Name Persistence".
   </para>
  </section>
<!-- bnc#746579 -->
  <section>
   <title>iSCSI Booting with iBFT in UEFI Mode</title>
   <para>
    If booting over iSCSI, iBFT information cannot be parsed when booting
    via native UEFI. The system should be configured to boot in legacy mode
    if iSCSI booting using iBFT is required.
   </para>
  </section>
<!-- relnotes.i.withiscsi -->
<!-- bnc#818162; SLES 11 SP3 -->
  <section id="Installation.iSCSI">
   <title>Using iSCSI Disks when Installing</title>
   <para>
    To use iSCSI disks during installation, passing the
    <literal>withiscsi</literal> boot parameter is no longer needed.
   </para>
   <para>
    During installation, an additional screen provides the option to attach
    iSCSI disks to the system and use them in the installation process.
   </para>
   <para>
    Booting from an iSCSI server on i386, x86_64 and ppc64 is supported if
    iSCSI-enabled firmware is used.
   </para>
<!-- bnc#594957 mge@novell.com 20100508
                   2011-11-08 ke: remove now superfluous note -->
  </section>
<!-- relnotes.i.qla_xxx -->
<!-- bnc#745201 -->
  <section id="Installation.qla">
   <title>Using qla3xxx and qla4xxx Drivers at the Same Time</title>
   <para>
    QLogic iSCSI Expansion Card for IBM BladeCenter provides both Ethernet
    and iSCSI functions. Some parts on the card are shared by both
    functions. The current qla3xxx (Ethernet) and qla4xxx (iSCSI) drivers
    support Ethernet and iSCSI function individually. In contrast to
    previous SLES releases, using both functions at the same time is now
    supported.
   </para>
   <para>
    If you happen to use <literal>brokenmodules=qla3xxx</literal> or
    <literal>brokenmodules=qla4xxx</literal> before upgrading to SLES 11
    SP2, these options can be removed.
   </para>
  </section>
<!-- relnotes.i.use_edd -->
  <section id="Installation.EDD">
   <title>Using EDD Information for Storage Device Identification</title>
   <para>
    EDD information (in
    <filename>/sys/firmware/edd/&lt;device&gt;</filename>) is used by
    default to identify your storage devices.
   </para>
   <para>
    EDD Requirements:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      BIOS provides full EDD information (found in
      <filename>/sys/firmware/edd/&lt;device&gt;</filename>)
     </para>
    </listitem>
    <listitem>
     <para>
      Disks are signed with a unique MBR signature (found in
      <filename>/sys/firmware/edd/&lt;device&gt;/mbr_signature</filename>).
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Add <literal>edd=off</literal> to the kernel parameters to disable EDD.
   </para>
  </section>
<!-- relnotes.i.autoinstall -->
  <section id="Installation.autoyast">
   <title>Automatic Installation with AutoYaST in an LPAR (System z)</title>
   <para>
    For automatic installation with AutoYaST in an LPAR, the
    <filename>parmfile</filename> used for such an installation must have
    blank characters at the beginning and at the end of each line (the first
    line does not need to start with a blank). The number of characters in
    one line should not exceed 80.
   </para>
  </section>
<!-- relnotes.i.dasd -->
  <section id="Installation.Systemz">
   <title>Adding DASD or zFCP Disks During Installation (System z)</title>
   <para>
    Adding of DASD or zFCP disks is not only possible during the
    installation workflow, but also when the installation proposal is shown.
    To add disks at this stage, please click on the
    <guimenu>Expert</guimenu> tab and scroll down. There the DASD and/or
    zFCP entry is shown. These added disks are not displayed in the
    partitioner automatically. To make the disks visible in the partitioner,
    you have to click on <guimenu>Expert</guimenu> and select
    <guimenu>reread partition table</guimenu>. This may reset any previously
    entered information.
   </para>
  </section>
<!-- bnc#448547 -->
  <section id="Installation.Network">
   <title>Network Installation via eHEA on POWER</title>
   <para>
    If you want to carry out a network installation via the IBM eHEA
    Ethernet Adapter on POWER systems, no huge (16GB) pages may be assigned
    to the partition during installation.
   </para>
  </section>
  <section>
   <title>For More Information</title>
   <para>
    For more information, see <xref linkend="InfraPackArch"/>.
   </para>
  </section>
 </chapter>
 <chapter id="Features">
  <title>Features and Versions</title>
  <section id="Features.Kernel" remap="Features:Kernel">
   <title>Linux Kernel and Toolchain</title>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-321400" remap="Features:Kernel">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/321400" -->
    <title>AMD Zen Support</title>
    <para>
     Minimal support for the upcoming AMD Zen architecture is available.
    </para>
   </section>
   <section role="notoc" id="fate-317598" remap="Features:Kernel">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317598" -->
    <title>qeth: Display Switch Port Mode</title>
    <para>
     A new <literal>sysfs</literal> attribute allows to display the port
     mode settings of an adjacent switch, for example to see if it is set
     for hairpin mode
    </para>
   </section>
   <section role="notoc" id="fate-317134" remap="Features:Kernel">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317134" -->
    <title>New Kernel Taint Flag - Unsigned Module</title>
    <para>
     In the past modules without proper cryptographic signature loaded into
     kernel caused the kernel's "forced module load" flag to be set. As a
     result, tracing was disabled for such modules.
    </para>
    <para>
     A flag has been introduced to indicate modules with invalid signature.
     Its internal kernel name is TAINT_UNSIGNED_MODULE, and is represented
     with letter 'E' in kernel debugging output.
    </para>
   </section>
   <section role="notoc" id="fate-316109" remap="Features:Kernel">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316109" -->
    <title>Enabling VEBOX on Haswell in the drm/i915 Kernel Driver</title>
    <para>
     Linux Cloud Video Transcode is an Intel GEN based hardware solution to
     support high quality and performance video transcoding on a server.
     With enabling VEBOX on Haswell for some video pre and post process
     features like DN/ADI SUSE Linux Enterprise features improved transcode
     quality.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>General Version Information</title>
<!-- see bnc#804971 -->
    <itemizedlist>
     <listitem>
      <para>
       GCC 4.3.4
      </para>
     </listitem>
     <listitem>
      <para>
       glibc 2.11.3
      </para>
     </listitem>
     <listitem>
      <para>
       Linux kernel 3.0
      </para>
     </listitem>
     <listitem>
      <para>
       perl 5.10
      </para>
     </listitem>
     <listitem>
<!-- bnc#760930 -->
<!-- bnc#804971 php 5.3 only on SP3-->
      <para>
       php 5.3
      </para>
     </listitem>
     <listitem>
<!-- 2015-06-10, behlert: via mail -->
      <para>
       python 2.6.9
      </para>
     </listitem>
     <listitem>
      <para>
       ruby 1.8.7
      </para>
     </listitem>
    </itemizedlist>
   </section>
   <section>
<!-- bnc#754267 -->
    <title>SUSE Linux Enterprise Real Time Extension</title>
    <para>
     To take advantage of the Real Time extension the extension must be at
     the same version as the base SUSE Linux Enterprise Server. An updated
     version for SUSE Linux Enterprise Real Time extension is provided later
     after the release of SUSE Linux Enterprise Server.
    </para>
   </section>
  </section>
  <section id="Features.Server" remap="Features:Server">
   <title>Server</title>
   <note>
    <para>
     Note: in the following text version numbers do not necessarily give the
     final patch- and security-status of an application, as SUSE may have
     added additional patches to the specific version of an application.
    </para>
   </note>
   <para>
    <remark>emap 2011-10-27: Proper Note markup?</remark>
    <remark>ke 2011-11-03: good enough for these simple document.
        Unknown, whether the all displaying tools (yast) support fancier
        markup (probably yes).</remark>
   </para>
   <remark>Versions will be mentioned via FATE:
        Apache: FATE#311973: virtual hosting: provide several SSL based domains on one IP address through Server Name Indication(SNI)
        Bind: FATE#308859: Upgrade BIND to long term supported version 9.6
        Samba: FATE#311645: Samba server version update
        </remark>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-318266" remap="Features:Server">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318266" -->
    <title>numactl and libnuma</title>
    <para>
     numactl and libnuma have been updated to the latest version.
    </para>
    <para>
     This update comes with many bug fixes and some new features that are
     especially important for large NUMA systems, e.g.:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       IO affinity support
      </para>
     </listitem>
     <listitem>
      <para>
       New option to memhog to disable transparent huge pages
      </para>
     </listitem>
     <listitem>
      <para>
       Show distances on machines without a node 0
      </para>
     </listitem>
    </itemizedlist>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="Features.Desktop" remap="Features:Desktop">
   <title>Desktop</title>
   <itemizedlist>
    <listitem>
<!-- bnc#804973 -->
     <para>
      GNOME 2.28
     </para>
     <para>
      GNOME was updated with SP2 and uses PulseAudio for sound.
     </para>
    </listitem>
    <listitem>
<!-- bnc#804973 -->
     <para>
      KDE 4.3.5
     </para>
     <para>
      KDE was updated with SP2.
     </para>
    </listitem>
    <listitem>
     <para>
      X.org 7.4
     </para>
    </listitem>
   </itemizedlist>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-318975" remap="Features:Desktop">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318975" -->
    <title>fbdev Driver Needs Reboot After Resolution Changes</title>
    <para>
     SaX2 offers to change the resolution even for the fbdev driver. Because
     this is controlled via a VGA kernel option, rebooting is needed after
     resolution changes. In other words: Modifications will take effect the
     next time the graphics system is restarted; in some cases a reboot of
     the machine is needed.
    </para>
   </section>
   <section role="notoc" id="fate-316713" remap="Features:Desktop">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316713" -->
    <title>GNOME: Primary Monitor for the Greeter</title>
    <para>
     With GNOME designating the primary monitor for the greeter now is
     possible.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="Features.Security" remap="Features:Security">
   <title>Security</title>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-317168" remap="Features:Security">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317168" -->
    <title>chpasswd with Support for SHA256 and SHA512</title>
    <para>
     Various parts of the password checking frameworks in PAM and pwdutils
     already had support for SHA256 and SHA512 based password hashing
     functions.
    </para>
    <para>
     Support was missing in chpasswd, a program usable for scripting
     password setting.
    </para>
    <para>
     <literal>chpasswd</literal> was made able to also set SHA256 and SHA512
     based passwords.
    </para>
   </section>
   <section role="notoc" id="fate-316939" remap="Features:Security">
<!-- sort_key="None"; non-rn-fate-cats="Security"; -->
<!-- href="https://fate.novell.com/316939" -->
    <title>openSSH update to 6.6p1</title>
    <para>
     OpenSSH is constantly improving and gaining new and more secure cipher
     suites. Backporting them is occasionally not possible.
    </para>
    <para>
     OpenSSH has been updated to version 6.6p1, same version as used in SUSE
     Linux Enterprise 12.
    </para>
    <para>
     The ciphers now includes modern elliptic curve based on the elliptic
     curve Curve25519, resulting in public key types Ed25519.
    </para>
    <para>
     Also the new transport cipher "chacha20-poly1305@openssh.com" was
     added, using the ChaCha20 stream cipher and Poly1305 MAC developed by
     Dan Bernstein.
    </para>
    <para>
     Various other improvements and bugfixes are also included.
    </para>
    <para>
     Please note that this openssh version is not FIPS 140-2 validated,
     although it contains FIPS 140-2 related improvements from SUSE Linux
     Enterprise 12. In a system operating in FIPS mode, you will need to
     install the openssh-fips package.
    </para>
   </section>
   <section role="notoc" id="fate-316552" remap="Features:Security">
<!-- sort_key="None"; non-rn-fate-cats="Security"; -->
<!-- href="https://fate.novell.com/316552" -->
    <title>Switch repomd from sha to sha26</title>
    <para>
     The update repository integrity used by SUSE is ensured by a GPG
     signature and the checksums of the YUM repomd XML metadata.
    </para>
    <para>
     SUSE Linux Enterprise 11 so far used sha1 as intermediate checksum,
     which should no longer be used.
    </para>
    <para>
     With SUSE Linux Enterprise 12 and SUSE Linux Enterprise 11 SP4 we start
     to use sha256 for the XML integrity handling and so get rid of the old
     sha1 hashing methods.
    </para>
    <para>
     If you have tools parsing the XML metadata yourself, please verify they
     can handle also the newer sha256 hashes.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>PAM Configuration</title>
    <para>
     The common PAM configuration files
     (<filename>/etc/pam.d/common-*</filename>) are now created and managed
     with <command>pam-config</command>.
    </para>
   </section>
   <section>
<!-- bnc#734148: waiting for feedback -->
    <title>SELinux Enablement</title>
    <para>
     In addition to AppArmor, SELinux capabilities have been added to SUSE
     Linux Enterprise Server. While these capabilities are not enabled by
     default, customers can run SELinux with SUSE Linux Enterprise Server if
     they choose to.
    </para>
    <para>
     What does SELinux enablement mean?
    </para>
    <itemizedlist>
     <listitem>
      <para>
       The kernel ships with SELinux support.
      </para>
     </listitem>
     <listitem>
      <para>
       We will apply SELinux patches to all “common” userland packages.
      </para>
     </listitem>
     <listitem>
      <para>
       The libraries required for SELinux
       (<systemitem class="resource">libselinux, libsepol,
       libsemanage</systemitem>, etc.) have been added to openSUSE and SUSE
       Linux Enterprise.
      </para>
     </listitem>
     <listitem>
      <para>
       Quality Assurance is performed with SELinux disabled—to make sure
       that SELinux patches do not break the default delivery and the
       majority of packages.
      </para>
     </listitem>
     <listitem>
      <para>
       The SELinux specific tools are shipped as part of the default
       distribution delivery.
      </para>
     </listitem>
     <listitem>
      <para>
       Arbitrary SELinux policies running on SLES are not supported, though,
       and we will not be shipping any SELinux policies in the distribution.
       Reference and minimal policies may be available from the repositories
       at some future point.
      </para>
     </listitem>
     <listitem>
      <para>
       Customers and Partners who have an interest in using SELinux in their
       solutions, are encouraged to contact SUSE to evaluate the level of
       support that is needed, and how support and services for the specific
       SELinux policies will be granted.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     By enabling SELinux in our code base, we add community code to offer
     customers the option to use SELinux without replacing significant parts
     of the distribution.
    </para>
   </section>
   <section>
    <title>Enablement for TPM/Trusted Computing</title>
    <para>
     SUSE Linux Enterprise Server 11 comes with support for Trusted
     Computing technology. To enable your system's TPM chip, make sure that
     the "security chip" option in your BIOS is selected. TPM support is
     entirely passive, meaning that measurements are being performed, but no
     action is taken based on any TPM-related activity. TPM chips
     manufactured by Infineon, NSC and Atmel are supported, in addition to
     the virtual TPM device for Xen.
    </para>
    <para>
     The corresponding kernel drivers are not loaded automatically. To do
     so, enter:
    </para>
<screen>find /lib/modules -type f -name "tpm*.ko"</screen>
    <para>
     and load the kernel modules for your system manually or via
     <command>MODULES_LOADED_ON_BOOT</command> in
     <filename>/etc/sysconfig/kernel</filename>.
    </para>
    <para>
     If your TPM chip with taken ownership is configured in Linux and
     available for use, you may read PCRs from
     <filename>/sys/devices/*/*/pcrs</filename>.
    </para>
    <para>
     The <systemitem class="resource">tpm-tools</systemitem> package
     contains utilities to administer your TPM chip, and the
     <systemitem class="resource">trousers</systemitem> package provides
     <systemitem class="daemon">tcsd</systemitem>—the daemon that allows
     userland programs to communicate with the TPM driver in the Linux
     kernel. <systemitem class="daemon">tcsd</systemitem> can be enabled as
     a service for the runlevels of your choice.
    </para>
    <para>
     To implement a trusted ("measured") boot path, use the package
     <systemitem class="resource">trustedgrub</systemitem> instead of the
     <systemitem class="resource">grub</systemitem> package as your
     bootloader. The trustedgrub bootloader does not display any graphical
     representation of a boot menu for informational reasons.
    </para>
   </section>
   <section>
    <title>Linux File System Capabilities</title>
    <para>
     Our kernel is compiled with support for Linux File System Capabilities.
     This is disabled by default. The feature can be enabled by adding
     <option>file_caps=1</option> as kernel boot option.
    </para>
   </section>
  </section>
  <section id="Features.Network" remap="Features:Network">
   <title>Network</title>
   <variablelist>
    <varlistentry>
     <term>
     IPv6 Improvements
   </term>
     <listitem>
      <para>
       SUSE Linux Enterprise Server has successfully completed the USGv6
       test program designated by NIST that provides a proof of compliance
       to IPv6 specifications outlined in current industry standards for
       common network products.
      </para>
      <para>
       Being IPv6 Consortium Member and Contributor Novell/SUSE have worked
       successfully with University of New Hampshire InterOperability
       Laboratory (UNH-IOL) to verify compliance to IPv6 specifications. The
       UNH-IOL offers ISO/IEC 17025 accredited testing designed specifically
       for the USGv6 test program. The devices that have successfully
       completed the USGv6 testing at the UNH-IOL by December 2012 are SUSE
       Linux Enterprise Server 11 SP2. Testing for subsequent releases of
       SUSE Linux Enterprise Server is in progress, and current and future
       results will be listed at
       <ulink url="https://www.iol.unh.edu/services/testing/ipv6/usgv6tested.php?company=105&amp;type=#eqplist"/>.
      </para>
      <para>
       SUSE Linux Enterprise Server can be installed in an IPv6 environment
       and run IPv6 applications. When installing via network, do not forget
       to boot with "<literal>ipv6=1</literal>" (accept v4 and v6) or
       "<literal>ipv6only=1</literal>" (only v6) on the kernel command line.
       For more information, see the Deployment Guide and also
       <xref linkend="TechInfo.IPv6"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>
     10G Networking Capabilities
   </term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>
     OFED 1.5
   </term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>
    traceroute 1.2
   </term>
     <listitem>
      <para>
       Support for traceroute over TCP.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>
    FCoE
   </term>
     <listitem>
      <para>
       FCoE is an implementation of the Fibre Channel over Ethernet working
       draft. Fibre Channel over Ethernet is the encapsulation of Fibre
       Channel frames in Ethernet packets. It allows users with a FCF (Fibre
       Channel over Ethernet Forwarder) to access their existing Fibre
       Channel storage using an Ethernet adapter. When leveraging DCB's PFC
       technology to provide a loss-less environment, FCoE can run SAN and
       LAN traffic over the same link.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>
    Data Center Bridging (DCB)
   </term>
     <listitem>
      <para>
       Data Center Bridging (DCB) is a collection of Ethernet enhancements
       designed to allow network traffic with differing requirements (e.g.,
       highly reliable, no drops vs. best effort vs. low latency) to operate
       and coexist on Ethernet. Current DCB features are:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         <emphasis>Enhanced Transmission Selection</emphasis> (aka
         <emphasis>Priority Grouping</emphasis>) to provide a framework for
         assigning bandwidth guarantees to traffic classes.
        </para>
       </listitem>
       <listitem>
        <para>
         <emphasis>Priority-based Flow Control (PFC)</emphasis> provides a
         flow control mechanism which can work independently for each 802.1p
         priority.
        </para>
       </listitem>
       <listitem>
        <para>
         <emphasis>Congestion Notification</emphasis> provides a mechanism
         for end-to-end congestion control for protocols, which do not have
         built-in congestion management.
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </varlistentry>
   </variablelist>
   <section role="notoc" id="jsc-SLE-11183">
    <title>New GeoIP Database Sources</title>
    <para>
     The GeoIP databases allows approximately geo-locating users by their IP
     address.
     In the past, the company MaxMind made such data available for free in
     its GeoLite Legacy databases.
     On January 2, 2019, MaxMind discontinued the GeoLite Legacy databases,
     now offering only the newer GeoLite2 databases for download.
     To comply with new data protection regulation, since December 30, 2019,
     GeoLite2 database users are required to comply with an additional usage
     license.
     This change means users now need to register for a MaxMind account and
     obtain a license key to download GeoLite2 databases.
     For more information about these changes, see the
     <ulink url="https://blog.maxmind.com/2019/12/18/significant-changes-to-accessing-and-using-geolite2-databases/">MaxMind blog</ulink>.
    </para>
    <para>
     SLES includes the <package>GeoIP</package> package of tools that are
     only compatible with GeoLite Legacy databases.
     As an update for SLES 12 SP2, we introduce the following new
     packages to deal with the changes to the GeoLite service:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       <command>geoipupdate</command>:
       The official Maxmind tool for downloading GeoLite2 databases.
       To use this tool, set up the configuration file with your MaxMind
       account details.
       This configuration file can also be generated on the Maxmind web page.
       For more information, see
       <ulink url="https://dev.maxmind.com/geoip/geoip2/geolite2/"/>.
      </para>
     </listitem>
     <listitem>
      <para>
       <command>geolite2legacy</command>:
       A script for converting GeoLite2 CSV data to the GeoLite Legacy format.
      </para>
     </listitem>
     <listitem>
      <para>
       <command>geoipupdate-legacy</command>:
       A convenience script that downloads GeoLite2 data, converts it to the
       GeoLite Legacy format, and stores it in <filename>/var/lib/GeoIP</filename>.
       With this script, applications developed for use with the legacy
       <command>geoip-fetch</command> tool will continue to work.
      </para>
     </listitem>
    </itemizedlist>
   </section>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-316723" remap="Features:Network">
<!-- sort_key="None"; non-rn-fate-cats="Storage and Partitioning"; -->
<!-- href="https://fate.novell.com/316723" -->
    <title>iSCSI Booting Using HBA Mode</title>
    <para>
     SLES 11 SP4 now allows iSCSI booting from some adapters using HBA mode,
     even if the boot target is on a different subnetwork. It does this by
     gathering and using three new iBFT boot parameters:
     <literal>boot_root</literal>, <literal>boot_nic</literal>, and
     <literal>boot_target</literal>. The kernel as well as
     <literal>open-iscsi</literal> was changed to provide this feature.
    </para>
   </section>
   <section role="notoc" id="fate-316279" remap="Features:Network">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316279" -->
    <title>sshd: ipv6 configuration and X11 Forwarding</title>
    <para>
     If ipv6 is disabled sshd automatically starts with the
     <literal>-4</literal> option. This way enabling X11 forwarding is
     possible.
    </para>
   </section>
   <section role="notoc" id="fate-316140" remap="Features:Network">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316140" -->
    <title>Linuxrc: Option for AutoYaST to Define a vlan 802.1q</title>
    <para>
     Linuxrc now writes <literal>VLanID: XXX</literal> to
     <literal>install.inf</literal>, but only if a vlan ID was set.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="Features.ResourceManagement">
   <title>Resource Management</title>
   <para/>
<!-- bnc#771384 -->
   <section id="features.resmgmt">
    <title>LXC Requires Correct Network Configuration</title>
    <para>
     LXC now comes with support for network gateway detection. This feature
     will prevent a container from starting, if the network configuration
     setup of the container is incorrect. For instance, you must make sure
     that the network address of the container is within the host ip range,
     if it was set up as bridged on host. You might need to specify the
     netmask of the container network address (using the syntax
     "<literal>lxc.network.ipv4 = X.Y.Z.T / cidr</literal>") if the netmask
     is not the network class default netmask).
    </para>
    <para>
     When using DHCP to assign a container network address, ensure
     "<literal>lxc.network.ipv4 = 0.0.0.0</literal>" is used in your
     configuration template.
    </para>
    <para>
     Previously a container would have been started but the network would
     not have been working properly. Now a container will refuse to start,
     and print an error message stating that the gateway could not be set
     up. For containers created before this update we recommend running
     <literal>rcnetwork restart</literal> to reestablish a container network
     connection.
    </para>
    <tip>
     <title>LXC Maintenance Update</title>
     <para>
      After installing LXC maintenance update, we recommend clearing the LXC
      SLES cache template (stored by default in
      <filename>/var/cache/lxc/sles/rootfs-*</filename>) to ensure changes
      in the SLES template are available in newly created containers.
     </para>
     <para>
      For containers created before the update, we recommend to install the
      packages "supportconfig", "sysconfig", and "iputils" using zypper.
     </para>
    </tip>
   </section>
  </section>
  <section id="Features.SystemManagement" remap="Features:SystemManagement">
   <title>Systems Management</title>
   <variablelist>
    <varlistentry>
     <term>
    Improved Update Stack
   </term>
     <listitem>
      <para>
       SUSE Linux Enterprise Server 11 provides an improved update stack and
       the new command line tool <command>zypper</command> to manage the
       repositories and install or update packages.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>
    Enhanced YaST Partitioner
   </term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>
    Extended Built-in Management Infrastructure
   </term>
     <listitem>
      <para>
       SUSE Linux Enterprise Server provides CIM/WBEM enablement with the
       SFCB CIMOM.
      </para>
      <para>
<!-- According to http://old-en.opensuse.org/SystemsManagement/CIM/Providers : -->
       The following CIM providers are available:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         cmpi-pywbem-base
        </para>
       </listitem>
       <listitem>
        <para>
         cmpi-pywbem-power-management (DSP1027)
        </para>
       </listitem>
       <listitem>
        <para>
         cmpi-pywbem-software (DSP1023)
        </para>
       </listitem>
       <listitem>
        <para>
         libvirt-cim (DSP1041, DSP1043, DSP1045, DSP1057, DSP1059, DSP1076,
         DSP1081)
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-base
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-dhcp
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-ethport_profile (DSP1014)
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-fsvol
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-network
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-nfsv3
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-nfsv4
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-sysfs
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-gather-provider
        </para>
       </listitem>
       <listitem>
        <para>
         smis-providers
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-dns
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-samba
        </para>
       </listitem>
       <listitem>
        <para>
         sblim-cmpi-smbios
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </varlistentry>
    <varlistentry>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c26 -->
     <term>
    Support for Web Services for Management (WS Management)
   </term>
     <listitem>
      <para>
       The WS-Management protocol is supported via Openwsman, providing
       client (package: openwsman-client) and server (package:
       openwsman-server) implementations.
      </para>
      <para>
       This allows for interoperable management with the Windows 'winrm'
       stack.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-317874" remap="Features:SystemManagement">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317874" -->
    <title>YaST iSCSI Client Keeps Startup Mode of Connected Targets</title>
    <para>
     There was no possibility to keep the startup mode ('automatic',
     'manual' or 'on boot') of already connected targets. Using either
     'Discovery' on 'Discovered Targets' or 'Add' of the 'Connected Targets'
     dialog used to reset the startup mode to the default mode 'manual'.
    </para>
    <para>
     Now it is possible when using the <literal>Add</literal> button of the
     <literal>Connected Targets</literal> dialog to detect additional
     targets. Then the startup mode of already connected targets will not
     change.
    </para>
   </section>
   <section role="notoc" id="fate-317650" remap="Features:SystemManagement">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317650" -->
    <title>IPMI Update</title>
    <para>
     IPMI tools have been updated to version 1.8.15 to support newer
     hardware.
    </para>
   </section>
   <section role="notoc" id="fate-316893" remap="Features:SystemManagement">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316893" -->
    <title>snmpd Improvements</title>
    <para>
     snmpd has been enhanced to allow the monitoring of
     <literal>tmpfs</literal> file systems with SUSE Linux Enterprise 11
     SP4.
    </para>
   </section>
   <section role="notoc" id="fate-316889" remap="Features:SystemManagement">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316889" -->
    <title>Tomcat: Support for renaming JSESSIONID</title>
    <para>
     When Tomcat is used together with other application servers the
     JSESSIONID session cookie can be over-written be each other.
    </para>
    <para>
     The solution is to allow the JSESSIONID to be renamed. This is possible
     with <literal>Tomcat 6.0.19</literal> and higher.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="Features.Other" remap="Features:Other">
   <title>Other</title>
   <variablelist>
    <varlistentry>
     <term>EVMS2 Replaced with LVM2</term>
     <listitem>
<!-- bnc#733037-->
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Default File System</term>
     <listitem>
      <para>
       With SUSE Linux Enterprise Server 11, the default file system in new
       installations has been changed from ReiserFS to ext3.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>UEFI Enablement on AMD64/Intel64</term>
     <listitem>
<!-- bnc#578927 c16 -->
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>SWAP over NFS</term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
<!-- bnc#662725 -->
     <term>Linux Foundation's Carrier Grade Linux (CGL)</term>
     <listitem>
      <para>
       SUSE supports the Linux Foundation's Carrier Grade Linux (CGL)
       specification. SUSE Linux Enterprise 11 meets the latest CGL 4.0
       standard, and is CGL-registered.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
<!-- bnc#658264 -->
<!-- bnc#867969 -->
     <term>Hot-Add Memory and CPU with vSphere 4.1 or Newer</term>
     <listitem>
      <para>
       Hot-add memory and CPU is supported and tested for both 32-bit and
       64-bit systems when running vSphere 4.1 or newer. For more
       information, see the VMware Compatibility Guide at
       <ulink url="https://www.vmware.com/resources/compatibility/search.php?deviceCategory=software&amp;partner=465&amp;virtualHardware=23"/>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-316976" remap="Features:Other">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316976" -->
    <title>/etc/os-release</title>
    <para>
     In addition to the <literal>/etc/SuSE-release</literal> file the file
     <literal>/etc/os-release</literal> is now available.
    </para>
    <para>
     <literal>/etc/os-release</literal> is a cross-distribution standard to
     identify a Linux system. For more information about the syntax, see the
     os-release man page (<literal>man os-release</literal>).
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
 </chapter>
 <chapter id="Drivers">
  <title>Driver Updates</title>
  <section id="Drivers.Network" remap="Drivers:Network">
   <title>Network Drivers</title>
   <itemizedlist>
<!-- FATE #XXX -->
    <listitem>
     <para>
      Updated bnx driver to version 2.0.4
     </para>
    </listitem>
<!-- FATE #XXX -->
    <listitem>
     <para>
      Updated bnx2x driver to version 1.52.1-7
     </para>
    </listitem>
<!-- FATE #XXX -->
    <listitem>
     <para>
      Updated e100 driver to version 3.5.24-k2
     </para>
    </listitem>
<!-- FATE #307117 -->
    <listitem>
     <para>
      Updated tg3 driver to version 3.106
     </para>
    </listitem>
<!-- FATE #XXX -->
    <listitem>
     <para>
      Added bna driver for Brocade 10Gbit LAN card in version 2.1.2.1
     </para>
    </listitem>
<!-- bnc#561881 -->
    <listitem>
     <para>
      Updated bfa driver to version 2.1.2.1
     </para>
    </listitem>
<!-- FATE #XXX -->
    <listitem>
     <para>
      Updated qla3xxx driver to version 2.03.00-k5
     </para>
    </listitem>
<!-- FATE #XXX -->
    <listitem>
     <para>
      Updated sky2 driver to version 1.25
     </para>
    </listitem>
   </itemizedlist>
<!-- bnc#744652 -->
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-318440" remap="Drivers:Network">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318440" -->
    <title>Network Modules</title>
    <para>
     The following modules got updated (selection):
     <itemizedlist>
      <listitem>
       <para>
        ixgbe - 3.19.1-k
       </para>
      </listitem>
      <listitem>
       <para>
        ixgbevf - 2.12.1-k
       </para>
      </listitem>
      <listitem>
       <para>
        igb - 5.2.15-k
       </para>
      </listitem>
      <listitem>
       <para>
        i40evf - 1.0.5
       </para>
      </listitem>
      <listitem>
       <para>
        e1000e - 2.3.2-k
       </para>
      </listitem>
      <listitem>
       <para>
        e1000 - 7.3.21-k8-NAPI
       </para>
      </listitem>
      <listitem>
       <para>
        e100 - 3.5.24-k2-NAPI
       </para>
      </listitem>
      <listitem>
       <para>
        i40e - 1.0.11-k
       </para>
      </listitem>
      <listitem>
       <para>
        igbvf - 2.0.2-k
       </para>
      </listitem>
      <listitem>
       <para>
        tg3 - 3.137
       </para>
      </listitem>
      <listitem>
       <para>
        cnic - 2.5.20
       </para>
      </listitem>
      <listitem>
       <para>
        bnx2 - 2.2.5
       </para>
      </listitem>
      <listitem>
       <para>
        bnx2i - 2.7.10.1
       </para>
      </listitem>
      <listitem>
       <para>
        bnx2fc - 2.8.1
       </para>
      </listitem>
      <listitem>
       <para>
        qla2xxx - 8.07.00.18-k
       </para>
      </listitem>
      <listitem>
       <para>
        qla4xxx - 5.03.00.00.11.4-k0
       </para>
      </listitem>
      <listitem>
       <para>
        qlcnic - 5.3.62
       </para>
      </listitem>
      <listitem>
       <para>
        qlge - 1.00.00.34
       </para>
      </listitem>
      <listitem>
       <para>
        netxen_nic - 4.0.82
       </para>
      </listitem>
      <listitem>
       <para>
        cxgb4 - 2.0.0-ko
       </para>
      </listitem>
      <listitem>
       <para>
        cxgb3 - 1.1.5-ko
       </para>
      </listitem>
      <listitem>
       <para>
        cxgb4i - 0.9.1
       </para>
      </listitem>
      <listitem>
       <para>
        cxgb3i - 2.0.0
       </para>
      </listitem>
      <listitem>
       <para>
        cxgb4 - 2.0.0-ko
       </para>
      </listitem>
      <listitem>
       <para>
        cxgb3 - 1.1.5-ko
       </para>
      </listitem>
     </itemizedlist>
    </para>
   </section>
   <section role="notoc" id="fate-317367" remap="Drivers:Network">
<!-- sort_key="None"; non-rn-fate-cats="Infiniband"; -->
<!-- href="https://fate.novell.com/317367" -->
    <title>PSM Library for the Intel Infiniband Solution (OFED)</title>
    <para>
     The PSM library for the Intel Infiniband solution (OFED) is now
     available.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>Updating Firmware for QLogic 82XX based CNA</title>
    <para>
     For QLogic 82XX based CNA, update the firmware to the latest from the
     QLogic website or whatever is recommended by the OEM in case you are
     running 4.7.x FW version.
    </para>
   </section>
<!-- bnc#742845 -->
<!-- bnc#750414 -->
<!--   <section> -->
<!--    <title>Broadcom 57712 vNICs/NPAR PCIE Functions Disappearing under -->
<!--    SP2</title> -->
<!--    <para>***CHECKIT: SP3?</para> -->
<!--    <para> -->
<!-- SP2 scans for the functions on a PCI device in a new way using ARI. -->
<!-- This can cause some of the functions on the Broadcom 57712 adapter to be -->
<!-- missing after upgrading to SP2. -->
<!--    </para> -->
<!--    <para> -->
<!-- Contact your system vendor to receive the latest firmware for the -->
<!-- 57712 adapter that resolves this issue. -->
<!-- Alternatively, upgrading to kernel 3.0.26 and adding the boot parameter -->
<!-- 'pci=noari' will allow all the functions on the 57712 adapter to become visible -->
<!-- under SLES 11 SP2 and later. -->
<!--    </para> -->
<!--   </section> -->
  </section>
  <section id="Drivers.Storage" remap="Drivers:Storage">
   <title>Storage Drivers</title>
   <itemizedlist>
<!-- FATE#307126/bnc#560415 -->
<!-- bnc#832630 -->
    <listitem>
     <para>
      Updated qla2xxx to version 8.04.00.13.11.3-k
     </para>
    </listitem>
<!-- bnc#818162 -->
    <listitem>
     <para>
      Updated qla4xxx to version v5.03.00.06.11.3-k0
     </para>
    </listitem>
<!-- FATE#XXX -->
    <listitem>
     <para>
      Updated megaraid_mbox driver to version 2.20.5.1
     </para>
    </listitem>
<!-- FATE#XXX -->
    <listitem>
     <para>
      Updated megaraid_sas to version 4.27
     </para>
    </listitem>
<!-- bnc#556587 -->
    <listitem>
     <para>
      Updated MPT Fusion to version 4.22.00.00
     </para>
    </listitem>
<!-- bnc#566013 -->
    <listitem>
     <para>
      Updated mpt2sas driver to version 04.100.01.02
     </para>
    </listitem>
<!-- bnc#572427 -->
    <listitem>
     <para>
      Updated lpfc driver to version 8.3.5.7
     </para>
    </listitem>
<!-- FATE #XXX -->
    <listitem>
     <para>
      Added bnx2i driver for Broadcom NetXtreme II in version 2.1.1
     </para>
    </listitem>
<!-- FATE#XXX -->
    <listitem>
     <para>
      Updated bfa driver to version 2.1.2.1
     </para>
    </listitem>
<!-- bnc#664906 -->
    <listitem>
     <para>
      The enic driver was updated to version 1.4.2 to support newer Cisco
      UCS systems. This update also replaces LRO (Large Receive Offload) to
      GRO (Generic Receive Offload).
     </para>
    </listitem>
   </itemizedlist>
<!-- bnc#726754 -->
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-319120" remap="Drivers:Storage">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319120" -->
    <title>Infiniband Driver Configuration</title>
    <para>
     This SP provides updated mvapich2 psm and verbs drivers, but mvapich2
     mpitests are failing to run with both verbs and psm.
    </para>
    <para>
     To successfully run the mvapich2 mpi tests, create the
     <literal>/etc/mpd.conf</literal> file on all the hosts involved and add
     "secretword=&lt;&gt;" to the file.
    </para>
    <para>
     Then start the mpd s (= multi-purpose daemons) using the command
     "mpdboot --totalnum=&lt;no_of_nodes&gt; --file=&lt;mpi_hosts_file&gt;"
     on the hosts where you want tol run mpirun. This will start a ring of
     mpd processes on all the hosts included in the mpi_hosts_file.
    </para>
   </section>
   <section role="notoc" id="fate-318441" remap="Drivers:Storage">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318441" -->
    <title>Storage Modules</title>
    <para>
     The following modules got updated (selection):
     <itemizedlist>
      <listitem>
       <para>
        3w-sas - 3.26.02.000
       </para>
      </listitem>
      <listitem>
       <para>
        3w-9xxx - 2.26.02.014
       </para>
      </listitem>
      <listitem>
       <para>
        megaraid_sas - 06.806.08.00-rc1
       </para>
      </listitem>
      <listitem>
       <para>
        mptsas - 4.28.00.01suse
       </para>
      </listitem>
      <listitem>
       <para>
        mpt2sas - 20.100.00.00
       </para>
      </listitem>
      <listitem>
       <para>
        mpt3sas - 09.100.00.00
       </para>
      </listitem>
      <listitem>
       <para>
        pmcraid - 1.0.3
       </para>
      </listitem>
      <listitem>
       <para>
        aacraid - 1.2-0[30300]-ms
       </para>
      </listitem>
      <listitem>
       <para>
        mtip32xx - 1.3.1
       </para>
      </listitem>
      <listitem>
       <para>
        mlx4_core - 2.2-1
       </para>
      </listitem>
      <listitem>
       <para>
        mlx5_core - 2.2-1
       </para>
      </listitem>
      <listitem>
       <para>
        be2net - 10.4s
       </para>
      </listitem>
      <listitem>
       <para>
        lpfc - 0:10.4.8000.0.
       </para>
      </listitem>
     </itemizedlist>
    </para>
   </section>
   <section role="notoc" id="fate-316475" remap="Drivers:Storage">
<!-- sort_key="None"; non-rn-fate-cats="Storage and Partitioning"; -->
<!-- href="https://fate.novell.com/316475" -->
    <title>LIO Based FC Targets</title>
    <para>
     The LIO target stack has been updated to support FC targets based on
     QLogic adapters.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>Brocade FCoE Switch Does Not Accept Fabric Logins from Initiator</title>
    <orderedlist>
     <listitem>
      <para>
       Once link is up, LLDP query QoS to get the new PFC, send FCoE
       incapable right away, which is right.
      </para>
     </listitem>
     <listitem>
      <para>
       After negotiating with neighbor, we got lldp frame with un-recognized
       ieee dcbx, so we declare link is CEE incapable, and send out FCoE
       Capable event with PFC = 0 to fcoe kernel.
      </para>
     </listitem>
     <listitem>
      <para>
       Then neighbor adjusts its version to match our CEE version, now we
       find right DCBX tlv in incoming LLDP frame, we declare link CEE
       capable. At this time we did not send FCoE capable again since we
       already sent it in step 2.
      </para>
     </listitem>
    </orderedlist>
    <para>
     To solve this, upgrade the switch firmware to v6.4.3 or above.
    </para>
   </section>
  </section>
  <section id="Drivers.Other" remap="Drivers:Other">
   <title>Other Drivers</title>
   <itemizedlist>
    <listitem>
     <para>
      Updated CIFS to version 1.74
     </para>
    </listitem>
<!-- OCFS is SLE HA only -->
<!-- NOFATE -->
    <listitem>
     <para>
      Updated intel-i810 driver
     </para>
    </listitem>
<!-- FATE#302149 -->
    <listitem>
     <para>
      Added X11 driver for AMD Geode LX 2D (xorg-x11-driver-video-amd)
     </para>
    </listitem>
    <listitem>
     <para>
      Updated X11 driver for Radeon cards
     </para>
    </listitem>
<!-- FATE#302772 -->
    <listitem>
     <para>
      Updated XFS and DMAPI driver
     </para>
    </listitem>
<!-- FATE#303052 -->
    <listitem>
     <para>
      Updated Wacom driver to version 1.46
     </para>
    </listitem>
   </itemizedlist>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-319647" remap="Drivers:Other">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319647" -->
    <title>'Click-on-touch' and 'click-on-release' for xf86-input-evdev Input Driver</title>
    <para>
     Kiosk style systems (cash registers, vending machines, etc.) with
     touchscreens need to make sure, touchscreen 'clicks' are delivered
     accurately at the point where the touch screen was touched initially,
     that is, where a widget element was 'pressed'. Virtually all UI toolkits
     wait for a button release to happen to accept a 'click' and to record
     the location to determine the widget element 'clicked'. This behavior
     is undesirable for kiosk style systems. At the same time kiosk style
     systems use a fixed window placement: the user should not be able to
     'drag' windows around.
    </para>
    <para>
     To remedy this the following approaches would be possible:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Use of a special UI toolkits developed for this purpose. However this
       would limit the choice of toolkits.
      </para>
     </listitem>
     <listitem>
      <para>
       Use of touchscreens which synthesize a 'button release' event right
       after a 'button press' regardless if the finger is still touching the
       screen or not. Such touch screens exist.
      </para>
     </listitem>
     <listitem>
      <para>
       A customized input driver which is able to emulate this feature: This
       provides the greatest flexibility as it will work with all touch
       screens and toolkits.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     For this the 'click-on-touch' and 'click-on-release' feature has been
     added to the updated evdev input driver (xf86-input-evdev). The feature
     can be enabled either statically using a config file or 'on-the-fly' at
     run time by changing the appropriate properties on the input device.
     Please refer to the evdev man page (man 4 evdev). Device properties can
     be set by an X application (for instance a cash register software) or
     generically using the tool 'xinput' (refer to 'man 1 xinput').
    </para>
    <para>
     The following options can be set:
    </para>
<screen>1. mode:
  0 - default press/release behavior,
  1 - click-on-touch: button release is syntesized immediately after a
      'button press',
  2 - click-on-release: the button press event is delayed until the finger
      is lifted off the screen and a release event is generated.
2. button:
  the button to which this behavior is applied (since touchscreens generate a button 1
  event for screen touches, this usually doesn't need to be modified).
3. delay:
  To allow for visual feedback, a small delay may be introduced between press
  and release. Finger movements during the delay period do not generate position
  events nor are they reflected in the position of the release event. The delay time
  is set in miliseconds. A value of 100 (.1 sec) is sufficient to obtain a visible visual
  feedback.</screen>
   </section>
   <section role="notoc" id="fate-318974" remap="Drivers:Other">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318974" -->
    <title>SaX2: Changing Video Resolution</title>
    <para>
     With a SLE 11 SP3 maintenance update resp. the general update to SLE 11
     SP4, SaX2 no longer lets you select a video resolution when KMS is
     active. With KMS and the native or the modesetting driver RandR &gt;
     1.1 is available, which lets you change the resolution on the fly. The
     Gnome desktop provides a tool to do this and save the settings
     persistently across sessions.
    </para>
    <para>
     For any UMS (and RandR 1.1) drivers you will still get the full list of
     video modes. If you select an unsupported mode, it will be ignored and
     a monitor preferred default mode will be used instead.
    </para>
   </section>
   <section role="notoc" id="fate-318442" remap="Drivers:Other">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318442" -->
    <title>Other Modules</title>
    <para>
     The following modules got updated (selection):
     <itemizedlist>
      <listitem>
       <para>
        BDW PCH (Wildcat Point-LP) SATA
       </para>
      </listitem>
      <listitem>
       <para>
        HD Audio
       </para>
      </listitem>
      <listitem>
       <para>
        TCO Watchdog
       </para>
      </listitem>
      <listitem>
       <para>
        I2C (SMBus)
       </para>
      </listitem>
      <listitem>
       <para>
        nvme
       </para>
      </listitem>
      <listitem>
       <para>
        mgag200
       </para>
      </listitem>
      <listitem>
       <para>
        mei
       </para>
      </listitem>
     </itemizedlist>
    </para>
   </section>
   <section role="notoc" id="fate-317764" remap="Drivers:Other">
<!-- sort_key="None"; non-rn-fate-cats="Hardware and Drivers"; -->
<!-- href="https://fate.novell.com/317764" -->
    <title>Intel Processor support</title>
    <para>
     This Service Pack adds support for the following Intel Processors.
    </para>
    <para>
     <itemizedlist>
      <listitem>
       <para>
        Intel® Xeon® processor E7-4800 v3 product family
       </para>
      </listitem>
      <listitem>
       <para>
        Intel® Xeon® processor E7-8800 v3 product family
       </para>
      </listitem>
      <listitem>
       <para>
        5th Gen Intel® Core™ processors
       </para>
      </listitem>
      <listitem>
       <para>
        Intel® Core™ M Processor
       </para>
      </listitem>
      <listitem>
       <para>
        Intel® Xeon® processor E3-1200 v4 product family
       </para>
      </listitem>
     </itemizedlist>
    </para>
   </section>
   <section role="notoc" id="fate-317533" remap="Drivers:Other">
<!-- sort_key="None"; non-rn-fate-cats="Interoperability,Virtualization"; -->
<!-- href="https://fate.novell.com/317533" -->
    <title>Hyper-v: Update drivers to latest upstream version</title>
    <para>
     The updated drivers provide the following features:
    </para>
    <para>
     A userland daemon to handle the file copy service is included.
    </para>
    <para>
     The VMBUS driver utilizes all virtual CPUs (vCPUs) to communicate with
     the host, this will improve performance.
    </para>
    <para>
     Support for Generation2 VMs is included. 'Secure Boot' must be disabled
     in the VM settings on the host side, otherwise the VM will not start.
    </para>
    <para>
     The network driver was updated to remove the warning about outdated
     'Integration Services' that was shown in the Hyper-V Manager GUI.
    </para>
    <para>
     The network driver was updated to handle hotplug, which is a feature of
     Windows Server 2016.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
 </chapter>
 <chapter id="OtherUpdates" remap="OtherUpdates">
  <title>Other Updates</title>
  <para/>
<!-- via
     http://w3.suse.de/~aginies/updated_new_packages_sp4/updated_packages_sle11-sp3_sle11-sp4.xml
-->
<!-- mar. mai 26 10:51:36 CEST 2015 -->
<!--v Items below imported from FATE-->
  <section role="notoc" id="fate-320942" remap="OtherUpdates">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/320942" -->
   <title>libssh2_org Update</title>
   <para>
    <literal>libssh2_org</literal> was updated to version 1.4.3 fixing an
    unbounded memory leak. This version is also available in SLE 12.
   </para>
  </section>
  <section role="notoc" id="fate-319526" remap="OtherUpdates">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319526" -->
   <title>ntp 4.2.8</title>
   <para>
    ntp is updated to version 4.2.8.
   </para>
   <itemizedlist>
    <listitem>
     <para>
      The ntp server ntpd does not synchronize with its peers anymore and
      the peers are specified by their host name in
      <literal>/etc/ntp.conf</literal>.
     </para>
    </listitem>
    <listitem>
     <para>
      The output of <literal>ntpq --peers</literal> lists IP numbers of the
      remote servers instead of their host names.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Name resolution for the affected hosts works otherwise.
   </para>
   <para>
    Configure ntpd to not run chroot mode by setting
   </para>
<screen>NTPD_RUN_CHROOTED="no"</screen>
   <para>
    in <literal>/etc/sysconfig/ntp</literal> and restart the service with
   </para>
<screen>rcntp restart</screen>
   <para>
    Due to the architecture of ntpd, it does not start reliably in a chroot
    environment. Furthermore, the daemon drops all capabilities except for
    the one needed to open sockets on reserved ports, so chroot is not
    required. AppArmor can be used to further limit the process in what it
    can do if policy requirements mandate this.
   </para>
   <para>
    <emphasis role="bold">Additional Information</emphasis>
   </para>
   <para>
    The meaning of some parameters have changed, e.g. <literal>sntp
    -s</literal> is now <literal>sntp -S</literal>.
   </para>
   <para>
    After having been deprecated for several years, ntpdc is now disabled by
    default for security reasons. It can be re-enabled by adding a line
    saying "enable mode7" to /etc/ntp.conf, but preferably ntpq should be
    used instead.
   </para>
  </section>
  <section role="notoc" id="fate-319015" remap="OtherUpdates">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319015" -->
   <title>Optional GCC 5.2 Suite on SDK</title>
   <para>
    The optional compiler on the SDK has been updated to GCC 5.2. It brings
    improvements in C++ language support, including full C++11 support in
    the runtime library and the compiler as well as support for most C++14
    changes.
   </para>
   <para>
    For more details, see
    <ulink url="https://gcc.gnu.org/gcc-5/changes.html">https://gcc.gnu.org/gcc-5/changes.html</ulink>.
   </para>
  </section>
  <section role="notoc" id="fate-319013" remap="OtherUpdates">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319013" -->
   <title>TLS 1.2 for OpenVPN</title>
   <para>
    openvpn as it is shipped in SUSE Linux Enterprise 11 does not offer GCM
    ciphers and has also no TLS 1.2 support. This is due to the old openssl
    0.9.8j which just does not have these ciphers.
   </para>
   <para>
    There is an additional openvpn-openssl1 package (openvpn 2.3.2) that is
    linked against openssl1 in the SLE 11 Security Module. This
    openvpn-openssl1 package is meant as a drop-in replacement for the
    regular openvpn package and uses the same configuration files. This way
    TLS 1.2 is available for OpenVPN.
   </para>
  </section>
  <section role="notoc" id="fate-316970" remap="OtherUpdates">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316970" -->
   <title>Update of PostgreSQL to Version 9.4</title>
   <para>
    The upstream end-of-life for version 9.1 is announced for September
    2016. Customers need to switch to a newer supported version until then.
   </para>
   <para>
    PostgreSQL was updated to version 9.4, prolonging the timeframe during
    which PostgreSQL is supported. Thus there is enough time for switching.
   </para>
  </section>
<!--^ End of Items imported from FATE-->
  <section>
   <title>List of Updated Packages (SLES)</title>
   <itemizedlist>
    <listitem>
     <para>
      Updated autoyast2 to version 2.17.76
     </para>
    </listitem>
    <listitem>
     <para>
      Updated binutils to version 2.24
     </para>
    </listitem>
    <listitem>
     <para>
      Updated biosdevname to version 0.6.1
     </para>
    </listitem>
    <listitem>
     <para>
      Updated brocade-firmware to version 3.2.3.0
     </para>
    </listitem>
    <listitem>
     <para>
      Updated btrfsprogs to version 3.18.2
     </para>
    </listitem>
    <listitem>
     <para>
      Updated cpupower to version 3.19
     </para>
    </listitem>
    <listitem>
     <para>
      Updated crash to version 7.0.9
     </para>
    </listitem>
    <listitem>
     <para>
      Updated cryptsetup to version 1.1.3
     </para>
    </listitem>
    <listitem>
     <para>
      Updated dosfstools to version 3.0.26
     </para>
    </listitem>
    <listitem>
     <para>
      Updated efibootmgr to version 0.6.0
     </para>
    </listitem>
    <listitem>
     <para>
      Updated gdb to version 7.7
     </para>
    </listitem>
    <listitem>
     <para>
      Updated gfxboot to version 4.1.34
     </para>
    </listitem>
    <listitem>
     <para>
      Updated hwinfo to version 15.54
     </para>
    </listitem>
    <listitem>
     <para>
      Updated hyper-v to version 6
     </para>
    </listitem>
    <listitem>
     <para>
      Updated installation-images to version 11.221
     </para>
    </listitem>
    <listitem>
     <para>
      Updated ipmitool to version 1.8.15
     </para>
    </listitem>
    <listitem>
     <para>
      Updated iproute2 to version 3.0
     </para>
    </listitem>
    <listitem>
     <para>
      Updated iprutils to version 2.4.1
     </para>
    </listitem>
    <listitem>
     <para>
      Updated iptables to version 1.4.16.3
     </para>
    </listitem>
    <listitem>
     <para>
      Updated ledmon to version 0.79
     </para>
    </listitem>
    <listitem>
     <para>
      Updated libcgroup1 to version 0.41.rc1
     </para>
    </listitem>
    <listitem>
     <para>
      Updated libdrm to version 2.4.52
     </para>
    </listitem>
    <listitem>
     <para>
      Updated libguestfs to version 1.20.12
     </para>
    </listitem>
    <listitem>
     <para>
      Updated libHBAAPI2 to version 2.2.9
     </para>
    </listitem>
    <listitem>
     <para>
      Updated libvirt to version 1.2.5
     </para>
    </listitem>
    <listitem>
     <para>
      Updated libvpd2 to version 2.2.4
     </para>
    </listitem>
    <listitem>
     <para>
      Updated libzypp to version 9.38.8
     </para>
    </listitem>
    <listitem>
     <para>
      Updated linux-kernel-headers to version 3.0
     </para>
    </listitem>
    <listitem>
     <para>
      Updated linuxrc to version 3.3.107
     </para>
    </listitem>
    <listitem>
     <para>
      Updated lldpad to version 0.9.46
     </para>
    </listitem>
    <listitem>
     <para>
      Updated makedumpfile to version 1.5.6
     </para>
    </listitem>
    <listitem>
     <para>
      Updated mcelog to version 1.0.2014.12.20
     </para>
    </listitem>
    <listitem>
     <para>
      Updated mdadm to version 3.3.1
     </para>
    </listitem>
    <listitem>
     <para>
      Updated mstflint to version 3.6.0
     </para>
    </listitem>
    <listitem>
     <para>
      Updated ntp to version 4.2.8p2
     </para>
    </listitem>
    <listitem>
     <para>
      Updated numactl to version 2.0.10
     </para>
    </listitem>
    <listitem>
     <para>
      Updated openCryptoki to version 3.2
     </para>
    </listitem>
    <listitem>
     <para>
      Updated open-fcoe to version 1.0.29
     </para>
    </listitem>
    <listitem>
     <para>
      Updated openssh to version 6.6p1
     </para>
    </listitem>
    <listitem>
     <para>
      Updated pciutils-ids to version 2014.11.18
     </para>
    </listitem>
    <listitem>
     <para>
      Updated perf to version 3.0.101
     </para>
    </listitem>
    <listitem>
     <para>
      Updated perl-Bootloader to version 0.4.89.70
     </para>
    </listitem>
    <listitem>
     <para>
      Updated perl-Sys-Virt to version 1.2.5
     </para>
    </listitem>
    <listitem>
     <para>
      Updated postgresql-init to version 9.4
     </para>
    </listitem>
    <listitem>
     <para>
      Updated release-notes-sles to version 11.4.10
     </para>
    </listitem>
    <listitem>
     <para>
      Updated sg3_utils to version 1.40
     </para>
    </listitem>
    <listitem>
     <para>
      Updated sles-installquick_cs to version 11.3
     </para>
    </listitem>
    <listitem>
     <para>
      Updated sles-manuals_en to version 11.4
     </para>
    </listitem>
    <listitem>
     <para>
      Updated smartmontools to version 6.3
     </para>
    </listitem>
    <listitem>
     <para>
      Updated src_vipa to version 2.1.0
     </para>
    </listitem>
    <listitem>
     <para>
      Updated suse-sam to version 0.8.5
     </para>
    </listitem>
    <listitem>
     <para>
      Updated suse-sam-data to version 0.8.5
     </para>
    </listitem>
    <listitem>
     <para>
      Updated virt-manager to version 0.9.5
     </para>
    </listitem>
    <listitem>
     <para>
      Updated virt-viewer to version 0.5.7
     </para>
    </listitem>
    <listitem>
     <para>
      Updated vm-install to version 0.6.37
     </para>
    </listitem>
    <listitem>
     <para>
      Updated xen to version 4.4.2_06
     </para>
    </listitem>
    <listitem>
     <para>
      Updated xrdp to version 0.6.1
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2 to version 2.17.138
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-bootloader to version 2.17.98
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-fcoe-client to version 2.17.26
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-http-server to version 2.17.17
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-installation to version 2.17.114
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-iscsi-client to version 2.17.41
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-iscsi-lio-server to version 2.17.14
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-iscsi-server to version 2.17.11
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-ncurses to version 2.17.23
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-network to version 2.17.207
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-nfs-client to version 2.17.19
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-ntp-client to version 2.17.16
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-online-update to version 2.17.24
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-packager to version 2.17.113
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-repair to version 2.17.13
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-samba-server to version 2.18.0
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-storage to version 2.17.157
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-support to version 2.17.21
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-ar to version 2.17.40
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-cs to version 2.17.49
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-da to version 2.17.36
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-de to version 2.17.61
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-el to version 2.17.19
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-en_GB to version 2.17.30
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-en_US to version 2.17.35
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-es to version 2.17.56
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-fi to version 2.17.40
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-fr to version 2.17.60
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-hu to version 2.17.60
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-it to version 2.17.58
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-ja to version 2.17.50
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-ko to version 2.17.56
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-nb to version 2.17.33
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-nl to version 2.17.55
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-pl to version 2.17.52
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-pt to version 2.17.11
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-pt_BR to version 2.17.55
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-ru to version 2.17.50
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-sv to version 2.17.40
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-tr to version 2.17.17
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-uk to version 2.17.29
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-zh_CN to version 2.17.45
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-trans-zh_TW to version 2.17.39
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-update to version 2.17.26
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-users to version 2.17.55
     </para>
    </listitem>
    <listitem>
     <para>
      Updated yast2-vm to version 2.17.17
     </para>
    </listitem>
    <listitem>
     <para>
      Updated zypper to version 1.6.323
     </para>
    </listitem>
   </itemizedlist>
  </section>
 </chapter>
 <chapter id="SDK" remap="SDK">
  <title>Software Development Kit</title>
  <para>
   SUSE provides a Software Development Kit (SDK) for SUSE Linux Enterprise
   11 Service Pack 4. This SDK contains libraries, development environments
   and tools along the following patterns:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     C/C++ Development
    </para>
   </listitem>
   <listitem>
    <para>
     Certification
    </para>
   </listitem>
   <listitem>
    <para>
     Documentation Tools
    </para>
   </listitem>
   <listitem>
    <para>
     GNOME Development
    </para>
   </listitem>
   <listitem>
    <para>
     Java Development
    </para>
   </listitem>
   <listitem>
    <para>
     KDE Development
    </para>
   </listitem>
   <listitem>
    <para>
     Linux Kernel Development
    </para>
   </listitem>
   <listitem>
    <para>
     Programming Libraries
    </para>
   </listitem>
   <listitem>
    <para>.NET Development
    </para>
   </listitem>
   <listitem>
    <para>
     Miscellaneous
    </para>
   </listitem>
   <listitem>
    <para>
     Perl Development
    </para>
   </listitem>
   <listitem>
    <para>
     Python Development
    </para>
   </listitem>
   <listitem>
    <para>
     Qt 4 Development
    </para>
   </listitem>
   <listitem>
    <para>
     Ruby on Rails Development
    </para>
   </listitem>
   <listitem>
    <para>
     Ruby Development
    </para>
   </listitem>
   <listitem>
    <para>
     Version Control Systems
    </para>
   </listitem>
   <listitem>
    <para>
     Web Development
    </para>
   </listitem>
   <listitem>
    <para>
     YaST Development
    </para>
   </listitem>
  </itemizedlist>
<!--v Items below imported from FATE-->
  <section role="notoc" id="fate-317094" remap="SDK">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317094" -->
   <title>samba-test subpackage with smbtorture and other binaries</title>
   <para>
    The <literal>samba-test</literal> subpackage was added, offering
    smbtorture and other binaries for testing.
   </para>
  </section>
<!--^ End of Items imported from FATE-->
 </chapter>
 <chapter id="Update">
  <title>Update-Related Notes</title>
  <para>
   This section includes update-related information for this release.
  </para>
<!-- This section includes update-related information -->
  <section id="Update.General" remap="Update:General">
   <title>General Notes</title>
<!-- AI:ke: describe what _is_ supported first!?!? -->
<!-- bnc#827325 -->
<!-- now fate#318189 -->
<!--

<title>Lower Version Numbers in SUSE Linux Enterprise 11 SP3 than in
SP2</title>
-->
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-319123" remap="Update:General">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319123" -->
    <title>Registration Key: Updating with Installed Add-ons</title>
    <para>
     If add-ons are installed on your system, you might need to enter the
     registration key in order to update the system.
    </para>
   </section>
   <section role="notoc" id="fate-318189" remap="Update:General">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318189" -->
    <title>Lower Version Numbers in SUSE Linux Enterprise 11 SP4 Than in Version 11 SP3</title>
    <para>
     When upgrading from SUSE Linux Enterprise Server or Desktop 11 SP3 to
     version 11 SP4, you may encounter a version downgrade of specific
     software packages, including the Linux Kernel.
    </para>
    <para>
     SLE 11 SP4 has all its software packages and updates in the SLE 11 SP4
     repositories. No packages from SLE 11 SP3 repositories are needed for
     installation or upgrade, not even from the SLE 11 SP3 update
     repositories.
    </para>
    <para>
     Note
    </para>
    <para>
     It is important to remember that the version number is not sufficient
     to determine which bugfixes are applied to a software package.
    </para>
    <para>
     In case you add SLE 11 SP3 update repositories, be aware of one
     characteristic of the repository concept: Version numbers in the SP3
     update repository can be higher than those in the SP4 repository. Thus,
     if you update with the SP3 repositories enabled, you may get the SP3
     version of a package instead of the SP4 version. This is admittedly
     unfortunate.
    </para>
    <para>
     It is recommended to avoid using the version from a lower product or
     SP, because using the SLE 11 SP3 package instead of the SP4 package can
     result in unexpected side effects. Thus we advise to switch off all the
     SLE 11 SP3 repositories, if you do not really need them. Keep old
     repositories only, if your system depends on a specific older package
     version. If you need a package from a lower product or SP though, and
     thus have SLE 11 SP3 repositories enabled, make sure that the packages
     you intended to upgrade have actually been upgraded.
    </para>
    <para>
     Summarizing: If you have an SLE 11 SP3 installation with all patches
     and updates applied, and then migrate off-line to SLE 11 SP4, you will
     see a downgrade of some packages. This is expected behavior.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section id="Update.General.Sequence">
<!-- bnc#665159 -->
<!-- bnc#733003 -->
<!-- bnc#751006 -->
<!-- bnc#755503 -->
    <title>Upgrading from SLES 10 (GA and Service Packs) or SLES 11 GA</title>
    <para>
     There are supported ways to upgrade from SLES 10 GA and SPx or
     SLES 11 GA and SP1 to SLES 11 SP4, which may require intermediate
     upgrade steps:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SLES 10 GA -&gt; SLES 10 SP1 -&gt; SLES 10 SP2 -&gt; SLES 10 SP3
       -&gt; SLES 10 SP4 -&gt; SLES 11 SP4, or
      </para>
     </listitem>
     <listitem>
      <para>
       SLES 11 GA -&gt; SLES 11 SP1 -&gt; SLES 11 SP2 -&gt; SLES 11 SP3
       -&gt; SLES 11 SP4
      </para>
     </listitem>
    </itemizedlist>
   </section>
   <section>
    <title>Online Migration from SP3 to SP4 via "YaST wagon"</title>
    <para>
     The online migration from SP3 to SP4 is supported via the "YaST wagon"
     module.
    </para>
   </section>
<!-- bnc#731924 -->
<!-- reuse
       http://www.novell.com/support/dynamickc.do?cmd=show&forward=nonthreadedKC&docType=kc&externalId=7010200_draft&sliceId=1
  (for SP2) -->
<!-- FIXME: adjust it there: this snippet is also used in the SLED
              release notes -->
   <section>
    <title>Migrating to SLE 11 SP4 Using Zypper</title>
    <para>
     To migrate the system to the Service Pack 4 level with
     <command>zypper</command>, proceed as follows:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Open a root shell.
      </para>
     </listitem>
     <listitem>
      <para>
       Run <command>zypper ref -s</command> to refresh all services and
       repositories.
      </para>
     </listitem>
     <listitem>
      <para>
<!-- <command>zypper up -t patch</command> is basically the same...-->
       Run <command>zypper patch</command> to install package management
       updates.
      </para>
     </listitem>
     <listitem>
      <para>
       Now it is possible to install all available updates for SLES/SLED 11
       SP3; run <command>zypper patch</command> again.
      </para>
     </listitem>
     <listitem>
      <para>
       Now the installed products contain information about distribution
       upgrades and which migration products should be installed to perform
       the migration. Read the migration product information from
       <filename>/etc/products.d/*.prod</filename> and install them.
      </para>
     </listitem>
     <listitem>
      <para>
       Enter the following command:
      </para>
<screen>grep '&lt;product' /etc/products.d/*.prod</screen>
      <para>
       A sample output could be as follows:
      </para>
<screen>&lt;product&gt;sle-sdk-SP4-migration&lt;/product&gt;
&lt;product&gt;SUSE_SLES-SP4-migration&lt;/product&gt;</screen>
     </listitem>
     <listitem>
      <para>
       Install these migration products (example):
      </para>
<screen>zypper in -t product sle-sdk-SP4-migration SUSE_SLES-SP4-migration</screen>
     </listitem>
     <listitem>
      <para>
       Run <command>suse_register -d 2 -L /root/.suse_register.log</command>
       to register the products in order to get the corresponding SP4 Update
       repositories.
      </para>
     </listitem>
     <listitem>
      <para>
       Run <command>zypper ref -s</command> to refresh services and
       repositories.
      </para>
     </listitem>
     <listitem>
      <para>
       Check the repositories using <command>zypper lr</command>. Disable
       SP3 repositories after the registration and enable the new SP4
       repositories (such as SP4-Pool, SP4-Updates):
      </para>
<screen>zypper mr --disable &lt;repo-alias&gt;
zypper mr --enable &lt;repo-alias&gt;</screen>
      <para>
       Also disable repositories you do not want to update from.
      </para>
     </listitem>
     <listitem>
      <para>
       Then perform a distribution upgrade by entering the following command
<!-- (example for SLES, adjust catalog names in case SLED is updated)-->
       :
      </para>
<screen>zypper dup --from SLES11-SP4-Pool --from SLES11-SP4-Updates \
  --from SLE11-SP2-WebYaST-1.3-Pool --from SLE11-SP2-WebYaST-1.3-Updates</screen>
      <para>
       Add more SP4 repositories here if needed, e.g. in case add-on
       products are installed. For WebYaST, it is actually
       <literal>SLE11-SP2-*</literal>, because there is one WebYaST release
       that runs on three SP code bases.
      </para>
      <note>
       <para>
        If you make sure that only repositories, which you migrate from, are
        enabled, you can omit the <literal>--from</literal> parameters.
       </para>
      </note>
     </listitem>
     <listitem>
      <para>
       zypper will report that it will delete the migration product and
       update the main products. Confirm the message to continue updating
       the RPM packages.
      </para>
     </listitem>
     <listitem>
      <para>
       To do a full update, run <command>zypper patch</command>.
      </para>
     </listitem>
     <listitem>
      <para>
       After the upgrade is finished, register the new products again:
      </para>
<screen>suse_register -d 2 -L /root/.suse_register.log</screen>
     </listitem>
     <listitem>
      <para>
       Run <command>zypper patch</command> after re-registering. Some
       products do not use the update repositories during the migration and
       they are not active at this point of time.
      </para>
     </listitem>
     <listitem>
      <para>
       Reboot the system.
      </para>
     </listitem>
    </itemizedlist>
<!--
  <para>
   For more information about migrating the system to SLE 11 SP2, see
   the Deployment Guide.
  </para>
  -->
   </section>
   <section>
<!-- bnc#733003 -->
    <title>Migration from SUSE Linux Enterprise Server 10 SP4 via Bootable Media</title>
    <para>
     Migration is supported from SUSE Linux Enterprise Server 10 SP4 via
     bootable media (incl. PXE boot).
    </para>
   </section>
<!-- bnc#818105 -->
<!-- 2015-09-09: according to jsrain, e can remove this -->
<!--
       <section>
       <title>Migrating Hosts Running SMT 11 SP2 to SMT 11 SP3</title>
   -->
   <section>
    <title>Online Migration with Debuginfo Packages Not Supported</title>
    <para>
     Online migration from SP3 to SP4 is not supported if debuginfo packages
     are installed.
    </para>
   </section>
   <section>
<!-- bnc#652004: obsolete -->
<!-- bnc#733001 -->
    <title>Upgrading to SLES 11 SP4 with Root File System on iSCSI</title>
    <para>
     The upgrade or the automated migration from SLES 10 to SLES 11 SP4
     may fail if the root file system of the machine is located on iSCSI
     because of missing boot options.
    </para>
    <para>
     There are two approaches to solve it, if you are using AutoYaST (adjust
     IP addresses and hostnames according to your environment!):
    </para>
    <variablelist>
     <varlistentry>
      <term>With Manual Intervention:</term>
      <listitem>
       <para>
        Use as boot options:
       </para>
       <para>
        <literal>withiscsi=1 autoupgrade=1
        autoyast=http://myserver/autoupgrade.xml</literal>
       </para>
       <para>
        Then, in the dialog of the iSCSI initiator, configure the iSCSI
        device.
       </para>
       <para>
        After successful configuration of the iSCSI device, YaST will find
        the installed system for the upgrade.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Fully Automated Upgrade:</term>
      <listitem>
       <para>
        Add or modify the &lt;iscsi-client&gt; section in your
        <filename>autoupgrade.xml</filename> as follows:
       </para>
<screen>&lt;iscsi-client&gt;
  &lt;initiatorname&gt;iqn.2012-01.com.example:initiator-example&lt;/initiatorname&gt;
  &lt;targets config:type="list"&gt;
    &lt;listentry&gt;
      &lt;authmethod&gt;None&lt;/authmethod&gt;
      &lt;iface&gt;default&lt;/iface&gt;
      &lt;portal&gt;10.10.42.84:3260&lt;/portal&gt;
      &lt;startup&gt;onboot&lt;/startup&gt;
      &lt;target&gt;iqn.2000-05.com.example:disk01-example&lt;/target&gt;
    &lt;/listentry&gt;
  &lt;/targets&gt;
  &lt;version&gt;1.0&lt;/version&gt;
&lt;/iscsi-client&gt;</screen>
       <para>
        Then, run the automated upgrade with these boot options:
       </para>
       <para>
        <literal>autoupgrade=1
        autoyast=http://myserver/autoupgrade.xml</literal>
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </section>
   <section>
    <title>Kernel Split in Different Packages</title>
    <para>
     With SUSE Linux Enterprise Server 11 the kernel RPMs are split in
     different parts:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       kernel-flavor-base
      </para>
      <para>
       Very reduced hardware support, intended to be used in virtual machine
       images.
      </para>
     </listitem>
     <listitem>
      <para>
       kernel-flavor
      </para>
      <para>
       Extends the base package; contains all supported kernel modules.
      </para>
     </listitem>
     <listitem>
      <para>
       kernel-flavor-extra
      </para>
      <para>
       All other kernel modules which may be useful but are not supported.
       This package will not be installed by default.
      </para>
     </listitem>
    </itemizedlist>
   </section>
   <section>
    <title>Tickless Idle</title>
    <para>
     SUSE Linux Enterprise Server uses tickless timers. This can be disabled
     by adding <option>nohz=off</option> as a boot option.
    </para>
   </section>
   <section>
    <title>Development Packages</title>
    <para>
     SUSE Linux Enterprise Server will no longer contain any development
     packages, with the exception of some core development packages
     necessary to compile kernel modules. Development packages are available
     in the SUSE Linux Enterprise Software Development Kit.
    </para>
   </section>
   <section>
    <title>Displaying Manual Pages with the Same Name</title>
    <para>
     The <command>man</command> command now asks which manual page the user
     wants to see if manual pages with the same name exist in different
     sections. The user is expected to type the section number to make this
     manual page visible.
    </para>
    <para>
     If you want to revert back to the previously used method, please set
     <literal>MAN_POSIXLY_CORRECT=1</literal> in a shell initialization file
     such as <filename>~/.bashrc</filename>.
    </para>
   </section>
   <section>
    <title>YaST LDAP Server No Longer Uses <filename>/etc/openldap/slapd.conf</filename></title>
    <para>
     The YaST LDAP Server module no longer stores the configuration of the
     LDAP Server in the file <filename>/etc/openldap/slapd.conf</filename>.
     It uses OpenLDAP's dynamic configuration backend, which stores the
     configuration in an LDAP database itself. That database consists of a
     set of <filename>.ldif</filename> files in the directory
     <filename>/etc/openldap/slapd.d</filename>. You should - usually - not
     need to access those files directly. To access the configuration you
     can either use the <command>yast2-ldap-server</command> module or any
     capable LDAP client (e.g., ldapmodify, ldapsearch, etc.). For details
     on the dynamic configuration of OpenLDAP, refer to the OpenLDAP
     Administration Guide.
    </para>
   </section>
   <section>
    <title>AppArmor</title>
    <para>
     This release of SUSE Linux Enterprise Server ships with AppArmor. The
     AppArmor intrusion prevention framework builds a firewall around your
     applications by limiting the access to files, directories, and POSIX
     capabilities to the minimum required for normal operation. AppArmor
     protection can be enabled via the AppArmor control panel, located in
     YaST under Security and Users. For detailed information about using
     AppArmor, see the documentation in
     <filename>/usr/share/doc/packages/apparmor-docs</filename>.
    </para>
    <para>
     The AppArmor profiles included with SUSE Linux have been developed with
     our best efforts to reproduce how most users use their software. The
     profiles provided work unmodified for many users, but some users may
     find our profiles too restrictive for their environments.
    </para>
    <para>
     If you discover that some of your applications do not function as you
     expected, you may need to use the AppArmor Update Profile Wizard in
     YaST (or use the aa-logprof(8) command line utility) to update your
     AppArmor profiles. Place all your profiles into learning mode with the
     following: <command>aa-complain /etc/apparmor.d/*</command>
    </para>
    <para>
     When a program generates many complaints, the system's performance is
     degraded. To mitigate this, we recommend periodically running the
     Update Profile Wizard (or aa-logprof(8)) to update your profiles even
     if you choose to leave them in learning mode. This reduces the number
     of learning events logged to disk, which improves the performance of
     the system.
    </para>
   </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c30 -->
<!-- bnc#740509 -->
   <section>
    <title>Updating with Alternative Boot Loader (Non-Linux) or Multiple Boot Loader Programs</title>
    <note>
     <para>
      Before updating, check the configuration of your boot loader to assure
      that it is not configured to modify any system areas (MBR, settings
      active partition or similar). This will reduce the amount of system
      areas that you need to restore after update.
     </para>
    </note>
    <para>
     Updating a system where an alternative boot loader (not grub) or an
     additional boot loader is installed in the MBR (Master Boot Record)
     might override the MBR and place grub as the primary boot loader into
     the system.
    </para>
    <para>
     In this case, we recommend the following: First backup your data. Then
     either do a fresh installation and restore your data, or run the update
     nevertheless and restore the affected system areas (in particular, the
     MBR). It is always recommended to keep data separated from the system
     software. In other words, <filename>/home</filename>,
     <filename>/srv</filename>, and other volumes containing data should be
     on separate partitions, volume groups or logical volumes. The YaST
     partitioning module will propose doing this.
    </para>
    <para>
     Other update strategies (except booting the install media) are safe if
     the boot loader is configured properly. But the other strategies are
     not available, if you update from SUSE Linux Enterprise Server 10.
    </para>
   </section>
   <section>
    <title>Upgrading MySQL to SUSE Linux Enterprise Server 11</title>
    <para>
     During the upgrade to SUSE Linux Enterprise Server 11 MySQL is also
     upgraded to the latest version. To complete this migration you may have
     to upgrade your data as described in the MySQL documentation.
    </para>
   </section>
<!-- relnotes.g.firewall -->
   <section>
    <title>Fine-Tuning Firewall Settings</title>
    <para>
     SuSEfirewall2 is enabled by default, which means you cannot log in from
     remote systems. This also interferes with network browsing and
     multicast applications, such as SLP and Samba ("Network Neighborhood").
     You can fine-tune the firewall settings using YaST.
    </para>
   </section>
<!-- bnc#474036 -->
<!-- bnc#733317 -->
   <section>
    <title>Upgrading from SUSE Linux Enterprise Server 10 SP4 with the Xen Hypervisor May Have Incorrect Network Configuration</title>
    <para>
     We have improved the network configuration: If you install SUSE Linux
     Enterprise Server 11 SP4 and configure Xen, you get a bridged setup
     through YaST.
    </para>
    <para>
     However, if you upgrade from SUSE Linux Enterprise Server 10 SP4 to
     SUSE Linux Enterprise Server 11 SP4, the upgrade does not configure
     the bridged setup automatically.
    </para>
    <para>
     To start the bridge proposal for networking, start the "YaST Control
     Center", choose "Virtualization", then "Install Hypervisor and Tools".
     Alternatively, call <command>yast2 xen</command> on the command line.
    </para>
   </section>
<!--  https://bugzilla.novell.com/show_bug.cgi?id=448734#c57 -->
<!--  https://bugzilla.novell.com/show_bug.cgi?id=740513 -->
   <section>
    <title>LILO Configuration Via YaST or AutoYaST</title>
    <para>
     The configuration of the LILO boot loader on the x86 and x86_64
     architecture via YaST or AutoYaST is deprecated, and not supported
     anymore. For more information, see Novell TID 7003226
     <ulink url="https://www.suse.com/support/kb/doc/?id=000016991"/>.
    </para>
   </section>
  </section>
<!-- This section includes update-related information -->
  <section id="Update.GAToSP3">
   <title>Update from SUSE Linux Enterprise Server 11</title>
   <section>
<!-- bnc#632856 -->
    <title>Changed Routing Behavior</title>
    <para>
     SUSE Linux Enterprise Server 10 and SUSE Linux Enterprise Server 11 set
     <literal>net.ipv4.conf.all.rp_filter = 1</literal> in
     <filename>/etc/sysctl.conf</filename> with the intention of enabling
     route path filtering. However, the kernel fails to enable routing path
     filtering, as intended, by default in these products.
    </para>
    <para>
     Since SLES 11 SP1, this bug is fixed and most simple single-homed
     unicast server setups will not notice a change. But it may cause issues
     for applications that relied on reverse path filtering being disabled
     (e.g., multicast routing or multi-homed servers).
    </para>
   </section>
   <section>
    <title>Kernel Devel Packages</title>
    <para>
     Starting with SUSE Linux Enterprise Server 11 Service Pack 1 the
     configuration files for recompiling the kernel were moved into their
     own sub-package:
    </para>
    <variablelist>
     <varlistentry>
      <term>kernel-flavor-devel</term>
      <listitem>
       <para>
        This package contains only the configuration for one kernel type
        (<quote>flavor</quote>), such as <literal>default</literal> or
        <literal>desktop</literal>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </section>
  </section>
  <section id="Update.SP1ToSP3">
   <title>Update from SUSE Linux Enterprise Server 11 SP1</title>
   <para>
    The direct update from SUSE Linux Enterprise Server 11 SP1 to SP4 is not
    supported. For more information, see
    <xref linkend="Update.General.Sequence"/>.
   </para>
<!-- most probably, this is not supported (simona will confirm it)
  <section>
   <title>Update from SUSE Linux Enterprise Server 11 SP 1</title>
    <para>
     ***CHECKIT
     Updating from SUSE Linux Enterprise Server 11 SP 1 with AutoYaST is
     supported.
    </para>
  </section>
 -->
  </section>
  <section id="Update.SP2ToSP3">
   <title>Update from SUSE Linux Enterprise Server 11 SP2</title>
   <section>
    <title>Update from SUSE Linux Enterprise Server 11 SP2</title>
    <para>
     Updating from SUSE Linux Enterprise Server 11 SP2 with AutoYaST is
     supported.
    </para>
   </section>
<!-- bnc#804970 -->
<!-- bsc#940594 -->
<!--
  <section id='Update.SP2ToSP3.webyast'>
   <title>Migrating SUSE Linux Enterprise Server 11 SP2 with WebYaST
   Installed via wagon</title>

   <para>
    For migrating SLES 11 SP2 with WebYaST installed to SP3 via wagon, it
    is necessary to install the WebYaST product metadata before starting
    the migration.  To do so, make sure the packages
    "sle-11-SP2-WebYaST-release" and "sle-11-SP2-WebYaST-release-cd" are
    installed. You can ignore, if wagon reports an unknown registration
    status of WebYaST at the beginning of the migration.
   </para>

   <note>
    <para>
     Without the WebYaST product metadata installed, WebYaST will not be
     migrated.
    </para>
   </note>

   <para>
    The product metadata are not needed when upgrading SLES via booting the
    installation media.
   </para>
  </section>
  -->
  </section>
  <section id="Update.SP3ToSP4">
   <title>Update from SUSE Linux Enterprise Server 11 SP3</title>
   <section>
    <title>Update from SUSE Linux Enterprise Server 11 SP3</title>
    <para>
     Updating from SUSE Linux Enterprise Server 11 SP3 with AutoYaST is
     supported.
    </para>
   </section>
  </section>
 </chapter>
 <chapter id="Deprecated" remap="Deprecated">
  <title>Deprecated Functionality</title>
<!--v Items below imported from FATE-->
  <section role="notoc" id="fate-319469" remap="Deprecated">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319469" -->
   <title>YaST Modules Dropped from SUSE Linux Enterprise 12</title>
   <para>
    The following YaST modules or obsolete features of modules will not be
    available in SUSE Linux Enterprise 12 anymore:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      yast2-phone-services
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-repair
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-network: DSL configuration
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-network: ISDN configuration
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-network: modem support
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-backup and yast2-restore
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-apparmor: incident reporting tools
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-apparmor: profile generating tools
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-*creator (moved to SDK)
     </para>
    </listitem>
    <listitem>
     <para>
      YaST installation into directory
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-x11
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-mouse
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-irda (IrDA)
     </para>
    </listitem>
    <listitem>
     <para>
      YaST Boot and Installation server modules
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-fingerprint-reader
     </para>
    </listitem>
    <listitem>
     <para>
      yast2-profile-manager
     </para>
    </listitem>
   </itemizedlist>
  </section>
<!--^ End of Items imported from FATE-->
  <section id="Deprecated.rmwith11sp4" remap="Deprecated:rmwith11sp4">
   <title>Packages Removed with SUSE Linux Enterprise Server 11 SP4</title>
   <para>
    The following packages were removed with the release of SUSE Linux
    Enterprise Server 11 SP4:
   </para>
   <variablelist>
    <varlistentry>
     <term/>
     <listitem>
      <para></para>
     </listitem>
    </varlistentry>
   </variablelist>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-318121" remap="Deprecated:rmwith11sp4">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318121" -->
    <title>IBM Java 6</title>
    <para>
     IBM Java 6 is no longer available on the SUSE Linux Enterprise SDK.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="Deprecated.rmwith11sp3">
   <title>Packages Removed with SUSE Linux Enterprise Server 11 SP3</title>
   <para>
    The following packages were removed with the release of SUSE Linux
    Enterprise Server 11 SP3:
   </para>
   <para>
    N/A
   </para>
<!--
 <variablelist>
   <varlistentry>
   <term></term>
  <listitem>
   <para>
   </para>
  </listitem>
  </varlistentry>
  </variablelist>
  -->
  </section>
  <section id="Deprecated.rmwith11sp2">
   <title>Packages Removed with SUSE Linux Enterprise Server 11 Service Pack 2</title>
   <para>
    The following packages were removed with the release of SUSE Linux
    Enterprise Server 11 Service Pack 2:
   </para>
   <variablelist>
    <varlistentry>
<!-- bnc#732997 -->
     <term>hyper-v-kmp</term>
     <listitem>
      <para>
       hyper-v-kmp has been removed.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>32-bit Xen Hypervisor as a Virtualization Host</term>
     <listitem>
      <para>
       The 32-bit Xen hypervisor as a virtualization host is not supported
       anymore. 32-bit virtual guests are not affected and fully supported
       with the provided 64-bit hypervisor.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </section>
  <section id="Deprecated.rmwith11sp1">
   <title>Packages Removed with SUSE Linux Enterprise Server 11 Service Pack 1</title>
   <para>
    The following packages were removed with the release of SUSE Linux
    Enterprise Server 11 Service Pack 1:
   </para>
   <variablelist>
    <varlistentry>
     <term>brocade-bfa</term>
     <listitem>
      <para>
       The brocade-bfa kernel module is now part of the main kernel package.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>enic-kmp</term>
     <listitem>
      <para>
       The enic kernel module is now part of the main kernel package.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>fnic-kmp</term>
     <listitem>
      <para>
       The fnic kernel module is now part of the main kernel package.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>kvm-kmp</term>
     <listitem>
      <para>
       The KVM kernel modules are now part of the main kernel package.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>java-1_6_0-ibm-x86</term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
   </variablelist>
  </section>
  <section id="Deprecated.rmwith11">
   <title>Packages Removed with SUSE Linux Enterprise Server 11</title>
   <para>
    The following packages were removed with the major release of SUSE Linux
    Enterprise Server 11:
   </para>
   <variablelist>
    <varlistentry>
     <term>dante</term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>JFS</term>
     <listitem>
      <para>
       The JFS file system is no longer supported and the utilities have
       been removed from the distribution.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
<!-- bnc#733037 -->
<!-- bnc#757044 -->
     <term>EVMS</term>
     <listitem>
      <para>
       Replaced with LVM2.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>ippl</term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>powertweak</term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>SUN Java</term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>uw-imapd</term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>mapped-base Functionality</term>
     <listitem>
      <para>
       The mapped-base functionality, which is used by 32-bit applications
       that need a larger dynamic data space (such as database management
       systems), has been replaced with flexmap.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>zmd</term>
     <listitem>
      <para/>
     </listitem>
    </varlistentry>
   </variablelist>
  </section>
  <section id="Deprecated.future">
   <title>Packages and Features to Be Removed in the Future</title>
   <para>
    The following packages and features are deprecated and will be removed
    with the next Service Pack or major release of SUSE Linux Enterprise
    Server:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      The <command>reiserfs</command> file system is fully supported for the
      lifetime of SUSE Linux Enterprise Server 11 specifically for
      migration purposes. We will however remove support for creating new
      reiserfs file systems starting with SUSE Linux Enterprise Server 12.
     </para>
    </listitem>
    <listitem>
     <para>
      The <systemitem class="resource">sendmail</systemitem> package is
      deprecated and might be discontinued with SUSE Linux Enterprise
      Server 12.
     </para>
    </listitem>
    <listitem>
     <para>
      The <systemitem class="resource">lprng</systemitem> package is
      deprecated and will be discontinued with SUSE Linux Enterprise
      Server 12.
     </para>
    </listitem>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=829664 -->
    <listitem>
     <para>
      The <systemitem class="resource">dhcpv6</systemitem> package is
      deprecated and will be discontinued with SUSE Linux Enterprise
      Server 12.
     </para>
    </listitem>
    <listitem>
     <para>
      The <systemitem class="resource">qt3</systemitem> package is
      deprecated and will be discontinued with SUSE Linux Enterprise
      Server 12.
     </para>
    </listitem>
<!-- FATE##312973: Stop L3 support for Openswan (replaced by strongSwan) -->
<!--
  <listitem>
   <para>
    The <systemitem class="resource">openswan</systemitem> and
    <systemitem class="resource">strongswan</systemitem> packages will
    be consolidated.
   </para>
  </listitem>
-->
    <listitem>
     <para>
      <systemitem class="resource">syslog-ng</systemitem> will be replaced
      with <systemitem class="resource">rsyslog</systemitem>.
     </para>
    </listitem>
    <listitem>
     <para>
      The <systemitem class="resource">smpppd</systemitem> package is
      deprecated and will be discontinued with one of the next Service Packs
      or SUSE Linux Enterprise Server 12.
     </para>
    </listitem>
    <listitem>
     <para>
      The raw block devices (major 162) are deprecated and will be
      discontinued with one of the next Service Packs or SUSE Linux
      Enterprise Server 12.
     </para>
    </listitem>
<!--  https://bugzilla.novell.com/show_bug.cgi?id=518491 -->
<!-- Now in Fate#312764, updated
<listitem>
    <para>
    IBM Java 1.4.2 is supported with &sles; 11 specifically for migration purposes. We will however remove support for this specific Java version with &sles; 12 latest.
    </para>
  </listitem>
  -->
   </itemizedlist>
  </section>
 </chapter>
 <chapter id="InfraPackArch">
  <title>Infrastructure, Package and Architecture Specific Information</title>
  <section id="InfraPackArch.SystemManagement" remap="InfraPackArch:SystemManagement">
   <title>Systems Management</title>
<!-- bnc#747605 -->
<!-- bnc#852291: fixed with SP3 -->
<!--
 <section>
  <title>YaST Repair Tool Limitation</title>
  <para>
   The YaST Repair Tool as available from the boot medium does not
   detect pseudo devices like <filename>/dev/btrfs</filename> and writes
   a warning about missing partitions instead.
  </para>
  <para>
   You should skip the repair of such a device, because for such pseudo
   devices the availability of a partition is not expected.
  </para>
 </section>
 -->
<!-- bnc#477469 -->
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-315162" remap="InfraPackArch:SystemManagement">
<!-- sort_key="None"; non-rn-fate-cats="Infiniband,Network,YaST"; -->
<!-- href="https://fate.novell.com/315162" -->
    <title>YaST: IPoIB Mode Configuration</title>
    <para>
     In YaST, an IPoIB mode configuration is available.
    </para>
   </section>
   <section role="notoc" id="fate-314994" remap="InfraPackArch:SystemManagement">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/314994" -->
    <title>Zypper: new option that shows enabled repo</title>
    <para>
     A new option <literal>lr</literal> is available for
     <literal>zypper</literal> to show enabled repositories.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>Modified Operation against Novell Customer Center</title>
    <para>
     Effective on 2009-01-13, provisional registrations have been disabled
     in the Novell Customer Center. Registering an instance of SUSE Linux
     Enterprise Server or Open Enterprise Server (OES) products now requires
     a valid, entitled activation code. Evaluation codes for reviews or
     proofs of concept can be obtained from the product pages and from the
     download pages on novell.com.
    </para>
    <para>
     If a device is registered without a code at setup time, a provisional
     code is assigned to it by Novell Customer Center (NCC), and it will be
     entered in your NCC list of devices. No update repositories are
     assigned to the device at this time.
    </para>
    <para>
     Once you are ready to assign a code to the device, start the YaST
     Novell Customer Center registration module and replace the unentitled
     provisional code that NCC generated with the appropriate one to fully
     entitle the device and activate the related update repositories.
    </para>
   </section>
<!-- bnc#477469 -->
   <section>
    <title>Operation against Subscription Management Tool</title>
    <para>
     Operation under the Subscription Management Tool (SMT) package and
     registration proxy is not affected. Registration against SMT will
     assign codes automatically from your default pool in NCC until all
     entitlements have been assigned. Registering additional devices once
     the pool is depleted will result in the new device being assigned a
     provisional code (with local access to updates) The SMT server will
     notify the administrator that these new devices need to be entitled.
    </para>
   </section>
   <section>
    <title>Minimal Pattern</title>
    <para>
     The minimal pattern provided in YaST's Software Selection dialog
     targets experienced customers and should be used as a base for your own
     specific software selections.
    </para>
    <para>
     Do not expect a minimal pattern to provide a useful basis for your
     business needs without installing additional software.
    </para>
    <para>
     This pattern does not include any dump or logging tools. To fully
     support your configuration, Novell Technical Services (NTS) will
     request installation of all tools needed for further analysis in case
     of a support request.
    </para>
   </section>
<!-- bnc#448734 comment#2-->
<!-- bnc#486449 -->
<!-- deleted, behlert via mail 2015-06-10
  <section>
   <title>SPident</title>

   <para>
    SPident is a tool to identify the Service Pack level of the current
    installation. On &sles; 11 GA, this tool has been replaced by the
    new SAM tool (package "suse-sam").
   </para>
   </section>
   -->
  </section>
  <section id="InfraPackArch.Performance">
   <title>Performance Related Information</title>
<!-- bnc#475311 -->
   <section>
    <title>Linux Completely Fair Scheduler Affects Java Performance</title>
    <para>
     Problem (Abstract)
    </para>
    <para>
     Java applications that use synchronization extensively might perform
     poorly on Linux systems that include the Completely Fair Scheduler. If
     you encounter this problem, there are two possible workarounds.
    </para>
    <para>
     Symptom
    </para>
    <para>
     You may observe extremely high CPU usage by your Java application and
     very slow progress through synchronized blocks. The application may
     appear to hang due to the slow progress.
    </para>
    <para>
     Cause
    </para>
    <para>
     The Completely Fair Scheduler (CFS) was adopted into the mainline Linux
     kernel as of release 2.6.23. The CFS algorithm is different from
     previous Linux releases. It might change the performance properties of
     some applications. In particular, CFS implements sched_yield()
     differently, making it more likely that a thread that yields will be
     given CPU time regardless.
    </para>
    <para>
     The new behavior of sched_yield() might adversely affect the
     performance of synchronization in the IBM JVM.
    </para>
    <para>
     Environment
    </para>
    <para>
     This problem may affect IBM JDK 5.0 and 6.0 (all versions) running on
     Linux kernels that include the Completely Fair Scheduler, including
     Linux kernel 2.6.27 in SUSE Linux Enterprise Server 11.
    </para>
    <para>
     Resolving the Problem
    </para>
    <para>
     If you observe poor performance of your Java application, there are two
     possible workarounds:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Either invoke the JVM with the additional argument
       <option>"-Xthr:minimizeUserCPU"</option>.
      </para>
     </listitem>
     <listitem>
      <para>
       Or configure the Linux kernel to use the more backward-compatible
       heuristic for sched_yield() by setting the sched_compat_yield tunable
       kernel property to <option>1</option>. For example:
      </para>
<screen>echo "1" &gt; /proc/sys/kernel/sched_compat_yield</screen>
     </listitem>
    </itemizedlist>
    <para>
     You should not use these workarounds unless you are experiencing poor
     performance.
    </para>
   </section>
<!-- bnc#476996 -->
   <section>
    <title>Tuning Performance of Simple Database Engines</title>
    <para>
     Simple database engines like Berkeley DB use memory mappings (mmap(2))
     to manipulate database files. When the mapped memory is modified, those
     changes need to be written back to disk. In SUSE Linux Enterprise 11,
     the kernel includes modified mapped memory in its calculations for
     deciding when to start background writeback and when to throttle
     processes which modify additional memory. (In previous versions, mapped
     dirty pages were not accounted for and the amount of modified memory
     could exceed the overall limit defined.) This can lead to a decrease in
     performance; the fix is to increase the overall limit.
    </para>
    <para>
     The maximum amount of dirty memory is 40% in SUSE Linux Enterprise 11
     by default. This value is chosen for average workloads, so that enough
     memory remains available for other uses. The following settings may be
     relevant when tuning for database workloads:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       vm.dirty_ratio
      </para>
      <para>
       Maximum percentage of dirty system memory (default 40).
      </para>
     </listitem>
     <listitem>
      <para>
       vm.dirty_background_ratio
      </para>
      <para>
<!-- confirmation in bnc#805838 that that's "10". -->
       Percentage of dirty system memory at which background writeback will
       start (default 10).
      </para>
     </listitem>
     <listitem>
      <para>
       vm.dirty_expire_centisecs
      </para>
      <para>
       Duration after which dirty system memory is considered old enough to
       be eligible for background writeback (in centiseconds).
      </para>
     </listitem>
    </itemizedlist>
    <para>
     These limits can be observed or modified with the sysctl utility (see
     sysctl(1) and sysctl.conf(5)).
    </para>
   </section>
<!-- bnc#458698 -->
<!-- https://bugzilla.novell.com/show_bug.cgi?id=458698#c47 -->
<!--
        <listitem>
                <para>Virtualization and AACRAID controllers</para>
                <para>When running fully virtualized &sles; 11 guests on systems with AACRAID
controllers, sparse-backed files should not be used, as this might result in
significant performance loss.</para>
</listitem>
-->
<!-- FATE#302085 bnc#467688 -->
<!-- disabled by ihno 2010/04/12
<listitem>
        <para>Memory controller (cgroup) is disabled by default</para>
        <para>Memory cgroup is runtime-disabled by default in &sles; 11 due to speed
        regressions introduced by this facility. Please pass
        "cgroup_enable=memory" to the kernel command line to have this enabled.
</para>
</listitem>
-->
  </section>
  <section id="InfraPackArch.Storage" remap="InfraPackArch:Storage">
   <title>Storage</title>
<!-- bnc#828888 -->
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-318330" remap="InfraPackArch:Storage">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization"; -->
<!-- href="https://fate.novell.com/318330" -->
    <title>SUSE Enterprise Storage (Powered by Ceph) Client</title>
    <para>
     SUSE Linux Enterprise Server 11 SP3 and SP4 now provides the
     functionality to act as a client for SUSE Enterprise Storage. qemu can
     now use storage provided by the SUSE Enterprise Storage Ceph cluster
     via the RADOS Block Device (rbd) backend. Applications can now be
     enhanced to directly incorporate object or block storage backed by the
     SUSE Enterprise Storage cluster, by linking with the librados and
     librbd client libraries.
    </para>
    <para>
     Also included is the rbd tool to manage RADOS block devices mapped via
     the rbd kernel module, for use as a standard generic block device.
    </para>
   </section>
   <section role="notoc" id="fate-316592" remap="InfraPackArch:Storage">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316592" -->
    <title>Enable set_4k_mtu in Mellanox for All ConnectX Ports</title>
    <para>
     The mlx4_ib Infiniband module allows for dynamic mtu configuration
     through a new, <literal>per-port sysfs</literal> entry.
    </para>
    <para>
     The mtu may be set per port via the following sysfs entry:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       /sys/class/infiniband/mlx4_{x}/device/mlx4_port{y}_mtu
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Here {x} is the HCA number, and {y} is the port number on the HCA
    </para>
    <para>
     When writing a value to this sysfs entry, five values are allowed:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       256
      </para>
     </listitem>
     <listitem>
      <para>
       512
      </para>
     </listitem>
     <listitem>
      <para>
       1024
      </para>
     </listitem>
     <listitem>
      <para>
       2048
      </para>
     </listitem>
     <listitem>
      <para>
       4096
      </para>
     </listitem>
    </itemizedlist>
    <para>
     All other values will result in an error.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>Multipath Configuration Change</title>
    <para>
     With the update to version 0.4.9 on SLES 11 SP2,
     <literal>rr_min_io</literal> is replaced by
     <literal>rr_min_io_rq</literal> in <filename>multipath.conf</filename>.
     The old option is now ignored. Check this setting, if you encounter
     performance issues.
    </para>
    <para>
     For more information, see the <quote>Storage Administration
     Guide</quote> shipped with SLES 11 SP3.
    </para>
   </section>
<!-- bnc#827016 -->
   <section>
    <title>Capturing kdump on a Target using Device Mapper (Incl. Multipath)</title>
    <para>
     If the root device is <emphasis>not</emphasis> using device mapper
     (multipath), as a workaround add additional parameters to
     <literal>KDUMP_COMMANDLINE_APPEND</literal> in
     <filename>/etc/sysconfig/kdump</filename>, to capture kdump on a target
     that is using device mapper (multipath):
    </para>
<screen>KDUMP_COMMANDLINE_APPEND="root_no_dm=1 root_no_mpath=1"</screen>
    <para>
     Then start the kdump service.
    </para>
    <para>
     If you use multipath for both root and kdump, these options must not be
     added.
    </para>
    <para>
     An example use case with System z could be a kdump target on multipath
     zfcp-attached SCSI devices and a root file system on DASD.
    </para>
   </section>
<!-- bnc#778116 -->
<!--
 <section>
  <title>Loop-mounting NFS Shares</title>

  <para>
   Loop-mounting NFS shares is supported only in SAP environments,
   and only within the strict limits described in the Whitepaper at
   /URL/.  This support is valid for SLES and SLES for SAP
   Applications.
  </para>
 </section>
 -->
<!-- bnc#475565 -->
   <section>
    <title>Multipathing: SCSI Hardware Handler</title>
    <para>
     Some storage devices, e.g. IBM DS4K, require special handling for path
     failover and fallback. In SUSE Linux Enterprise Server 10 SP2, dm
     layer served as hardware handler.
    </para>
    <para>
     One drawback of this implementation was that the underlying SCSI layer
     did not know about the existence of the hardware handler. Hence, during
     device probing, SCSI would send I/O on the passive path, which would
     fail after a timeout and also print extraneous error messages in the
     console.
    </para>
    <para>
     In SUSE Linux Enterprise Server 11, this problem is resolved by moving
     the hardware handler to the SCSI layer, hence the term SCSI Hardware
     Handler. These handlers are modules created under the SCSI directory in
     the Linux Kernel.
    </para>
    <para>
     In SUSE Linux Enterprise Server 11, there are four SCSI Hardware
     Handlers: <literal>scsi_dh_alua</literal>,
     <literal>scsi_dh_rdac</literal>, <literal>scsi_dh_hp_sw</literal>,
     <literal>scsi_dh_emc</literal>.
    </para>
    <para>
     These modules need to be included in the initrd image so that SCSI
     knows about the special handling during probe time itself.
    </para>
    <para>
     To do so, carry out the following steps:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Add the device handler modules to the
       <literal>INITRD_MODULES</literal> variable in
       <filename>/etc/sysconfig/kernel</filename>
      </para>
     </listitem>
     <listitem>
      <para>
       Create a new initrd with:
      </para>
<screen>mkinitrd -k /boot/vmlinux-&lt;flavour&gt; \
-i /boot/initrd-&lt;flavour&gt;-scsi_dh \
-M /boot/System.map-&lt;flavour&gt;</screen>
     </listitem>
     <listitem>
      <para>
       Update the <filename>grub.conf/lilo.conf/yaboot.conf</filename> file
       with the newly built initrd.
      </para>
     </listitem>
     <listitem>
      <para>
       Reboot.
      </para>
     </listitem>
    </itemizedlist>
   </section>
<!-- bnc#485183 -->
<!-- bnc#750625: obsolete -->
<!--
   <title>Multipathing: Failed Paths Do Not Return after a Path Failure.</title>
   -->
<!-- relnotes.i.iSCSI-OCFS2 -->
   <section>
    <title>Local Mounts of iSCSI Shares</title>
    <para>
     An iSCSI shared device should never be mounted directly on the local
     machine. In an OCFS2 environment, doing so causes all hardware to hard
     hang.
    </para>
   </section>
  </section>
  <section id="InfraPackArch.HyperV">
   <title>Hyper-V</title>
   <section>
<!-- bnc#822523 -->
<!-- Also valid for SLE12:
      https://bugzilla.novell.com/show_bug.cgi?id=822523#c53
 -->
    <title>Hyper-V: Time Synchronization</title>
    <para>
     The system time of a guest will drift several seconds per day.
    </para>
    <para>
     To maintain an accurate system time it is recommended to run
     <command>ntpd</command> in a guest. The ntpd daemon can be configured
     with the YaST "NTP Client" module. In addition to such a configuration,
     the following two variables must be set manually to
     "<literal>yes</literal>" in <filename>/etc/sysconfig/ntp</filename>:
    </para>
<screen>NTPD_FORCE_SYNC_ON_STARTUP="yes"
NTPD_FORCE_SYNC_HWCLOCK_ON_STARTUP="yes"</screen>
   </section>
<!-- bnc#732997 -->
<!-- fixed on RC2
  <listitem>
   <para>
    Known Issues
   </para>
   <para>
    Installation on the Btrfs filesystem or on LVM volumes in the guest
    is currently not supported; it will lead to a crash in the guest. It
    is recommended to use ext3 as the root filesystem instead.
   </para>
   <para>
    Also an update from SLES 11 SP1 to SLES 11 SP2 will fail, if the
    root filesystem is on LVM.
   </para>
  </listitem>
  -->
   <section>
    <title>Change of Kernel Device Names in Hyper-V Guests</title>
    <para>
     Starting with SP2, SLES 11 has a newer block device driver, which
     presents all configured virtual disks as SCSI devices. Disks, which
     used to appear as <filename>/dev/hda</filename> in SLES 11 SP1 will
     from now on appear as <filename>/dev/sda</filename>.
    </para>
   </section>
   <section>
    <title>Using the "Virtual Machine Snapshot" Feature</title>
    <para>
     The Windows Server Manager GUI allows to take snapshots of a Hyper-V
     guest. After a snapshot is taken the guest will fail to reboot. By
     default, the guest's root file system is referenced by the serial
     number of the virtual disk. This serial number changes with each
     snapshot. Since the guest expects the initial serial number, booting
     will fail.
    </para>
    <para>
     The solution is to either delete all snapshots using the Windows GUI,
     or configure the guest to mount partitions by file system UUID. This
     change can be made with the YaST partitioner and boot loader
     configurator.
    </para>
   </section>
<!-- bnc#754041 -->
<!-- 2013-05-13: obsolete on SP3 (ohering) -->
<!-- <title>Formatting Large Disk Partitions on Windows 8 Server</title> -->
  </section>
  <section id="InfraPackArch.ArchIndependent">
   <title>Architecture Independent Information</title>
   <section id="InfraPackArch.ArchIndependent.Package" remap="InfraPackArch:ArchIndependent:Package">
    <title>Changes in Packaging and Delivery</title>
<!--v Items below imported from FATE-->
    <section role="notoc" id="fate-318340" remap="InfraPackArch:ArchIndependent:Package">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318340" -->
     <title>Updating tcsh</title>
     <para>
      tcsh 6.15 has a locking issue when used concurrently.
     </para>
     <para>
      On SLE 11 SP3, SUSE updated tcsh to version 6.18 to solve a locking
      issue when used concurrently.
     </para>
    </section>
    <section role="notoc" id="fate-318115" remap="InfraPackArch:ArchIndependent:Package">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318115" -->
     <title>New Ruby Packaging Scheme with the Update to Ruby 1.8</title>
     <para>
      The different Ruby package versions cannot clearly be handled on one
      system with the old packaging scheme. To help packagers with the new
      scheme introduced with SLE 12, two new scripts in the ruby package
      helps to find the correct version suffix for new packages.
     </para>
     <para>
      This improvement is now available as a backport in SLE 11 SP4, too.
     </para>
    </section>
    <section role="notoc" id="fate-317817" remap="InfraPackArch:ArchIndependent:Package">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317817" -->
     <title>New Package: vhostmd / vm-dump-metrics</title>
     <para>
      vhostmd (Virtual Host Metrics Daemon) allows virtual machines to see
      limited information about the host they are running on.
      vm-dump-metrics runs inside the guest to dump the host metrics.
     </para>
    </section>
    <section role="notoc" id="fate-317625" remap="InfraPackArch:ArchIndependent:Package">
<!-- sort_key="None"; non-rn-fate-cats="Cloud,Virtualization"; -->
<!-- href="https://fate.novell.com/317625" -->
     <title>New Package: cloud-init</title>
     <para>
      cloud-init is the de facto package that handles early initialization
      of a cloud instance.
     </para>
     <para>
      To install it, enable the repository of the Public Cloud Module.
     </para>
    </section>
    <section role="notoc" id="fate-317600" remap="InfraPackArch:ArchIndependent:Package">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317600" -->
     <title>Update to IBM Java 7 Release 1 (1.7.1)</title>
     <para>
      The only supported_ IBM Java on SLES 11 SP4 is version 7 Release 1 (<literal>java-1_7_1-ibm</literal>).
     </para>
     <para>
      IBM Java 7 Release 1 provides performance improvements through IBM
      POWER8 and IBM zEnterprise EC12 exploitation.
     </para>
    </section>
    <section role="notoc" id="fate-316603" remap="InfraPackArch:ArchIndependent:Package">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316603" -->
     <title>Support for 46bit Memory Addressing in makedumpfile and crash</title>
     <para>
      Starting with SP3, the makedumpfile and crash utilities can analyze
      memory dumps taken on systems with 46bit addresses.
     </para>
    </section>
<!--^ End of Items imported from FATE-->
    <section>
     <title>SUSE Linux Enterprise High Availability Extension 11</title>
     <para>
      With the <emphasis>SUSE Linux Enterprise High Availability Extension
      11</emphasis>, SUSE offers the most modern open source High
      Availability Stack for Mission Critical environments.
     </para>
    </section>
<!-- Document, how to switch off cgroups/mem bnc#587832 -->
    <section>
     <title>Kernel Has Memory Cgroup Support Enabled By Default</title>
     <para>
      While this functionality is welcomed in most environments, it requires
      about 1% of memory. Memory allocation is done at boot time and is
      using 40 Bytes per 4 KiB page which results in 1% of memory.
     </para>
     <para>
      In virtualized environments, specifically but not exclusively on s390x
      systems, this may lead to a higher basic memory consumption: e.g., a
      20GiB host with 200 x 1GiB guests consumes 10% of the real memory.
     </para>
     <para>
      This memory is not swappable by Linux itself, but the guest cgroup
      memory is pageable by a z/VM host on an s390x system and might be
      swappable on other hypervisors as well.
     </para>
     <para>
      Cgroup memory support is activated by default but it can be
      deactivated by adding the Kernel Parameter
      <literal>cgroup_disable=memory</literal>
     </para>
     <para>
      A reboot is required to deactivate or activate this setting.
     </para>
    </section>
    <section>
<!-- bnc#661511 -->
     <title>Kernel Development Files Moved to Individual kernel-$flavor-devel Packages</title>
     <para>
      Up to SLE 11 GA, the kernel development files
      (<filename>.config</filename>, <filename>Module.symvers</filename>,
      etc.) for all flavors were packaged in a single kernel-syms package.
      Starting with SLE 11 SP1, these files are packaged in individual
      kernel-$flavor-devel packages, allowing to build KMPs for only the
      required kernel flavors. For compatibility with existing spec files,
      the kernel-syms package still exists and depends on the individual
      kernel-$flavor-devel packages.
     </para>
    </section>
<!-- KVM guest migration bnc#580412 -->
    <section>
     <title>Live Migration of KVM Guest with Device Hot-Plugging</title>
     <para>
      Hot-plugging a device (network, disk) works fine for a KVM guest on a
      SLES 11 host since SP1. However, migrating the same guest with the
      hotplugged device (available on the destination host) fails.
     </para>
     <para>
      Since SLES 11 SP1, supports the hotplugging of the device to the KVM
      guest, but migrating the guest with the hot-plugged device is not
      supported and expected to fail.
     </para>
    </section>
   </section>
   <section id="InfraPackArch.ArchIndependent.Security" remap="InfraPackArch:ArchIndependent:Security">
    <title>Security</title>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c27 -->
<!--v Items below imported from FATE-->
    <section role="notoc" id="fate-320344" remap="InfraPackArch:ArchIndependent:Security">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/320344" -->
     <title>KMS Graphics Drivers for Matrox G200, AST and Cirrus Chips</title>
     <para>
      On SLE11-SP3 and SP4, the kernel graphics mode setting (KMS) for
      Matrox G200, AST, and Cirrus graphics devices are enabled only in
      Secure Boot mode. Although these kernel driver modules are loaded
      automatically at boot, they will not be enabled and signal some kernel
      warning message. This is intentional behavior, and nothing to worry
      about.
     </para>
     <para>
      The graphics on these devices is supported well via the X11 user mode
      setting driver (UMS). This driver is even more stable and functional
      than KMS for the SLE 11 code base.
     </para>
     <para>
      In secure boot, due to its device locking for security reason, UMS
      driver cannot get direct access to the hardware. Hence KMS mode is
      applied fore secure boot instead.
     </para>
     <para>
      If you still want to use KMS instead of UMS in non-secure boot mode,
      pass modeset=1 option to each kernel driver (mgag200, ast, or cirrus,
      respectively). For example for Matrox, pass this boot option:
     </para>
<screen>mgag200.modeset=1</screen>
    </section>
    <section role="notoc" id="fate-320164" remap="InfraPackArch:ArchIndependent:Security">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/320164" -->
     <title>Enabling TLS 1.2 Support for wget</title>
     <para>
      The wget tool as shipped in SUSE Linux Enterprise 11 only supports
      SSL/TLS up to TLS 1.0.
     </para>
     <para>
      Current requirements and websites prefer and recommend to use TLS 1.2.
     </para>
     <para>
      As wget uses the old openssl 0.9.8j, which does not support TLS 1.2.
     </para>
     <para>
      A separate version of wget with the RPM name wget-openssl1 is supplied
      in the SUSE Linux Enterprise 11 SECURITY Module.
     </para>
     <para>
      it can be installed in parallel to the regular wget version.
     </para>
     <para>
      it includes a binary /usr/bin/wget.openssl1 which could be called
      directly.
     </para>
     <para>
      It also can be used as /usr/bin/wget replacement. For this we use
      "update-alternatives" to select the wget implementation.
     </para>
     <para>
      To switch /usr/bin/wget to use openssl 1.0.1 and so support TLS 1.2 in
      HTTPS connections use:
     </para>
<screen>update-alternatives --set wget /usr/bin/wget.openssl1</screen>
     <para>
      to switch back, use:
     </para>
<screen>update-alternatives --set wget /usr/bin/wget.openssl0</screen>
     <para>
      to display the current state use:
     </para>
<screen>update-alternatives --display wget</screen>
    </section>
    <section role="notoc" id="fate-319043" remap="InfraPackArch:ArchIndependent:Security">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319043" -->
     <title>openldap2-client 2.4: New Options</title>
     <para>
      These new options are especially noteworthy:
     </para>
     <orderedlist>
      <listitem>
       <para>
        Specify the handshake protocol and the strength of minimally
        acceptable SSL/TLS ciphers for the operation of OpenLDAP server.
       </para>
      </listitem>
      <listitem>
       <para>
        Specify the handshake protocol and the strength of proposed SSL/TLS
        ciphers for the operation of OpenLDAP client.
       </para>
      </listitem>
     </orderedlist>
     <para>
      <emphasis>General information:</emphasis>
     </para>
     <para>
      The parameter "TlsParameterMin" helps both use cases. The parameter
      value controls both handshake protocol and cipher strength. The
      interpretation of the value by server and client is identical, however
      the parameter name appears differently in server's and client's
      configuration files.
     </para>
     <para>
      The value format is "X.Y" where X and Y are single digits:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        If X is 2, handshake is SSLv2, the usable ciphers are SSLv2 and up.
       </para>
      </listitem>
      <listitem>
       <para>
        If X is 3, handshake is TLSv1.0 (SLES 11) or TLSv1.2 (SLES 12), the
        usable ciphers are TLSv1.(Y-1) and up.
       </para>
      </listitem>
     </itemizedlist>
     <para>
      <emphasis>Examples:</emphasis>
     </para>
     <itemizedlist>
      <listitem>
       <para>
        2.0 - Handshake is SSLv2, usable ciphers are SSLv2, SSLv3, and
        TLSv1.x
       </para>
      </listitem>
      <listitem>
       <para>
        2.1 - Same as above
       </para>
      </listitem>
      <listitem>
       <para>
        3.1 - Handshake is TLSv1.0 (SLES 11), usable ciphers are SSLv3 and
        up.
       </para>
      </listitem>
      <listitem>
       <para>
        3.2 - Handshake is TLSv1.0 (SLES 11), usable ciphers are TLSv1.1 and
        up.
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Important: OpenSSL identifies TLSv1.0 ciphers as "SSLv3", if the
      parameter value prohibits SSLv3 operation, then TLSv1.0 ciphers will
      be rejected too, and vice versa.
     </para>
     <para>
      Use case 1:
     </para>
     <para>
      Supported by SLES 12 only. SLES 11 is too old to support this use
      case. Add parameter TLSProtocolMin to slapd.conf and restart server.
     </para>
     <para>
      <emphasis>Example</emphasis> - reject SSLv2 handshake, accept TLSv1.0
      handshake and TLSv1.x ciphers:
     </para>
<screen>TLSProtocolMin 3.1</screen>
     <para>
      Use case 2:
     </para>
     <para>
      Supported by both SLE 12 and SLE 11 server and desktop products. Add
      parameter TLS_PROTOCOL_MIN to either /etc/openldap/ldap.conf or
      ~/.ldaprc.
     </para>
     <para>
      <emphasis>Example</emphasis> - do not use SSLv2 handshake, use TLSv1.0
      handshake, and propose SSLv3 and TLSv1.x ciphers:
     </para>
<screen>TLS_PROTOCOL_MIN 3.1</screen>
     <para>
      <emphasis>Debug tips for Client operation:</emphasis>
     </para>
     <para>
      Run ldap client programs with debug level 5 (-d 5) will trace TLS
      operations. Be aware that OpenSSL will misleadingly print this
      message:
     </para>
<screen>SSL_connect:SSLv2/v3 write client hello A</screen>
     <para>
      which apparently suggests the usage of SSLv2, but in fact OpenSSL has
      not decided on the handshake protocol yet!
     </para>
     <para>
      <emphasis>References:</emphasis>
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Original feature commit by OpenLDAP developers:
        <ulink url="https://bugs.openldap.org/show_bug.cgi?id=5655"/>
       </para>
      </listitem>
      <listitem>
       <para>
        OpenLDAP client configuration manual:
        <ulink url="http://man7.org/linux/man-pages/man5/ldap.conf.5.html"/>
       </para>
      </listitem>
      <listitem>
       <para>
        OpenLDAP server configuration manual (note the lack of
        TlsProtocolMin usage instruction):
        <ulink url="https://www.openldap.org/doc/admin24/tls.html"/>
       </para>
      </listitem>
     </itemizedlist>
    </section>
    <section role="notoc" id="fate-318998" remap="InfraPackArch:ArchIndependent:Security">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318998" -->
     <title>Kdump Over Network Via SSH</title>
     <para>
      For improved security, the following steps are now required:
     </para>
     <orderedlist>
      <listitem>
       <para>
        Add the root user's public key to the dump user's
        <literal>authorized_keys</literal> on the target machine.
       </para>
      </listitem>
      <listitem>
       <para>
        If the target machine's host key is not in machine's
        <literal>known_hosts</literal> file, the following additional steps
        are required:
       </para>
      </listitem>
      <listitem>
       <para>
        Add the target machine's host key to the dump machine's
        <literal>known_hosts</literal> file.
       </para>
      </listitem>
      <listitem>
       <para>
        Re-generate the kdump initrd (<literal>mkdumprd -f</literal>).
       </para>
      </listitem>
      <listitem>
       <para>
        Restart kdump (<literal>rckdump restart</literal>).
       </para>
      </listitem>
     </orderedlist>
    </section>
    <section role="notoc" id="fate-318874" remap="InfraPackArch:ArchIndependent:Security">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318874" -->
     <title>ECDSA Support for kdump Over SSH</title>
     <para>
      When saving kernel dumps over SSH, kdump has relied on an external
      library (libssh2). This library only supports RSA and DSA keys. The
      default SSH key type in SLE 11 SP4 is ECDSA, which is not supported by
      libssh2. Consequently, if a SUSE Linux Enterprise product is installed
      on the target machine, the admin must configure it with one of the
      supported ciphers.
     </para>
     <para>
      Kernel dumping now uses the "ssh" binary to establish the connection.
      This automatically enables all ciphers and key exchange protocols that
      are supported by the openssh2 package, including forthcoming
      additions.
     </para>
    </section>
    <section role="notoc" id="fate-318862" remap="InfraPackArch:ArchIndependent:Security">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318862" -->
     <title>OpenSSL Version 1 Enabled OpenSSH</title>
     <para>
      The SUSE Linux Enterprise 11 version of OpenSSH does not support
      AES-GCM ciphers.
     </para>
     <para>
      We now provide a OpenSSH version built against OpenSSL 1, which
      supports AES-GCM ciphers, a modern and commonly used and required
      cipher.
     </para>
     <para>
      The package is called "openssh-openssl1" and is contained in the SLE
      11 Security module, which needs to be enabled separately.
     </para>
    </section>
    <section role="notoc" id="fate-314496" remap="InfraPackArch:ArchIndependent:Security">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/314496" -->
     <title>New Symlink and Hardlink Security Restrictions</title>
     <para>
      A number of security breaches is based on symlink and hardlink
      exploitation.
     </para>
     <para>
      To increase the system robustness, restrictions on link creation have
      been implemented in the operating system kernel. The kernel permits
      symlinks to only be followed when outside of a sticky world-writable
      directory, or when the uid of the symlink and follower match, or when
      the directory owner matches the symlink's owner. The mechanism can be
      switched off by the system administrator by setting the
      <literal>fs.protected_hardlinks</literal> and
      <literal>fs.protected_symlinks</literal> sysctl parameters to 0.
     </para>
    </section>
<!--^ End of Items imported from FATE-->
    <section>
     <title>Removable Media</title>
     <para>
      To allow a specific user (<quote>joe</quote>) to mount removable
      media, run the following command as root:
     </para>
<screen>polkit-auth --user joe \
--grant org.freedesktop.hal.storage.mount-removable
   </screen>
     <para>
      To allow all locally logged in users on the active console to mount
      removable media, run the following commands as root:
     </para>
<screen>echo 'org.freedesktop.hal.storage.mount-removable no:no:yes' \
  &gt;&gt; /etc/polkit-default-privs.local
/sbin/set_polkit_default_privs
</screen>
    </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c29  -->
    <section>
     <title>Verbose Audit Records for System User Management Tools</title>
     <para>
      Install the package "pwdutils-plugin-audit". To enable this plugin,
      add "audit" to <filename>/etc/pwdutils/logging</filename>. See the
      <quote>Security Guide</quote>
      <remark>emap: use entity?</remark>
      <remark>ke: not needed.</remark>
      for more information.
     </para>
    </section>
   </section>
   <section id="InfraPackArch.ArchIndependent.Network" remap="InfraPackArch:ArchIndependent:Network">
    <title>Networking</title>
<!--v Items below imported from FATE-->
    <section role="notoc" id="fate-322422" remap="InfraPackArch:ArchIndependent:Network">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/322422" -->
     <title>No Support for Samba as Active Directory-Style Domain Controller</title>
     <para>
      The version of Samba shipped with SLE 11 SP4 does not include support
      to operate as an Active Directory-style domain controller. This
      functionality is currently disabled, as it lacks integration with
      system-wide MIT Kerberos.
     </para>
    </section>
    <section role="notoc" id="fate-316898" remap="InfraPackArch:ArchIndependent:Network">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316898" -->
     <title>openssl1 Enablement</title>
     <para>
      Customers require TLS 1.2 support in the openssl1 library, partially
      for their own programs, but also for selected SUSE ones.
     </para>
     <para>
      We provide <literal>openssl1</literal> enablement packages in a
      separate repository.
     </para>
    </section>
    <section role="notoc" id="fate-316512" remap="InfraPackArch:ArchIndependent:Network">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/316512" -->
     <title>Improved Samba libsmbclient Support for Microsoft Distributed File System (DFS)</title>
     <para>
      libsmbclient previously resolved DFS referrals on every API call,
      always using the first entry in the referral response. With random DFS
      referral ordering, libsmbclient would often open a new server
      connection, rather than reusing an existing (cached) connection
      established from a previous DFS referred API call.
     </para>
     <para>
      <literal>libsmbclient</literal> now checks the connection cache for
      any of the DFS referral response entries before creating a new
      connection.
     </para>
    </section>
    <section role="notoc" id="fate-316419" remap="InfraPackArch:ArchIndependent:Network">
<!-- sort_key="None"; non-rn-fate-cats="Customer Request,Security"; -->
<!-- href="https://fate.novell.com/316419" -->
     <title>Providing TLS 1.2 Support for Apache2 Via mod_nss</title>
     <para>
      The Apache Web server offers HTTPS protocol support via mod_ssl, which
      in turn uses the openssl shared libraries. SUSE Linux Enterprise
      Server 11 SP2 and SP3 come with openssl version 0.9.8j. This openssl
      version supports TLS version up to and including TLSv1.0, support for
      newer TLS versions like 1.1 or 1.2 is missing.
     </para>
     <para>
      Recent recommendations encourage the use of TLSv1.2, specifically to
      support Perfect Forward Secrecy. To overcome this limitation, the SUSE
      Linux Enterprise Server 11 SP2, SP3, and SP4 are supplied with
      upgrades to recent versions of the mozilla-nss package and with the
      package apache2-mod_nss, which makes use of mozilla-nss for TLSv1.2
      support for the Apache Web server.
     </para>
     <para>
      An additional <literal>mod_nss</literal> module is supplied for
      <literal>apache2</literal>, which can coexist with all existing
      libraries and apache2 modules. This module uses the <literal>mozilla
      netscape security services</literal> library, which supports TLS 1.1
      and TLS 1.2 protocols. It is not a drop-in replacement; configuration
      and certificate storages are different. It can coexist with
      <literal>mod_ssl</literal> if necessary.
     </para>
     <para>
      The package includes a sample configuration and a README-SUSE.txt for
      setup guidance.
     </para>
    </section>
<!--^ End of Items imported from FATE-->
    <section>
     <title>Bind Update to Version 9.9</title>
<!-- href="https://fate.novell.com/308859" -->
<!-- bnc#831891 -->
     <para>
      <emphasis>The DNS Server Bind has been updated to the long term
      supported version 9.9 for longer stability going forward. In version
      9.9, the commands 'dnssec-makekeyset' and 'dnssec-signkey' are not
      available anymore.</emphasis>
     </para>
     <para>
      DNSSEC tools provided by Bind 9.2.4 are not compatible with Bind 9.9
      and later and have been replaced where applicable. Specifically,
      DNSSEC-bis functionality removes the need for dnssec-signkey(1M) and
      dnssec-makekeyset(1M); dnssec-keygen(1M) and dnssec-signzone(1M) now
      provide alternative functionality.
     </para>
     <para>
      For more information, see
      <ulink url="https://www.suse.com/support/kb/doc.php?id=7012684">TID
      7012684</ulink> (https://www.suse.com/support/kb/doc.php?id=7012684).
     </para>
    </section>
    <section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=832264 -->
     <title>Enabling NFS 4.1 for nfsd</title>
     <para>
      Support for NFS 4.1 is now available.
     </para>
     <para>
      The parameter <literal>NFS4_SERVER_MINOR_VERSION</literal> is now
      available in <filename>/etc/nfs/syconfig</filename> for setting the
      supported minor version of NFS 4.
     </para>
    </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=778116 -->
    <section>
     <title>Mounting NFS Volumes Locally on the Exporting Server</title>
     <para>
      Mounting NFS volumes locally on the exporting server is not supported
      on SUSE Linux Enterprise systems, as it is the case on all Enterprise
      class Linux systems.
     </para>
    </section>
<!--
  <section>
   <!-\- bnc#810756, ke 2013-03-21 -\->
   <!-\- commented, will come thru fate, 2013-03-25 -\->
   <title>Broadcom bnx2x Driver Limitation</title>
   <para>
    Only the initial SR-IOV Linux support is available. SR-IOV is
    planned to be supported in future SLES releases and with PLDP
    drivers.
   </para>
  </section>
-->
<!-- https://bugzilla.novell.com/show_bug.cgi?id=725246 -->
    <section>
     <title>Loading the mlx4_en Adapter Driver with the Mellanox ConnectX2 Ethernet Adapter</title>
     <para>
      There is a reported problem that the Mellanox ConnectX2 Ethernet
      adapter does not trigger the automatic load of the mlx4_en adapter
      driver. If you experience problems with the mlx4_en driver not
      automatically loading when a Mellanox ConnectX2 interface is
      available, create the file <filename>mlx4.conf</filename> in the
      directory <filename>/etc/modprobe.d</filename> with the following
      command:
     </para>
<screen>install mlx4_core /sbin/modprobe --ignore-install mlx4_core \
  &amp;&amp; /sbin/modprobe mlx4_en</screen>
    </section>
<!--  https://bugzilla.novell.com/show_bug.cgi?id=448734#c28 -->
    <section>
     <title>Using the System as a Router</title>
     <para>
      As long as the firewall is active, the option
      <filename>ip_forwarding</filename> will be reset by the firewall
      module. To activate the system as a router, the variable
      <filename>FW_ROUTE</filename> has to be set, too. This can be done
      through <command>yast2 firewall</command> or manually.
     </para>
    </section>
   </section>
   <section id="InfraPackArch.ArchIndependent.Cross">
    <title>Cross Architecture Information</title>
<!-- bnc#744314 -->
<!--   <section> -->
<!--    <title>ATI Radeon ES1000 Support</title> -->
<!--    <para> -->
<!--     ***CHECKIT -->
<!-- If upgrading from SP1 to SP2 on a system with an ATI Radeon ES1000 video -->
<!-- chip, there may be issues with the color palette when running Xorg.  To -->
<!-- avoid this issue, regenerate a new <filename>xorg.conf</filename> file -->
<!-- after the installation with: -->
<!--    </para> -->
<!--    <screen>sax2 -a -r</screen> -->
<!--    <para> -->
<!-- This will allow the Xorg vesa driver to control the video chip. -->
<!--    </para> -->
<!--   </section> -->
    <section>
     <title>Myricom 10-Gigabit Ethernet Driver and Firmware</title>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c47  -->
<!-- https://bugzilla.novell.com/show_bug.cgi?id=736148 -->
     <para>
      SUSE Linux Enterprise 11 (x86, x86_64 and IA64) is using the Myri10GE
      driver from mainline Linux kernel. The driver requires a firmware file
      to be present, which is not being delivered with SUSE Linux Enterprise
      11.
     </para>
     <para>
      Download the required firmware at
      <ulink url="https://www.cspi.com/"/>.
     </para>
    </section>
   </section>
  </section>
  <section id="InfraPackArch.x86_64_x86">
   <title>AMD64/Intel64 64-Bit (x86_64) and Intel/AMD 32-Bit (x86) Specific Information</title>
   <section id="InfraPackArch.x86_64_x86.System">
    <title>System and Vendor Specific Information</title>
    <section>
<!-- bnc#810756, ke 2013-03-21 and 2013-04-29 -->
<!-- bnc#819950, ke 2013-05-15 -->
     <title>Installation on 4KB Sector Drives Not Supported</title>
     <para>
      Legacy installations are not supported on 4KB sector drives that are
      installed in x86/x86_64 servers. (UEFI installations and the use of
      the 4KB sector disks as non-boot disks are supported).
     </para>
    </section>
    <section>
<!-- per mail, 2012-06-11 -->
<!-- https://bugzilla.novell.com/show_bug.cgi?id=872172
        link fix
   -->
     <title>Insecurity with XEN on Some AMD Processors</title>
     <para>
      This hardware flaw ("AMD Erratum #121") is described in "Revision
      Guide for AMD Athlon 64 and AMD Opteron Processors"
      (<ulink url="https://www.amd.com/system/files/TechDocs/25759.pdf"/>):
     </para>
     <para>
      The following 130nm and 90nm (DDR1-only) AMD processors are subject to
      this erratum:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        First-generation AMD-Opteron(tm) single and dual core processors in
        either 939 or 940 packages:
       </para>
       <itemizedlist>
        <listitem>
         <para>
          AMD Opteron(tm) 100-Series Processors
         </para>
        </listitem>
        <listitem>
         <para>
          AMD Opteron(tm) 200-Series Processors
         </para>
        </listitem>
        <listitem>
         <para>
          AMD Opteron(tm) 800-Series Processors
         </para>
        </listitem>
        <listitem>
         <para>
          AMD Athlon(tm) processors in either 754, 939 or 940 packages
         </para>
        </listitem>
        <listitem>
         <para>
          AMD Sempron(tm) processor in either 754 or 939 packages
         </para>
        </listitem>
        <listitem>
         <para>
          AMD Turion(tm) Mobile Technology in 754 package
         </para>
        </listitem>
       </itemizedlist>
      </listitem>
      <listitem>
       <para>
        This issue does not affect Intel processors.
       </para>
      </listitem>
     </itemizedlist>
     <para>
      As this is a hardware flaw, it can only be fixed by upgrading your
      hardware to a newer revision, or not allowing untrusted 64-bit guest
      systems, or accepting that someone stops your machine. The impact of
      this flaw is that a malicious PV guest user can halt the host system.
     </para>
     <para>
      The SUSE XEN updates will fix it via disabling the boot of XEN GUEST
      systems. The HOST will boot, just not start guests. In other words: If
      the update is installed on the above listed AMD64 hardware, the guests
      will no longer boot by default.
     </para>
     <para>
      To re-enable booting, the "<literal>allow_unsafe</literal>" option
      needs to be added to <literal>XEN_APPEND</literal> in
      <filename>/etc/sysconfig/bootloader</filename> as follows:
     </para>
<screen>XEN_APPEND="allow_unsafe"</screen>
    </section>
    <section>
     <title>Boot Device Larger than 2 TiB</title>
     <para>
      Due to limitations in the legacy x86/x86_64 BIOS implementations,
      booting from devices larger than 2 TiB is technically not possible
      using legacy partition tables (DOS MBR).
     </para>
     <para>
      Since SUSE Linux Enterprise Server 11 Service Pack 1 we support
      installation and boot using uEFI on the x86_64 architecture and
      certified hardware.
     </para>
    </section>
<!-- relnotes.g.i386-memory -->
    <section>
     <title>i586 and i686 Machines with More than 16 GB of Memory</title>
     <para>
      Depending on the workload, i586 and i686 machines with 16GB-48GB of
      memory can run into instabilities. Machines with more than 48GB of
      memory are not supported at all. Lower the memory with the
      <literal>mem=</literal> kernel boot option.
     </para>
     <para>
      In such memory scenarios, we strongly recommend using a x86-64 system
      with 64-bit SUSE Linux Enterprise Server, and run the (32-bit) x86
      applications on it.
     </para>
    </section>
<!-- bnc#721333 -->
    <section>
     <title>Directly Addressable Memory on x86 Machines</title>
     <para>
      When running SLES on an x86 machine, the kernel can only address 896MB
      of memory directly. In some cases, the pressure on this memory zone
      increases linearly according to hardware resources such as number of
      CPUs, amount of physical memory, number of LUNs and disks, use of
      multipath, etc.
     </para>
     <para>
      To workaround this issue, we recommend running an x86_64 kernel on
      such large server machines.
     </para>
    </section>
<!-- bnc#471221 -->
    <section>
     <title>NetXen 10G Ethernet Expansion Card on IBM BladeCenter HS12 System</title>
     <para>
      When installing SUSE Linux Enterprise Server 11 on a HS12 system with
      a "NetXen Incorporated BladeCenter-H 10 Gigabit Ethernet High Speed
      Daughter Card", the boot parameter <literal>pcie_aspm=off</literal>
      should be added.
     </para>
    </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c37 -->
    <section>
     <title>NIC Enumeration</title>
     <para>
      Ethernet interfaces on some hardware do not get enumerated in a way
      that matches the marking on the chassis.
     </para>
    </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c41 -->
<!-- AI:mge , asked ASadeghpour -->
<!-- https://bugzilla.novell.com/show_bug.cgi?id=826123 -->
    <section>
     <title>Service Pack for HP Linux ProLiant</title>
     <para>
      The hpilo driver is included in SUSE Linux Enterprise Server 11.
      Therefore, no hp-ilo package will be provided in the Linux ProLiant
      Service Pack for SUSE Linux Enterprise Server 11.
     </para>
     <para>
      For more details, see TID 7002735 at
      <ulink url="https://www.suse.com/support/kb/doc/?id=000016926"/>.
     </para>
    </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c41 -->
    <section>
     <title>HP High Performance Mouse for iLO Remote Console.</title>
     <para>
      The desktop in SUSE Linux Enterprise Server 11 now recognizes the HP
      High Performance Mouse for iLO Remote Console and is configured to
      accept and process events from it. For the desktop mouse and the HP
      High Performance Mouse to stay synchronized, it is necessary to turn
      off mouse acceleration. As a result, the HP iLO2 High-Performance
      mouse (hpmouse) package is no longer needed with SUSE Linux Enterprise
      Server 11 once one of the following three options are implemented.
     </para>
     <orderedlist>
      <listitem>
       <para>
        In a terminal run <literal>xset m 1</literal> — this setting will
        not survive a reset of the desktop.
       </para>
      </listitem>
      <listitem>
       <para>
        (Gnome) In a terminal run <literal>gconf-editor</literal> and go to
        desktop-&gt;gnome-&gt;peripherals-&gt;mouse. Edit the "motion
        acceleration" field to be 1.
       </para>
       <para>
        (KDE) Open "Personal Settings (Configure Desktop)" in the menu and
        go to "Computer
        Administration-&gt;Keyboard&amp;Mouse-&gt;Mouse-&gt;Advanced" and
        change "Pointer Acceleration" to 1.
       </para>
      </listitem>
      <listitem>
       <para>
        (Gnome) In a terminal run "gnome-mouse-properties" and adjust the
        "Pointer Speed" slide scale until the HP High Performance Mouse and
        the desktop mouse run at the same speed across the screen. The
        recommended adjustment is close to the middle, slightly on the
        "Slow" side.
       </para>
      </listitem>
     </orderedlist>
     <para>
      After acceleration is turned off, sync the desktop mouse and the ILO
      mouse by moving to the edges and top of the desktop to line them up in
      the vertical and horizontal directions. Also if the HP High
      Performance Mouse is disabled, pressing the &lt;Ctrl&gt; key will stop
      the desktop mouse and allow easier syncing of the two pointers.
     </para>
     <para>
      For more details, see TID 7002735 at
      <ulink url="https://www.suse.com/support/kb/doc/?id=000016926"/>.
     </para>
    </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=490462 -->
    <section>
     <title>Missing 32-Bit Compatibility Libraries for libstdc++ and libg++ on 64-Bit Systems (x86_64)</title>
     <para>
      32-bit (x86) compatibility libraries like "libstdc++-libc6.2-2.so.3"
      have been available on x86_64 in the package "compat-32-bit" with SUSE
      Linux Enterprise Server 9, SUSE Linux Enterprise Server 10, and are
      also available on the SUSE Linux Enterprise Desktop 11 medium
      (compat-32-bit-2009.1.19), but are not included in SUSE Linux
      Enterprise Server_11.
     </para>
     <para>
      Background
     </para>
     <para>
      The respective libraries have been deprecated back in 2001 and shipped
      in the compatibility package with the release of SUSE Linux Enterprise
      Server 9 in 2004. The package was still shipped with SUSE Linux
      Enterprise Server 10 to provide a longer transition period for
      applications requiring the package.
     </para>
     <para>
      With the release of SUSE Linux Enterprise Server 11 the compatibility
      package is no longer supported.
     </para>
     <para>
      Solution
     </para>
     <para>
      In an effort to enable a longer transition period for applications
      still requiring this package, it has been moved to the unsupported
      "Extras" channel. This channel is visible on every SUSE Linux
      Enterprise Server 11 system, which has been registered with the Novell
      Customer Center. It is also mirrored via SMT alongside the supported
      and maintained SUSE Linux Enterprise Server 11 channels.
     </para>
     <para>
      Packages in the "Extras" channel are not supported or maintained.
     </para>
     <para>
      The compatibility package is part of SUSE Linux Enterprise Desktop 11
      due to a policy difference with respect to deprecation and deprecated
      packages as compared to SUSE Linux Enterprise Server 11.
     </para>
     <para>
      We encourage customers to work with SUSE and SUSE's partners to
      resolve dependencies on these old libraries.
     </para>
    </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=547040 -->
    <section>
     <title>32-Bit Devel-Packages Missing from the Software Development Kit (x86_64)</title>
     <para>
      Example: libpcap0-devel-32-bit package was available in Software
      Development Kit 10, but is missing from Software Development Kit 11
     </para>
     <para>
      Background
     </para>
     <para>
      SUSE supports running 32-bit applications on 64-bit architectures;
      respective runtime libraries are provided with SUSE Linux Enterprise
      Server 11 and fully supported. With SUSE Linux Enterprise 10 we also
      provided 32-bit devel packages on the 64-bit Software Development Kit.
      Having 32-bit devel packages and 64-bit devel packages installed in
      parallel may lead to side-effects during the build process. Thus with
      SUSE Linux Enterprise 11 we started to remove some (but not yet all)
      of the 32-bit devel packages from the 64-bit Software Development Kit.
     </para>
     <para>
      Solution
     </para>
     <para>
      With the development tools provided in the Software Development Kit
      11, customers and partners have two options to build 32-bit packages
      in a 64-bit environment (see below). Beyond that, SUSE's appliance
      offerings provide powerful environments for software building,
      packaging and delivery.
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Use the "build" tool, which creates a chroot environment for
        building packages.
       </para>
      </listitem>
      <listitem>
       <para>
        The Software Development Kit contains the software used for the Open
        Build Service. Here the abstraction is provided by virtualization.
       </para>
      </listitem>
     </itemizedlist>
    </section>
   </section>
   <section id="InfraPackArch.x86_64_x86.Virtualization" remap="InfraPackArch:x86_64_x86:Virtualization">
    <title>Virtualization</title>
<!-- KVM -->
<!--v Items below imported from FATE-->
    <section role="notoc" id="fate-318443" remap="InfraPackArch:x86_64_x86:Virtualization">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318443" -->
     <title>XEN: Watchdog Usage</title>
     <para>
      Multiple XEN watchdog instances are not supported. Enabling more than
      one instance can cause system crashes.
     </para>
    </section>
    <section role="notoc" id="fate-318226" remap="InfraPackArch:x86_64_x86:Virtualization">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization"; -->
<!-- href="https://fate.novell.com/318226" -->
     <title>Inclusion of the virt-top tools</title>
     <para>
      <literal>virt-top</literal> is a top-like utility for showing stats of
      virtualized domains. Many keys and command line options are the same
      as for ordinary <literal>top</literal>.
     </para>
    </section>
    <section role="notoc" id="fate-318106" remap="InfraPackArch:x86_64_x86:Virtualization">
<!-- sort_key="None"; non-rn-fate-cats="Interoperability,Virtualization"; -->
<!-- href="https://fate.novell.com/318106" -->
     <title>open-vm-tools Now Included</title>
     <para>
      In the past, it was necessary to install VMware tools separately,
      because they had not been shipped with the distribution.
     </para>
     <para>
      SUSE Linux Enterprise 11 SP4 includes the
      <literal>open-vm-tools</literal> package. These tools are pre-selected
      when installing on a VMware platform.
     </para>
     <para>
      Partnering with VMware, SUSE provides full support for these tools.
      For more information, see
      <ulink url="https://kb.vmware.com/s/article/2073803"/>.
     </para>
    </section>
    <section role="notoc" id="fate-317638" remap="InfraPackArch:x86_64_x86:Virtualization">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317638" -->
     <title>Xen: Kernel Dom0 and Raw Hardware Characteristics</title>
     <para>
      Because the kernel dom0 is running virtualized, tools such as
      <literal>irqbalance</literal> or <literal>lscpu</literal> will not
      reflect the raw hardware characteristics.
     </para>
    </section>
    <section role="notoc" id="fate-314895" remap="InfraPackArch:x86_64_x86:Virtualization">
<!-- sort_key="None"; non-rn-fate-cats="Documentation,Virtualization"; -->
<!-- href="https://fate.novell.com/314895" -->
     <title>VMware: Enabling X2APIC</title>
     <para>
      For improved performance, X2APIC is now supported.
     </para>
    </section>
<!--^ End of Items imported from FATE-->
    <section>
     <title>KVM</title>
     <para>
<!-- bnc#730631 -->
      Since SUSE Linux Enterprise Server 11 SP1, KVM is fully supported on
      the x86_64 architecture. KVM is designed around hardware
      virtualization features included in both AMD (AMD-V) and Intel (VT-x)
      CPUs produced within the past few years, as well as other
      virtualization features in even more recent PC chipsets and PCI
      devices. For example, device assignment using IOMMU and SR-IOV.
     </para>
     <para>
      The following website identifies processors which support hardware
      virtualization:
      <ulink url="https://en.wikipedia.org/wiki/X86_virtualization"/>
     </para>
     <para>
      The KVM kernel modules will not load if the basic hardware
      virtualization features are not present and enabled in the BIOS. If
      KVM does not start, please check the BIOS settings.
     </para>
     <para>
      KVM allows for memory overcommit and disk space overcommit. It is up
      to the user to understand the impact of doing so. Hard errors
      resulting from exceeding available resources will result in guest
      failures. CPU overcommit is supported but carries performance
      implications.
     </para>
     <para>
<!-- bnc#739455 -->
      KVM supports a number of storage caching strategies which may be
      employed when configuring a guest VM. There are important data
      integrity and performance implications when choosing a caching mode.
      As an example, <literal>cache=writeback</literal> is not as safe as
      <literal>cache=none</literal>. See the online "SUSE Linux Enterprise
      Server Virtualization with KVM" documentation for details.
     </para>
     <para>
      The following guest operating systems are supported:
     </para>
     <itemizedlist>
      <listitem>
       <para>
<!-- MSvec via E-Mail -->
        Starting with SLES 11 SP2, Windows guest operating systems are fully
        supported on the KVM hypervisor, in addition to Xen. For the best
        experience, we recommend using WHQL-certified virtio drivers, which
        are part of SLE VMDP.
       </para>
       <para>
<!-- bnc#733003 -->
        SUSE Linux Enterprise Server 11 SP2 and SP3 as fully virtualized.
        The following virtualization aware drivers are available: kvm-clock,
        virtio-net, virtio-block, virtio-balloon
       </para>
      </listitem>
      <listitem>
       <para>
<!-- bnc#602493 -->
<!-- bnc#733003 -->
        SUSE Linux Enterprise Server 10 SP3 and SP4 as fully virtualized.
        The following virtualization aware drivers are available: kvm-clock,
        virtio-net, virtio-block, virtio-balloon
       </para>
      </listitem>
      <listitem>
       <para>
        SUSE Linux Enterprise Server 9 SP4 as fully virtualized. For 32-bit
        kernel, specify <literal>clock=pmtmr</literal> on the Linux boot
        line; for 64-bit kernel, specify
        <literal>ignore_lost_ticks</literal> on the Linux boot line.
       </para>
      </listitem>
     </itemizedlist>
     <para>
      For more information, see
      <filename>/usr/share/doc/packages/kvm/kvm-supported.txt</filename>.
     </para>
    </section>
<!-- VMI/bnc#608693 -->
    <section>
     <title>VMI Kernel (x86, 32-bit only)</title>
     <para>
      VMware, SUSE and the community improved the kernel infrastructure in a
      way that VMI is no longer necessary. Starting with SUSE Linux
      Enterprise Server 11 SP1, the separate VMI kernel flavor is obsolete
      and therefore has been dropped from the media. When upgrading the
      system, it will be automatically replaced by the PAE kernel flavor.
      The PAE kernel provides all features, which were included in the
      separate VMI kernel flavor.
     </para>
    </section>
<!-- bnc#484850 following bnc#469598 -->
<!-- bnc#744288: update for SP2 requested -->
    <section>
     <title>CPU Overcommit and Fully Virtualized Guest</title>
     <para>
      Unless the hardware supports Pause Loop Exiting (Intel) or Pause
      Intercept Filter (AMD) there might be issues with fully virtualized
      guests with CPU overcommit in place becoming unresponsive or hang
      under heavy load.
     </para>
     <para>
      Paravirtualized guests work flawlessly with CPU overcommit under heavy
      load.
     </para>
     <para>
      This issue is currently being worked on.
     </para>
    </section>
<!-- bnc#468251 -->
    <section>
     <title>IBM System x x3850/x3950 with ATI Radeon 7000/VE Video Cards and Xen Hypervisor</title>
     <para>
      When installing SUSE Linux Enterprise Server 11 on IBM System x
      x3850/x3950 with ATI Radeon 7000/VE video cards, the boot parameter
      'vga=0x317' needs to be added to avoid video corruption during the
      installation process.
     </para>
     <para>
      Graphical environment (X11) in Xen is not supported on IBM System x
      x3850/x3950 with ATI Radeon 7000/VE video cards.
     </para>
    </section>
<!--  https://bugzilla.novell.com/show_bug.cgi?id=448734#c40 -->
    <section>
     <title>Video Mode Selection for Xen Kernels</title>
     <para>
      In a few cases, following the installation of Xen, the hypervisor does
      not boot into the graphical environment. To work around this issue,
      modify <filename>/boot/grub/menu.lst</filename> and replace
      <filename>vga=&lt;number&gt;</filename> with
      <filename>vga=mode-&lt;number&gt;</filename>. For example, if the
      setting for your native kernel is <literal>vga=0x317</literal>, then
      for Xen you will need to use <literal>vga=mode-0x317</literal>.
     </para>
    </section>
<!-- bnc#477729 -->
    <section>
     <title>Time Synchronization in virtualized Domains with NTP</title>
     <para>
      Paravirtualized (PV) DomUs usually receive the time from the
      hypervisor. If you want to run "ntp" in PV DomUs, the DomU must be
      decoupled from the Dom0's time. At runtime, this is done with:
     </para>
<screen>echo 1 &gt; /proc/sys/xen/independent_wallclock</screen>
     <para>
      To set this at boot time:
     </para>
     <orderedlist>
      <listitem>
       <para>
        either append "independent_wallclock=1" to kernel cmd line in DomU's
        grub configuration file
       </para>
      </listitem>
      <listitem>
       <para>
        or append "xen.independent_wallclock = 1" to
        <filename>/etc/sysctl.conf</filename> in the DomU.
       </para>
      </listitem>
     </orderedlist>
     <para>
      If you encounter time synchronization issues with Paravirtualized
      Domains, we encourage you to use NTP.
     </para>
    </section>
   </section>
<!--
  <listitem>
    <para>
     Kernel Limits (Maximum Memory, Number of CPUs)
    </para>
    <para>
    </para>
  </listitem>
-->
  </section>
  <section id="InfraPackArch.IA64">
   <title>Intel Itanium (ia64) Specific Information</title>
   <section>
<!-- bnc#468922
       https://bugzilla.novell.com/show_bug.cgi?id=448734#c31 -->
    <title>Installation on Systems with Many LUNs (Storage)</title>
    <para>
     While the number of LUNs for a running system is virtually unlimited,
     we suggest not having more than 64 LUNs online while installing the
     system, to reduce the time to initialize and scan the devices and thus
     reduce the time to install the system in general.
    </para>
   </section>
<!--
<itemizedlist>

        <listitem>
                <para></para>
                <para></para>
        </listitem>

</itemizedlist>
-->
  </section>
  <section id="InfraPackArch.Power" remap="InfraPackArch:Power">
   <title>POWER (ppc64) Specific Information</title>
<!-- bnc#495886 -->
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-318212" remap="InfraPackArch:Power">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/318212" -->
    <title>ppc64-diag</title>
    <para>
     ppc64-diag is a RAS package used to retrieve platform error logs and
     take some of the actions (like DLPAR, EPOW actions, etc). It is not
     part of the base installation pattern for Power on SLES 11 SP4 but
     should be installed manually on any Power system.
    </para>
   </section>
   <section role="notoc" id="fate-317619" remap="InfraPackArch:Power">
<!-- sort_key="None"; non-rn-fate-cats="Hardware and Drivers"; -->
<!-- href="https://fate.novell.com/317619" -->
    <title>POWER8 Support</title>
    <para>
     SLES 11 SP4 provides a number of kernel improvements for the POWER8
     processor:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SMT8 support
      </para>
     </listitem>
     <listitem>
      <para>
       New POWER8 vector instructions
      </para>
     </listitem>
     <listitem>
      <para>
       New POWER8 hardware performance counters
      </para>
     </listitem>
     <listitem>
      <para>
       Data Stream Control Register (DSCR) improvements
      </para>
     </listitem>
    </itemizedlist>
   </section>
   <section role="notoc" id="fate-317611" remap="InfraPackArch:Power">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317611" -->
    <title>GPT (GUID Partition Table) Support</title>
    <para>
     Support for installation on GPT (GUID Partition Table) is now
     available.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section>
    <title>Supported Hardware and Systems</title>
    <para>
     All POWER3, POWER4, PPC970 and RS64–based models that were supported
     by SUSE Linux Enterprise Server 9 are no longer supported.
    </para>
   </section>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=812457 -->
   <section>
    <title>Using btrfs as /root File System on IBM Power Systems</title>
    <para>
     Configure a minimum of 32MB for the PReP partition when using btrfs as
     the <filename>/root</filename> file system.
    </para>
   </section>
<!-- bnc#705401 -->
<!-- bnc#755877 : obsolete -->
<!--
   <title>Misleading Buffer I/O Error Messages</title>
  -->
<!-- bnc#427960 -->
<!-- bnc#756801 -->
<!-- bnc#1018445 -->
   <section>
    <title>Loading the Installation Kernel via Network on POWER</title>
    <para>
     To load the installation kernel via network, copy the files
     <filename>yaboot.ibm</filename> and <filename>yaboot.cnf</filename>
     from the <filename>DVD1/suseboot</filename> directory to the TFTP
     server. Rename the <filename>yaboot.cnf</filename> file to
     <filename>yaboot.conf</filename>. yaboot can also load config files for
     specific Ethernet MAC addresses. Use a name like
     <filename>yaboot.conf-01-23-45-ab-cd-ef</filename> to match a MAC
     address. Depending on the DVD revision the DVD may contain an
     <filename>inst64</filename> file or separate
     <filename>linux64</filename> and <filename>initrd64</filename> files.
     An example <filename>yaboot.conf</filename> for TFTP booting looks like
     this:
    </para>
<screen>default=sles11
timeout=100
image[64-bit]=inst64
  label=sles11
  append="quiet install=nfs://hostname/exported/sles11dir"</screen>
    <para>
     or
    </para>
<screen>default=sles11
timeout=100
image[64bit]=linux64
  label=sles11
  append="quiet sysrq=1 insmod=sym53c8xx insmod=ipr install=nfs://hostname/exported/sles11dir"
  initrd=initrd64</screen>
    <para>
     Copy the files specified in the <filename>yaboot.conf</filename> as
     image and initrd (if any) to your TFTP server as well.
    </para>
   </section>
<!-- bnc#448547 -->
   <section>
    <title>Huge Page Memory Support on POWER</title>
    <para>
     Huge Page Memory (16GB pages, enabled via HMC) is supported by the
     Linux kernel, but special kernel parameters must be used to enable this
     support. Boot with the parameters "<literal>hugepagesz=16G
     hugepages=N</literal>" in order to use the 16GB huge pages, where N is
     the number of 16GB pages assigned to the partition via the HMC. The
     number of 16GB huge pages available can not be changed once the
     partition is booted. Also, there are some restrictions if huge pages
     are assigned to a partition in combination with eHEA / eHCA adapters:
    </para>
    <para>
     IBM eHEA Ethernet Adapter:
    </para>
    <para>
     The eHEA module will fail to initialize any eHEA ports if huge pages
     are assigned to the partition and Huge Page kernel parameters are
     missing. Thus, no huge pages should be assigned to the partition during
     a network installation. To support huge pages after installation, the
     huge page kernel parameters need to be added to the boot loader
     configuration before huge pages are assigned to the partition.
    </para>
    <para>
     IBM eHCA InfiniBand Adapter:
    </para>
    <para>
     The current eHCA device driver is not compatible with huge pages. If
     huge pages are assigned to a partition, the device driver will fail to
     initialize any eHCA adapters assigned to the partition.
    </para>
   </section>
<!-- bnc#431284 -->
   <section>
    <title>Installation on POWER onto IBM VSCSI Target</title>
    <para>
     The installation on a vscsi client will fail with old versions of the
     AIX VIO server.
    </para>
    <para>
     Solution: Upgrade the AIX VIO server to version 1.5.2.1-FP-11.1 or
     later.
    </para>
   </section>
<!-- bnc#486012 -->
<!-- bnc#825141 -->
<!--
  <section>
   <title>
    iSCSI Installations with Multiple NICs Losing
    Network Connectivity at the End of Firstboot Stage
   </title>
  -->
<!-- bnc#433956 replaced by bnc#598902 -->
   <section>
    <title>IBM Linux VSCSI Server Support in SUSE Linux Enterprise Server 11</title>
    <para>
     Customers using SLES 9 or SLES 10 to serve Virtual SCSI to other LPARs,
     using the ibmvscsis driver, who wish to migrate from these releases,
     should consider migrating to the IBM Virtual I/O server. The IBM
     Virtual I/O server supports all the IBM PowerVM virtual I/O features
     and also provides integration with the Virtual I/O management
     capabilities of the HMC. It can be downloaded from:
     <ulink url="https://www14.software.ibm.com/webapp/set2/sas/f/vios/download/home.html"/>
    </para>
   </section>
<!-- bnc#476471 -->
   <section>
    <title>Virtual Fibre Channel Devices</title>
    <para>
     When using IBM Power Virtual Fibre Channel devices utilizing N-Port ID
     Virtualization, the Virtual I/O Server may need to be updated in order
     to function correctly. Linux requires VIOS 2.1, Fixpack 20.1, and the
     LinuxNPIV I-Fix for this feature to work properly. These updates can be
     downloaded from:
     <ulink url="https://www14.software.ibm.com/webapp/set2/sas/f/vios/home.html"/>
    </para>
   </section>
<!-- bnc#476385 replaced by bnc#598902 -->
   <section>
    <title>Virtual Tape Devices</title>
    <para>
     When using virtual tape devices served by an AIX VIO server, the
     Virtual I/O Server may need to be updated in order to function
     correctly. The latest updates can be downloaded from:
     <ulink url="https://www14.software.ibm.com/webapp/set2/sas/f/vios/home.html"/>
    </para>
    <para>
     For more information about IBM Virtual I/O Server, see
     <ulink url="https://www14.software.ibm.com/webapp/set2/sas/f/vios/documentation/home.html"/>.
    </para>
   </section>
<!-- bnc#475566 bnc#473572 bnc#743336-->
<!-- <listitem> -->
<!--  <para>ITrace</para> -->
<!-- bnc#476855 -->
   <section>
    <title>Chelsio cxgb3 iSCSI Offload Engine</title>
    <para>
     The Chelsio hardware supports ~16K packet size (the exact value depends
     on the system configuration). It is recommended that you set the
     parameter <filename>MaxRecvDataSegmentLength</filename> in
     <filename>/etc/iscsid.conf</filename> to 8192.
    </para>
    <para>
     For the cxgb3i driver to work properly, this parameter needs to be set
     to 8192.
    </para>
    <para>
     In order to use the cxgb3i offload engine, the cxgb3i module needs to
     be loaded manually after open-scsi has been started.
    </para>
    <para>
     For additional information, refer to
     <filename>/usr/src/linux/Documentation/scsi/cxgb3i.txt</filename> in
     the kernel source tree.
    </para>
   </section>
<!-- bnc#465601 -->
   <section>
    <title>Known TFTP Issues with Yaboot</title>
    <para>
     When attempting to netboot yaboot, users may see the following error
     message:
    </para>
<screen>Can't claim memory for TFTP download (01800000 @ 01800000-04200000)</screen>
    <para>
     and the netboot will stop and immediately display the yaboot "boot:"
     prompt. Use the following steps to work around the problem.
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Reboot the system and at the IBM splash screen select '8' to get to
       an Open Firmware prompt "0&gt;"
      </para>
     </listitem>
     <listitem>
      <para>
       At the Open Firmware prompt, type the following commands:
      </para>
<screen>setenv load-base 4000
setenv real-base c00000
dev /packages/gui obe
</screen>
     </listitem>
     <listitem>
      <para>
       The second command will take the system back to the IBM splash screen
       and the netboot can be attempted again.
      </para>
     </listitem>
    </itemizedlist>
   </section>
<!-- bnc#585190 -->
   <section>
    <title>Graphical Administration of Remotely Installed Hardware</title>
    <para>
     If you do a remote installation in text mode, but want to connect to
     the machine later in graphical mode, be sure to set the default
     runlevel to 5 via YaST. Otherwise xdm/kdm/gdm might not be started.
    </para>
   </section>
<!-- bnc#600835 bnc#743336-->
<!-- <listitem> -->
<!--  <para>The itrace Tracing Software May Affect GDB Functionality</para> -->
<!-- bnc#602954 -->
   <section>
    <title>InfiniBand - SDP Protocol Not Supported on IBM Hardware</title>
    <para>
     To disable SDP on IBM hardware set <literal>SDP=no</literal> in
     openib.conf so that by default SDP is not loaded. After you have set
     this setting in openib.conf to 'no' run <command>openibd
     restart</command> or reboot the system for this setting to take effect.
    </para>
   </section>
<!-- bnc#585361 -->
   <section>
    <title>RDMA NFS Server May Hang During Shutdown (OFED)</title>
    <para>
     If your system is configured as an NFS over RDMA server, the system may
     hang during a shutdown if a remote system has an active NFS over RDMA
     mount. To avoid this problem, prior to shutting down the system, run
     "openibd stop"; run it in the background, because the command will hang
     and otherwise block the console:
    </para>
<screen>/etc/init.d/openibd stop &amp;</screen>
    <para>
     A shutdown can now be run cleanly.
     <remark>emap: We just told the user to run the command in order to avoid the
  problem.</remark>
     <remark>ke: open bug to seek developer feedback.</remark>
     <remark>ke: I changed it for clarity.</remark>
    </para>
    <para>
     The steps to configure and start NFS over RDMA are as follows:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       On the server system:
      </para>
      <orderedlist>
       <listitem>
        <para>
         Add an entry to the file <filename>/etc/exports</filename>, for
         example:
        </para>
<screen>/home   192.168.0.34/255.255.255.0(fsid=0,rw,async,insecure,no_root_squash)</screen>
       </listitem>
       <listitem>
        <para>
         As the root user run the commands:
        </para>
<screen>/etc/init.d/nfsserver start
echo rdma 20049 &gt; /proc/fs/nfsd/portlist</screen>
       </listitem>
      </orderedlist>
     </listitem>
     <listitem>
      <para>
       On the client system:
      </para>
      <orderedlist>
       <listitem>
        <para>
         Run the command: <command>modprobe xprtrdma</command>.
        </para>
       </listitem>
       <listitem>
        <para>
         Mount the remote file system using the command
         <command>/sbin/mount.nfs</command>. Specify the ip address of the
         ip-over-ib network interface (ib0, ib1...) of the server and the
         options: <option>proto=rdma,port=20049</option>, for example:
        </para>
<screen>/sbin/mount.nfs 192.168.0.64:/home /mnt \
-o proto=rdma,port=20049,nolock</screen>
       </listitem>
      </orderedlist>
     </listitem>
    </itemizedlist>
   </section>
<!-- bnc#815356 -->
   <section>
    <title>XFS Stack Overflow</title>
    <para>
     Under heavy IO load on a fragmented filesystem, XFS can overflow the
     stack on ppc64 architecture leading to system crash.
    </para>
    <para>
     This problem is fixed with the first SLE 11 SP3 maintenance update.
     The released kernel version is 3.0.82-0.7.9
    </para>
   </section>
  </section>
  <section id="InfraPackArch.SystemZ">
   <title>System z (s390x) Specific Information</title>
   <para>
    In the following, IBM zEnterprise 196 (z196) and IBM zEnterprise 114
    (z114) are referred to as z196 and z114.
   </para>
   <section id="InfraPackArch.SystemZ.Hardware">
    <title>Hardware</title>
    <para/>
    <section>
     <title>IBM System z Architecture Level Set (ALS) Preparation</title>
<!-- AI:ihno, mkraft , information is old -->
     <para>
      To exploit new IBM System z architecture capabilities during the life
      cycle of SUSE Linux Enterprise Server 11, support for machines of the
      types z900, z990, z800, z890 is deprecated in this release. SUSE plans
      to introduce an ALS earliest with SUSE Linux Enterprise Server 11
      Service Pack 1 (SP1), latest with SP2. After ALS, SUSE Linux
      Enterprise Server 11 only executes on z9 or newer processors.
     </para>
     <para>
      With SUSE Linux Enterprise Server 11 GA, only machines of type z9 or
      newer are supported.
     </para>
     <para>
      When developing software, we recommend to switch gcc to z9/z10
      optimization:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        install gcc
       </para>
      </listitem>
      <listitem>
       <para>
        install gcc-z9 package (change gcc options to -march=z9-109
        -mtune=z10)
       </para>
      </listitem>
     </itemizedlist>
    </section>
    <section>
     <title>Minimum Storage Firmware Level for LUN Scanning</title>
     <para>
      For LUN Scanning to work properly, the minimum storage firmware level
      should be:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        DS8000 Code Bundle Level 64.0.175.0
       </para>
      </listitem>
      <listitem>
       <para>
        DS6000 Code Bundle Level 6.2.2.108
       </para>
      </listitem>
     </itemizedlist>
    </section>
<!-- bsc#933278: obsolete
  <section><title>Large Page Support in IBM System z</title>
  <para>
   Large Page support allows processes to allocate process memory in chunks
   of 1 MiB instead of 4 KiB. This works through the hugetlbfs.
  </para></section>
  -->
<!-- bnc#417244, outdate -->
<!-- bnc#753005 -->
<!-- bsc#933278: obsolete
  <section>
   <title>Collaborative Memory Management Stage II (CMM2) Lite</title>
   <para>
    SLES 11 SP2 supports CMM2 Lite for optimized memory usage and to
    handle memory overcommitment via memory page state transitions based
    on "stable" and "unused" memory pages of z/VM guests using the
    existing <literal>arch_alloc_page</literal> and
    <literal>arch_free_page</literal> callbacks.
   </para>
  </section>
  -->
<!-- bnc#488642 -->
    <section>
     <title>Issue with SLES 11 and NSS under z/VM</title>
     <para>
      Starting SLES 11 under z/VM with NSS sometimes causes a guest to
      logoff by itself.
     </para>
     <para>
      Solution: IBM addresses this issue with APAR VM64578.
     </para>
    </section>
   </section>
   <section id="InfraPackArch.SystemZ.Virtualization">
    <title>Virtualization</title>
<!-- bnc#738559 -->
<!-- ihno, 2013-05-27: applies for SP3 as well -->
    <section>
     <title>Support of Live Guest Relocation (LGR) with z/VM 6.2
<!-- on SLES 11 SP2--></title>
     <para>
      Live guest relocation (LGR) with z/VM 6.2
<!-- on SLES 11 SP2 -->
      requires z/VM service applied, especially with Collaborative Memory
      Management (CMMA) active (<literal>cmma=on</literal>).
     </para>
     <para>
      Apply z/VM APAR VM65134.
     </para>
    </section>
<!-- bnc#743338 -->
    <section>
     <title>Linux Guests Running on z/VM 5.4 and 6.1 Require z/VM Service Applied</title>
     <para>
      Linux guests using dedicated devices may experience a loop, if an
      available path to the device goes offline prior to the IPL of Linux.
     </para>
     <para>
      Apply recommended z/VM service APARs VM65017 and VM64847.
     </para>
    </section>
   </section>
   <section id="InfraPackArch.SystemZ.Storage" remap="InfraPackArch:SystemZ:Storage">
    <title>Storage</title>
    <para/>
<!--v Items below imported from FATE-->
    <section role="notoc" id="fate-317594" remap="InfraPackArch:SystemZ:Storage">
<!-- sort_key="None"; non-rn-fate-cats="zSeries"; -->
<!-- href="https://fate.novell.com/317594" -->
     <title>QSAM Access Method for Data sharing with z/OS - Stage 1</title>
     <para>
      This feature introduces a new interface that enables Linux
      applications like Data Stage to access and process (read only) data in
      z/OS owned physical sequential data sets without interfering with
      z/OS. By avoiding FTP or NFS transfer of data from z/OS the turnaround
      time for batch processing is significantly reduced.
     </para>
    </section>
<!--^ End of Items imported from FATE-->
   </section>
   <section id="InfraPackArch.SystemZ.Network" remap="InfraPackArch:SystemZ:Network">
    <title>Network</title>
<!-- bnc#728611 -->
<!--v Items below imported from FATE-->
    <section role="notoc" id="fate-319065" remap="InfraPackArch:SystemZ:Network">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/319065" -->
     <title>10GbE RoCE Express</title>
     <para>
      SLES 11 SP4 supports the 10GbE RoCE Express feature on zEC12, zBC12,
      z13 via the TCP/IP layer. Before using this feature on an IBM z13
      ensure to have the minimum required service applied: z/VM APAR UM34525
      and HW ycode N98778.057 (bundle 14). Also it is recommended to use the
      default MTU size (1500). SLES 11 SP4 includes RDMA enablement and
      DAPL/OFED for s390x as a technology preview but these can only be used
      on LPAR when running on IBM z Systems zEC12, zBC12 and cannot be used
      on IBM z13.
     </para>
    </section>
    <section role="notoc" id="fate-317595" remap="InfraPackArch:SystemZ:Network">
<!-- sort_key="None"; non-rn-fate-cats="zSeries"; -->
<!-- href="https://fate.novell.com/317595" -->
     <title>src_vipa: IPv6 Enablement</title>
     <para>
      Adds support for IPv6 addresses to the <literal>src_vipa</literal>
      tool, that only supported IPv4 up to now
     </para>
    </section>
<!--^ End of Items imported from FATE-->
    <section>
     <title>YaST May Fail to Activate Hipersocket Devices in Layer 2 Mode</title>
     <para>
      In rare occasions Hipersocket devices in layer 2 mode may remain in
      softsetup state when configured via YaST.
     </para>
     <para>
      Perform <command>ifup</command> manually.
     </para>
    </section>
<!-- bnc#728611 -->
    <section>
     <title>YaST Sets an Invalid Default MAC Address for OSA Devices in Layer 2 Mode</title>
     <para>
      OSA devices in layer 2 mode remain in softsetup state when "Set
      default MAC address" is used in YaST.
     </para>
     <para>
      Do not select "Set default MAC address" in YaST. If default MAC
      address got selected in YaST remove the line
      <literal>LLADR='00:00:00:00:00:00'</literal> from the
      <filename>ifcfg</filename> file in
      <filename>/etc/sysconfig/network</filename>.
     </para>
    </section>
<!-- bnc#744841 -->
    <section>
     <title>Limitations with the "qetharp" Utility</title>
     <variablelist>
      <varlistentry>
       <term><command>qetharp -d</command>
       </term>
       <listitem>
        <para>
         Deleting: An ARP entry, which is part of Shared OSA should not get
         deleted from the arp cache.
        </para>
        <para>
         Current Behavior: An ARP entry, which is part of shared OSA is
         getting deleted from the arp cache.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term><command>qetharp -p</command>
       </term>
       <listitem>
        <para>
         Purging: It should remove all the remote entries, which are not
         part of shared OSA.
        </para>
        <para>
         Current Behavior: It is only flushing out the remote entries, which
         are not part of shared OSA for first time. Then, if the user pings
         any of the purged ip address, the entry gets added back to the arp
         cache. Later, if the user runs purge for a second time, that
         particular entry is not getting removed from the arp cache.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </section>
   </section>
   <section id="InfraPackArch.SystemZ.RAS" remap="InfraPackArch:SystemZ:RAS">
    <title>RAS</title>
    <para/>
<!--v Items below imported from FATE-->
    <section role="notoc" id="fate-317623" remap="InfraPackArch:SystemZ:RAS">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317623" -->
     <title>Keywords for ipl and Console Device for Use in cio_ignore</title>
     <para>
      Enable the use of keywords, "IPLDEV" for the IPL device and "CONDEV"
      for the console devices to ease installation when a system uses
      cio_ignore to blacklist all devices at install time and does not have
      a default CCW console device number, has no devices other than the IPL
      device as a base to clone Linux guests, or with ramdisk based
      installations with no devices other than the CCW console.
     </para>
    </section>
    <section role="notoc" id="fate-317597" remap="InfraPackArch:SystemZ:RAS">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317597" -->
     <title>libica 2.4.2 Available since SLES 11 SP4 for s390x</title>
     <para>
      The libica package contains the interface library routines used by IBM
      modules to interface with IBM Cryptographic Hardware (ICA). Starting
      with SLES 11 SP1, libica is provided in the s390x distribution in
      three flavors of packages: libica-1_3_9, libica-2_0_2, libica-2_1_0
      and libica-2_4_2, providing libica versions 1.3.9, 2.0.2, 2.1.0 and
      2.4.2 respectively.
     </para>
     <para>
      libica 1.3.9 is provided for compatibility reasons with legacy
      hardware. For s390x users it is always recommended to use the new
      libica 2.4.2 library since it supports all newer s390x hardware,
      improved crypto usage statistics and is backwards compatible with any
      crypto device driver in the s390x architecture.
     </para>
     <para>
      You may choose to continue using libica 1.3.9, 2.0.2 or 2.1.0 if you
      do not have newer Cryptographic hardware to exploit or wish continue
      using custom applications that do not support the libica 2.4.2 library
      yet. Both openCryptoki and openssl-ibmca, the two main exploiters for
      the libica interface, are provided starting with SLES 11 SP4 to
      support the newer libica 2.4.2 library.
     </para>
    </section>
    <section role="notoc" id="fate-317596" remap="InfraPackArch:SystemZ:RAS">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317596" -->
     <title>Support of Enterprise PKCS#11 (EP11)</title>
     <para>
      Exploitation of Enterprise wide PKCS#11 (EP11) in CryptoExpress4
      device driver and openCryptoki token for access to the Enterprise
      PKCS#11 (EP11) features of the CEX4S crypto adapter that implements
      certified PKCS#11 mechanism.
     </para>
    </section>
<!--^ End of Items imported from FATE-->
   </section>
   <section id="InfraPackArch.SystemZ.Performance" remap="InfraPackArch:SystemZ:Performance">
    <title>Performance</title>
    <para/>
<!--v Items below imported from FATE-->
    <section role="notoc" id="fate-317698" remap="InfraPackArch:SystemZ:Performance">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317698" -->
     <title>Add support for hardware sampling to the perf tool</title>
     <para>
      With support for the CPU-measurement sampling facility available with
      IBM System z10 (z10) and later hardware the perf program can be used
      to capture performance data for processes, shared libraries, the
      kernel and device drivers.
     </para>
    </section>
    <section role="notoc" id="fate-317621" remap="InfraPackArch:SystemZ:Performance">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317621" -->
     <title>snIPL Interface to Control Dynamic CPU Capacity</title>
     <para>
      Remote control of the capacity of target systems in HA setups allows
      to maintain the bandwidth during failure situations and removes the
      need for keeping unused capacity activated during normal operation
     </para>
    </section>
<!--^ End of Items imported from FATE-->
   </section>
  </section>
 </chapter>
 <chapter id="Resolved">
  <title>Resolved Issues</title>
  <itemizedlist>
   <listitem>
    <para>
     Bugfixes
    </para>
    <para>
     This Service Pack contains all the latest bugfixes for each package
     released via the maintenance Web since the GA version. For details, see
     <ulink url="https://bugzilla.suse.com">https://bugzilla.suse.com</ulink>.
    </para>
   </listitem>
   <listitem>
    <para>
     Security Fixes
    </para>
    <para>
     This Service Pack contains all the latest security fixes for each
     package released via the maintenance Web since the GA version.
    </para>
   </listitem>
   <listitem>
    <para>
     Program Temporary Fixes
    </para>
    <para>
     This Service Pack contains all the PTFs (Program Temporary Fix) for
     each package released via the maintenance Web since the GA version
     which were suitable for integration into the maintained common code
     base.
    </para>
   </listitem>
  </itemizedlist>
 </chapter>
 <chapter id="TechInfo">
  <title>Technical Information</title>
  <para>
   This section contains information about system limits, a number of
   technical changes and enhancements for the experienced user.
  </para>
<!-- bnc#483250 -->
  <para>
   When talking about CPUs we are following this terminology:
  </para>
  <variablelist>
   <varlistentry>
    <term>CPU Socket</term>
    <listitem>
     <para>
      The visible physical entity, as it is typically mounted to a
      motherboard or an equivalent.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CPU Core</term>
    <listitem>
     <para>
      The (usually not visible) physical entity as reported by the CPU
      vendor.
     </para>
     <para>
      On System z this is equivalent to an IFL.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Logical CPU</term>
    <listitem>
     <para>
      This is what the Linux Kernel recognizes as a "CPU".
     </para>
     <para>
      We avoid the word "thread" (which is sometimes used), as the word
      "thread" would also become ambiguous subsequently.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Virtual CPU</term>
    <listitem>
     <para>
      A logical CPU as seen from within a Virtual Machine.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
  <section id="TechInfo.Kernel">
   <title>Kernel Limits</title>
   <para>
    This table summarizes the various limits which exist in our recent
    kernels and utilities (if related) for SUSE Linux Enterprise Server 11.
   </para>
   <informaltable frame="all">
    <tgroup cols="6">
     <colspec colnum="1" colname="c1"/>
     <colspec colnum="2" colname="c2"/>
     <colspec colnum="3" colname="c3"/>
     <colspec colnum="4" colname="c4"/>
     <colspec colnum="5" colname="c5"/>
     <colspec colnum="6" colname="c6"/>
     <thead>
      <row rowsep="1">
       <entry><emphasis>SLES 11 (3.0)</emphasis>
       </entry>
       <entry><emphasis>x86</emphasis>
       </entry>
       <entry><emphasis>ia64</emphasis>
       </entry>
       <entry><emphasis>x86_64</emphasis>
       </entry>
       <entry><emphasis>s390x</emphasis>
       </entry>
       <entry><emphasis>ppc64</emphasis>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         CPU bits
        </para>
       </entry>
       <entry>
        <para>
         32
        </para>
       </entry>
       <entry>
        <para>
         64
        </para>
       </entry>
       <entry>
        <para>
         64
        </para>
       </entry>
       <entry>
        <para>
         64
        </para>
       </entry>
       <entry>
        <para>
         64
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         max. # Logical CPUs
        </para>
       </entry>
       <entry>
        <para>
         32
        </para>
       </entry>
       <entry>
        <para>
         4096
        </para>
       </entry>
       <entry>
        <para>
         4096
        </para>
       </entry>
       <entry>
        <para>
         64
        </para>
       </entry>
       <entry>
        <para>
         1024
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         max. RAM (theoretical / certified)
        </para>
       </entry>
       <entry>
        <para>
         64/16 GiB
        </para>
       </entry>
       <entry>
        <para>
         1 PiB/8+ TiB
        </para>
       </entry>
       <entry>
        <para>
         64 TiB/16 TiB
        </para>
       </entry>
       <entry>
        <para>
         4 TiB/256 GiB
        </para>
       </entry>
<!-- bsc#1028458 -->
<!-- bsc#1078361 -->
<!-- bsc#1079501 -->
       <entry>
        <para>
         32 TiB/32 TiB
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         max. user-/kernelspace
        </para>
       </entry>
       <entry>
        <para>
         3/1 GiB
        </para>
       </entry>
       <entry>
        <para>
         2 EiB/φ
        </para>
       </entry>
       <entry>
        <para>
         128 TiB/128 TiB
        </para>
       </entry>
       <entry>
        <para>
         φ/φ
        </para>
       </entry>
       <entry>
        <para>
         2 TiB/2 EiB
        </para>
       </entry>
      </row>
      <row>
       <entry>
<!-- bnc#708969 -->
        <para>
         max. swap space
        </para>
       </entry>
       <entry namest="c2" nameend="c6">
        <para>
         up to 29 * 64 GB (i386 and x86_64) or 30 * 64 GB (other
         architectures)
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         max. # processes
        </para>
       </entry>
       <entry namest="c2" nameend="c6">
        <para>
         1048576
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         max. # threads per process
        </para>
       </entry>
       <entry namest="c2" nameend="c6">
        <para>
         tested with more than 120000; maximum limit depends on memory and
         other parameters
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         max. size per block device
        </para>
       </entry>
       <entry>
        <para>
         up to 16 TiB
        </para>
       </entry>
       <entry namest="c3" nameend="c6">
        <para>
         and up to 8 EiB on all 64-bit architectures
        </para>
       </entry>
      </row>
      <row>
<!-- bnc#550958 -->
       <entry>
        <para>
         FD_SETSIZE
        </para>
       </entry>
       <entry namest="c2" nameend="c6">
        <para>
         1024
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <para/>
  </section>
  <section id="TechInfo.KVM" remap="TechInfo:KVM">
   <title>KVM Limits</title>
   <informaltable frame="all">
    <tgroup cols="2">
     <colspec colnum="1" colname="c1"/>
     <colspec colnum="2" colname="c2"/>
     <tbody>
      <row>
       <entry>
        <para>
         Guest RAM size
        </para>
       </entry>
       <entry>
<!-- fate#314371: 2 TiB -->
        <para>
         2 TB
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Virtual CPUs per guest
        </para>
       </entry>
       <entry>
<!-- bnc#730631 -->
<!-- fate#314371 -->
        <para>
         160
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Maximum number of NICs per guest
        </para>
       </entry>
       <entry>
        <para>
         8
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Block devices per guest
        </para>
       </entry>
       <entry>
        <para>
         4 emulated, 20 para-virtual
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Maximum number of guests
        </para>
       </entry>
       <entry>
        <para>
         Limit is defined as the total number of vCPUs in all guests being
         no greater than eight times the number of CPU cores in the host.
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-318278" remap="TechInfo:KVM">
<!-- sort_key="None"; non-rn-fate-cats="Documentation,Virtualization"; -->
<!-- href="https://fate.novell.com/318278" -->
    <title>Virtualization: Supported Live Migration Scenarios</title>
    <para>
     The following KVM host operating system combinations will be fully
     supported (L3) for live migrating guests from one host to another:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       VM from a SLES 12 host to SLES 12 host
      </para>
     </listitem>
     <listitem>
      <para>
       VM from a SLES 11 SP4 host to SLES 12 host
      </para>
     </listitem>
    </itemizedlist>
    <para>
     The following KVM host operating system combinations will be fully
     supported (L3) for live migrating guests from one host to another,
     later when released:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       VM from a SLES 12 host to SLES 12 SP1 host
      </para>
     </listitem>
    </itemizedlist>
    <para>
     All guests as outlined in the <emphasis>Virtualization Guide</emphasis>, chapter <emphasis>Supported VM Guests</emphasis>, are supported.
    </para>
    <para>
     Backward migration is not supported:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       VM from a SLES 12 host to SLES 11 SP4 host
      </para>
     </listitem>
     <listitem>
      <para>
       VM from a SLES 11 SP4 host to SP3/SP3 host
      </para>
     </listitem>
    </itemizedlist>
   </section>
   <section role="notoc" id="fate-318098" remap="TechInfo:KVM">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization,Virtualization / KVM"; -->
<!-- href="https://fate.novell.com/318098" -->
    <title>KVM: QXL Video Driver</title>
    <para>
     The QXL video driver is now available. With the QXL video virtual GPU
     you will get para-virtualized performance. Thus SLES 11 SP4 will run
     better as a guest under SLES 12.
    </para>
   </section>
   <section role="notoc" id="fate-318097" remap="TechInfo:KVM">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization,Virtualization / KVM"; -->
<!-- href="https://fate.novell.com/318097" -->
    <title>KVM: QEMU Guest Agent</title>
    <para>
     SLES11 SP4 now provide a QEMU Guest Agent to enable better controls and
     interactions with a SLES 11 SP4 guest.
    </para>
   </section>
   <section role="notoc" id="fate-316314" remap="TechInfo:KVM">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization"; -->
<!-- href="https://fate.novell.com/316314" -->
    <title>Online Disk Resizing</title>
    <para>
     KVM guests are able to see the new size of their disk after a resize on
     the host using the <literal>virsh blockresize</literal> command.
    </para>
   </section>
   <section role="notoc" id="fate-315032" remap="TechInfo:KVM">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/315032" -->
    <title>TLS Support for QEMU Websockets</title>
    <para>
     Since SLE 11 SP3 we ship QEMU with TLS encryption support for QEMU
     Websockets. This feature allows every modern browser to create a secure
     VNC connection to QEMU without any additional plugins or configuration
     on the user side.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="TechInfo.Xen" remap="TechInfo:Xen">
   <title>Xen Limits</title>
<!-- bnc#732995 -->
   <informaltable frame="all">
    <tgroup cols="2">
     <colspec colnum="1" colname="c1"/>
     <colspec colnum="2" colname="c2"/>
     <thead>
      <row rowsep="1">
       <entry><emphasis>SLES 11 SP3</emphasis>
       </entry>
       <entry><emphasis>x86</emphasis>
       </entry>
      </row>
     </thead>
     <tbody>
      <row>
       <entry>
        <para>
         CPU bits
        </para>
       </entry>
       <entry>
        <para>
         64
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Logical CPUs (Xen Hypervisor)
        </para>
       </entry>
       <entry>
        <para>
         256
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Virtual CPUs per VM
        </para>
       </entry>
       <entry>
        <para>
         64
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Maximum supported memory (Xen Hypervisor)
        </para>
       </entry>
       <entry>
        <para>
         2 TB
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Maximum supported memory (Dom0)
        </para>
       </entry>
       <entry>
        <para>
         500 GiB
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Virtual memory per VM
        </para>
       </entry>
       <entry>
<!-- bsc#938757#c21 -->
        <para>
         16 GB (32-bit), 511 GB (64-bit)
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Total virtual devices per host
        </para>
       </entry>
       <entry>
        <para>
         2048
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Maximum number of NICs per host
        </para>
       </entry>
       <entry>
        <para>
         8
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Maximum number of vNICs per guest
        </para>
       </entry>
       <entry>
        <para>
         8
        </para>
       </entry>
      </row>
      <row>
       <entry>
        <para>
         Maximum number of guests per host
        </para>
       </entry>
       <entry>
        <para>
         64
        </para>
       </entry>
      </row>
     </tbody>
    </tgroup>
   </informaltable>
   <para>
    In Xen 4.2, the hypervisor bundled with SUSE Linux Enterprise
    Server 11 SP3, dom0 is able to see and handle a maximum of 512 logical
    CPUs. The hypervisor itself, however, can access up to logical 256
    logical CPUs and schedule those for the VMs.
   </para>
<!-- In the following para, keep SP2 -->
   <para>
    With SUSE Linux Enterprise Server 11 SP2, we removed the 32-bit
    hypervisor as a virtualization host. 32-bit virtual guests are not
    affected and are fully supported with the provided 64-bit hypervisor.
   </para>
   <para/>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-318277" remap="TechInfo:Xen">
<!-- sort_key="None"; non-rn-fate-cats="Documentation,Virtualization"; -->
<!-- href="https://fate.novell.com/318277" -->
    <title>Virtualization: Supported Disks Formats and Protocols</title>
    <para>
     Currently, the disk formats <literal>raw</literal>,
     <literal>qed</literal> (only KVM), <literal>qcow</literal> (only Xen)
     and <literal>qcow2</literal> has read-write (rw) support. The disk
     formats <literal>vmdk</literal>, <literal>vpc</literal>, and
     <literal>vhd/vhdx</literal> are only supported in read-only (ro) mode.
     The <literal>http</literal>, <literal>https</literal>,
     <literal>ftp</literal>, <literal>ftps</literal>,
     <literal>tftp</literal> protocols are supported for read-only access to
     images.
    </para>
    <para>
     Under Xen the <literal>qed</literal> format will not be displayed as a
     selectable storage under <literal>virt-manager</literal>.
    </para>
   </section>
   <section role="notoc" id="fate-318081" remap="TechInfo:Xen">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization"; -->
<!-- href="https://fate.novell.com/318081" -->
    <title>XEN: Update Xen to Version 4.4</title>
    <para>
     Xen updated to Version 4.4.
    </para>
   </section>
   <section role="notoc" id="fate-317240" remap="TechInfo:Xen">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/317240" -->
    <title>Libvirt: Enhancement of virsh/libvirtd "send-key" command</title>
    <para>
     The <literal>xm</literal> and <literal>xl</literal> management tools
     have long supported sending SysRq keys to a domain using the
     <literal>sysrq</literal> subcommand. virsh now supports sending SysRq
     keys to a domain using the <literal>send-key</literal> subcommand.
    </para>
   </section>
   <section role="notoc" id="fate-317239" remap="TechInfo:Xen">
<!-- sort_key="None"; non-rn-fate-cats="Virtualization,Xen Virtual Machine Monitor"; -->
<!-- href="https://fate.novell.com/317239" -->
    <title>Libvirt: enhancement of the virsh/libvirtd "migrate" command</title>
    <para>
     Similar to the <literal>xm</literal> tool, <literal>virsh
     migrate</literal> now supports options to control the process of
     migration. Large memory virtual machines running busy workloads pose
     migration challenges. Memory pages can be dirtied at a higher rate than
     they are transferred to the migration destination, resulting in
     prolonged migration time. The default migration algorithm will detect
     stalls due to high dirty page rate, suspend the virtual machine, and
     transfer the remaining dirty pages. In virtual machines running busy
     guest workloads, the final memory transfer can take considerable time,
     which could affect guest workloads sensitive to the time jump incurred
     when resuming the virtual machine. These new options allow fine-tuning
     the migration process
    </para>
    <para>
     <itemizedlist>
      <listitem>
       <para>
        <literal>--max_iters &lt;number&gt;</literal>: Number of transfer
        iterations before suspend (default: 30)
       </para>
      </listitem>
      <listitem>
       <para>
        <literal>--max_factor &lt;factor&gt;</literal>: Maximum amount of
        memory to transfer before suspend (default: 3*RAM)
       </para>
      </listitem>
      <listitem>
       <para>
        <literal>--min_remaining &lt;number&gt;</literal>: Minimum number
        of dirty pages remaining to be transferred before suspend (default:
        50)
       </para>
      </listitem>
      <listitem>
       <para>
        <literal>--abort_if_busy</literal>: Abort migration instead of
        doing suspend and final memory transfer
       </para>
      </listitem>
     </itemizedlist>
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="TechInfo.Filesystems" remap="TechInfo:Filesystems">
   <title>File Systems</title>
   <para>
    <ulink url="https://www.suse.com/products/server/technical-information/#FileSystem"/>
   </para>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-320631" remap="TechInfo:Filesystems">
<!-- sort_key="None"; non-rn-fate-cats=""; -->
<!-- href="https://fate.novell.com/320631" -->
    <title>Deadlock Avoidance of Loopback-Mounted NFS File Systems</title>
    <para>
     There is now a deadlock avoidance feature for loopback-mounted NFS 3
     file systems. This feature exclusively works with NFS 3.
    </para>
   </section>
   <section role="notoc" id="fate-314864" remap="TechInfo:Filesystems">
<!-- sort_key="None"; non-rn-fate-cats="Filesystems"; -->
<!-- href="https://fate.novell.com/314864" -->
    <title>ext4: Runtime Switch for Write Support</title>
    <para>
     The SUSE Linux Enterprise 11 kernel contains a fully supported ext4
     file system module, which provides read-only access to the file system.
     A separate package is not required.
    </para>
    <para>
     Read-write access to an ext4 file system can be enabled by using the
     <literal>rw=1</literal> module parameter. The parameter can be passed
     while loading the ext4 module manually, by adding it for automatic use
     by creating <literal>/etc/modprobe.d/ext4</literal> with the contents
     <literal>options ext4 rw=1</literal>, or after loading the module by
     writing <literal>1</literal> to
     <literal>/sys/module/ext4/parameters/rw</literal>. Note that
     read-write ext4 file systems are still officially unsupported by SUSE
     Technical Services.
    </para>
    <para>
     ext4 is not supported for the installation of the SUSE Linux Enterprise
     operating system.
    </para>
    <para>
     Since SLE 11 SP2 we support offline migration from ext4 to the
     supported btrfs file system.
    </para>
    <para>
     The ext4-writeable package is still available for compatibility with
     systems with kernels from both the SLE 11 SP2 and SLE 11 SP3 releases
     installed.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
   <section id="TechInfo.Filesystems.Comparison">
    <title>Comparison of Supported File Systems</title>
    <para>
     SUSE Linux Enterprise was the first enterprise Linux distribution to
     support journaling file systems and logical volume managers back in
     2000. Today, we have customers running XFS and ReiserFS with more than
     8TiB in one file system, and our own SUSE Linux Enterprise engineering
     team is using all 3 major Linux journaling file systems for all its
     servers.
    </para>
    <para>
     We are excited to add the OCFS2 cluster file system to the range of
     supported file systems in SUSE Linux Enterprise.
    </para>
    <para>
     We propose to use XFS for large-scale file systems, on systems with
     heavy load and multiple parallel read- and write-operations (e.g., for
     file serving with Samba, NFS, etc.). XFS has been developed for such
     conditions, while typical desktop use (single write or read) will not
     necessarily benefit from its capabilities.
    </para>
<!-- bnc#580311 -->
    <para>
     Due to technical limitations (of the bootloader), we do not support XFS
     to be used for <filename>/boot</filename>.
    </para>
    <informaltable frame="all">
     <tgroup cols="6">
      <colspec colnum="1" colname="c1"/>
      <colspec colnum="2" colname="c2"/>
      <colspec colnum="3" colname="c3"/>
      <colspec colnum="4" colname="c4"/>
      <colspec colnum="5" colname="c5"/>
      <colspec colnum="6" colname="c6"/>
      <thead>
       <row rowsep="1">
        <entry><emphasis>Feature</emphasis>
        </entry>
        <entry><emphasis>Ext 3</emphasis>
        </entry>
        <entry><emphasis>Reiserfs 3.6</emphasis>
        </entry>
        <entry><emphasis>XFS</emphasis>
        </entry>
        <entry><emphasis>Btrfs *</emphasis>
        </entry>
        <entry><emphasis>OCFS 2 **</emphasis>
        </entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>
         <para>
          Data/Metadata Journaling
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          ○/•
         </para>
        </entry>
        <entry>
         <para>
          ○/•
         </para>
        </entry>
        <entry>
         <para>
          n/a *
         </para>
        </entry>
        <entry>
         <para>
          ○/•
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Journal internal/external
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          n/a *
         </para>
        </entry>
        <entry>
         <para>
          •/○
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Offline extend/shrink
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          ○/○
         </para>
        </entry>
        <entry>
<!-- file systems (btrfs) bnc#807470 -->
         <para>
          ○/○
         </para>
        </entry>
        <entry>
         <para>
          •/○
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Online extend/shrink
         </para>
        </entry>
        <entry>
         <para>
          •/○
         </para>
        </entry>
        <entry>
         <para>
          •/○
         </para>
        </entry>
        <entry>
         <para>
          •/○
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          •/○
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Sparse Files
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Tail Packing
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Defrag
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Extended Attributes/ Access Control Lists
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
        <entry>
         <para>
          •/•
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Quotas
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          ^
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Dump/Restore
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
        <entry>
         <para>
          •
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
        <entry>
         <para>
          ○
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          Blocksize default
         </para>
        </entry>
        <entry>
         <para>
          4 KiB
         </para>
        </entry>
        <entry>
         <para>
          4 KiB
         </para>
        </entry>
        <entry>
         <para>
          4 KiB
         </para>
        </entry>
        <entry>
<!-- bnc#807235 -->
         <para>
          4/64 KiB
         </para>
        </entry>
        <entry>
         <para>
          4 KiB
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          max. File System Size
         </para>
        </entry>
        <entry>
         <para>
          16 TiB
         </para>
        </entry>
        <entry>
         <para>
          16 TiB
         </para>
        </entry>
        <entry>
         <para>
          8 EiB
         </para>
        </entry>
        <entry>
         <para>
          16 EiB
         </para>
        </entry>
        <entry>
         <para>
          16 TiB
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          max. Filesize
         </para>
        </entry>
        <entry>
         <para>
          2 TiB
         </para>
        </entry>
        <entry>
         <para>
          1 EiB
         </para>
        </entry>
        <entry>
         <para>
          8 EiB
         </para>
        </entry>
        <entry>
         <para>
          16 EiB
         </para>
        </entry>
        <entry>
         <para>
          1 EiB
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>

         </para>
        </entry>
        <entry namest="c2" nameend="c6">
         <para>
          * Btrfs is supported in SUSE Linux Enterprise Server 11 Service
          Pack3; Btrfs is a copy-on-write logging-style file system. Rather
          than journaling changes before writing them in-place, it writes
          them to a new location, then links it in. Until the last write,
          the new changes are not "committed". Due to the nature of the
          filesystem, quotas will be implemented based on subvolumes in a
          future release. The blocksize default varies with different host
          architectures. 64KiB is used on ppc64 and IA64, 4KiB on most other
          systems. The actual size used can be checked with the command
          "getconf PAGE_SIZE".
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>

         </para>
        </entry>
        <entry namest="c2" nameend="c6">
         <para>
          ** OCFS2 is fully supported as part of the SUSE Linux Enterprise
          High Availability Extension.
         </para>
        </entry>
       </row>
      </tbody>
     </tgroup>
    </informaltable>
    <para>
     The maximum file size above can be larger than the file system's actual
     size due to usage of sparse blocks. Note that unless a file system
     comes with large file support (LFS), the maximum file size on a 32-bit
     system is 2 GB (2^31 bytes). Currently all of our standard file systems
     (including ext3 and ReiserFS) have LFS, which gives a maximum file size
     of 2^63 bytes in theory. The numbers in the above tables assume that
     the file systems are using 4 KiB block size. When using different block
     sizes, the results are different, but 4 KiB reflects the most common
     standard.
    </para>
    <para>
     In this document: 1024 Bytes = 1 KiB; 1024 KiB = 1 MiB; 1024 MiB = 1
     GiB; 1024 GiB = 1 TiB; 1024 TiB = 1 PiB; 1024 PiB = 1 EiB. See also
     <ulink url="http://physics.nist.gov/cuu/Units/binary.html"/>.
    </para>
   </section>
   <section>
    <title>Supported Btrfs Features</title>
    <para>
     The following table lists supported and unsupported Btrfs features
     across multiple SLES versions.
    </para>
    <para>
     <simplelist>
      <member><emphasis role="bold">+</emphasis> supported</member>
      <member><emphasis role="bold">–</emphasis> unsupported</member>
     </simplelist>
    </para>
<!-- Table according to bsc#979501, this attachment:
  https://bugzilla.suse.com/attachment.cgi?id=687340 -->
    <informaltable>
     <tgroup cols="5">
      <colspec colnum="1" colname="feature" colwidth="32*"/>
      <colspec colnum="2" colname="11SP4" colwidth="17*"/>
      <colspec colnum="3" colname="12GA" colwidth="17*"/>
      <colspec colnum="4" colname="12SP1" colwidth="17*"/>
      <colspec colnum="5" colname="12SP2" colwidth="17*"/>
      <thead>
       <row>
<!-- Remove unsupported OS's. -->
        <entry>Feature</entry>
        <entry>SLES 11 SP4</entry>
        <entry>SLES 12 GA</entry>
        <entry>SLES 12 SP1</entry>
        <entry>SLES 12 SP2</entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>Copy on Write</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Snapshots/Subvolumes</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Metadata Integrity</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Data Integrity</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Online Metadata Scrubbing</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Automatic Defragmentation</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
       </row>
       <row>
        <entry>Manual Defragmentation</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>In-band Deduplication</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
       </row>
       <row>
        <entry>Out-of-band Deduplication</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Quota Groups</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Metadata Duplication</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Multiple Devices</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>RAID 0</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>RAID 1</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>RAID 10</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>RAID 5</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
       </row>
       <row>
        <entry>RAID 6</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
       </row>
       <row>
        <entry>Hot Add/Remove</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Device Replace</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
       </row>
       <row>
        <entry>Seeding Devices</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
       </row>
       <row>
        <entry>Compression</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Big Metadata Blocks</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Skinny Metadata</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Send Without File Data</entry>
        <entry>–</entry>
        <entry>+</entry>
        <entry>+</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Send/Receive</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>+</entry>
       </row>
       <row>
        <entry>Inode Cache</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
       </row>
       <row>
        <entry>Fallocate with Hole Punch</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>–</entry>
        <entry>+</entry>
       </row>
      </tbody>
     </tgroup>
    </informaltable>
   </section>
   <section>
    <title>Additional Information</title>
    <para>
<!-- bnc#608543 and bnc#574572 -->
     NFSv4 with IPv6 is only supported for the client side. A NFSv4 server
     with IPv6 is not supported.
    </para>
    <para>
<!-- bnc#606288 -->
     This version of Samba delivers integration with Windows 7 Active
     Directory Domains. In addition we provide the clustered version of
     Samba as part of SUSE Linux Enterprise High Availability 11 SP3.
    </para>
   </section>
  </section>
  <section id="TechInfo.KernelModules">
   <title>Kernel Modules</title>
   <para>
    An important requirement for every Enterprise operating system is the
    level of support a customer receives for his environment. Kernel modules
    are the most relevant connector between hardware ("controllers") and the
    operating system. Every kernel module in SUSE Linux Enterprise Server 11
    has a flag 'supported' with three possible values: <literal>"yes",
    "external", ""</literal> (empty, not set, "unsupported").
   </para>
   <para>
    The following rules apply:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      All modules of a self-recompiled kernel are by default marked as
      unsupported.
     </para>
    </listitem>
    <listitem>
     <para>
      Kernel Modules supported by SUSE partners and delivered using SUSE's
      Partner Linux Driver process are marked "external".
     </para>
    </listitem>
    <listitem>
     <para>
      If the <literal>"supported"</literal> flag is not set, loading this
      module will taint the kernel. Tainted kernels are not supported. To
      avoid this, not supported Kernel modules are included in an extra RPM
      (kernel-&lt;flavor&gt;-extra) and will not be loaded by default
      ("flavor"=default|smp|xen|...). In addition, these unsupported modules
      are not available in the installer, and the package
      kernel-$flavor-extra is not on the SUSE Linux Enterprise Server media.
     </para>
    </listitem>
    <listitem>
     <para>
      Kernel Modules not provided under a license compatible to the license
      of the Linux kernel will also taint the kernel; see
      <filename>/usr/src/linux/Documentation/sysctl/kernel.txt</filename>
      and the state of <filename>/proc/sys/kernel/tainted</filename>.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Technical Background
   </para>
   <remark>emap: section mark-up?</remark>
   <remark>ke: Probably yes, but thus far, nobody complained.</remark>
   <itemizedlist>
    <listitem>
     <para>
      Linux Kernel
     </para>
     <para>
      The value of /proc/sys/kernel/unsupported defaults to 2 on SUSE Linux
      Enterprise Server 11 ("do not warn in syslog when loading unsupported
      modules"). This is the default used in the installer as well as in the
      installed system. See
      <filename>/usr/src/linux/Documentation/sysctl/kernel.txt</filename>
      for more information.
     </para>
    </listitem>
    <listitem>
     <para>
      modprobe
     </para>
     <para>
      The <command>modprobe</command> utility for checking module
      dependencies and loading modules appropriately checks for the value of
      the "supported" flag. If the value is <literal>"yes"</literal> or
      <literal>"external"</literal> the module will be loaded, otherwise it
      will not. See below, for information on how to override this behavior.
     </para>
<!-- https://bugzilla.novell.com/show_bug.cgi?id=448734#c37
        bnc#466005 -->
     <para>
      Note: SUSE does not generally support removing of storage modules via
      <command>modprobe -r</command>.
     </para>
     <remark>emap: proper 'Note' mark-up?</remark>
     <remark>ke: good enough as-is.</remark>
    </listitem>
   </itemizedlist>
   <para>
    Working with Unsupported Modules
   </para>
   <remark>emap: section mark-up?</remark>
   <remark>ke: probably yes.  Or variablelist.</remark>
   <para>
    While the general supportability is important, there might occur
    situations where loading an unsupported module is required (e.g., for
    testing or debugging purposes, or if your hardware vendor provides a
    hotfix):
   </para>
   <itemizedlist>
    <listitem>
     <para>
      You can override the default by changing the variable
      <option>allow_unsupported_modules</option> in
      <filename>/etc/modprobe.d/unsupported-modules</filename> and set the
      value to "<literal>1</literal>".
     </para>
     <para>
      If you only want to try loading a module once, the
      <option>--allow-unsupported-modules</option> command-line switch can
      be used with <filename>modprobe</filename>. (For more information, see
      <command>man modprobe</command>).
     </para>
    </listitem>
    <listitem>
     <para>
      During installation, unsupported modules may be added through driver
      update disks, and they will be loaded.
     </para>
     <para>
      To enforce loading of unsupported modules during boot and afterwards,
      please use the kernel command line option
      <option>oem-modules</option>.
     </para>
<!-- bnc#875427 -->
     <para>
      While installing and initializing the
      <systemitem class="resource">module-init-tools</systemitem> package,
      the kernel flag <option>"TAINT_NO_SUPPORT"</option>
      (<filename>/proc/sys/kernel/tainted</filename>) will be evaluated. If
      the kernel is already tainted,
      <option>allow_unsupported_modules</option> will be enabled. This will
      prevent unsupported modules from failing in the system being
      installed. (If no unsupported modules are present during installation
      and the other special kernel command line option (oem-modules=1) is
      not used, the default will still be to disallow unsupported modules.)
     </para>
    </listitem>
    <listitem>
     <para>
      If you install unsupported modules after the initial installation and
      want to enable those modules to be loaded during system boot, please
      do not forget to run <command>depmod</command> and
      <command>mkinitrd</command>.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Remember that loading and running unsupported modules will make the
    kernel and the whole system unsupported by SUSE.
   </para>
  </section>
  <section id="TechInfo.IPv6" remap="TechInfo:IPv6">
   <title>IPv6 Implementation and Compliance</title>
   <para>
    SUSE Linux Enterprise Server 11 is compliant to IPv6 Logo Phase 2.
    However, when running the respective tests, you may see some tests
    failing. For various reasons, we cannot enable all the configuration
    options by default, which are necessary to pass all the tests. For
    details, see below.
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Section 3: RFC 4862 - IPv6 Stateless Address Autoconfiguration
     </para>
     <para>
      Some tests fail because of the default DAD handling in Linux;
      disabling the complete interface is possible, but not the default
      behavior (because security-wise, this might open a DoS attack vector,
      a malicious node on a network could shutdown the complete segment)
      this is still conforming to RFC 4862: the shutdown of the interface is
      a "should", not a mandatory ("must") rule.
     </para>
     <para>
      The Linux kernel allows you to change the default behavior with a
      sysctl parameter. To do this on SUSE Linux Enterprise Server 11, you
      need to make the following changes in configuration:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Add ipv6 to the modules load early on boot
       </para>
       <para>
        Edit <filename>/etc/sysconfig/kernel</filename> and add ipv6 to
        MODULES_LOADED_ON_BOOT e.g.
        <option>MODULES_LOADED_ON_BOOT="ipv6"</option>. This is needed for
        the second change to work, if ipv6 is not loaded early enough,
        setting the sysctl fails.
       </para>
      </listitem>
      <listitem>
       <para>
        Add the following lines to <filename>/etc/sysctl.conf</filename>
       </para>
<screen>## shutdown IPV6 on MAC based duplicate address detection
net.ipv6.conf.default.accept_dad = 2
net.ipv6.conf.all.accept_dad = 2
net.ipv6.conf.eth0.accept_dad = 2
net.ipv6.conf.eth1.accept_dad = 2
      </screen>
       <para>
        Note: if you use other interfaces (e.g., eth2), modify the lines.
        With these changes, all tests for RFC 4862 should pass.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
    <listitem>
     <para>
      Section 4: RFC 1981 - Path MTU Discovery for IPv6
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Test v6LC.4.1.10: Multicast Destination - One Router
       </para>
      </listitem>
      <listitem>
       <para>
        Test v6LC.4.1.11: Multicast Destination - Two Routers
       </para>
      </listitem>
     </itemizedlist>
     <para>
      On these two tests ping6 needs to be told to allow defragmentation of
      multicast packets. Newer ping6 versions have this disabled by default.
      Use: <command>ping6 -M want &lt;other parameters&gt;</command>. See
      <command>man ping6</command> for more information.
     </para>
    </listitem>
<!-- bnc#484093 -->
    <listitem>
     <para>
      Enable IPv6 in YaST for SCTP Support
     </para>
     <para>
      SCTP is dependent on IPv6, so in order to successfully insert the SCTP
      module, IPv6 must be enabled in YaST. This allows for the IPv6 module
      to be automatically inserted when <command>modprobe sctp</command> is
      called.
     </para>
    </listitem>
   </itemizedlist>
<!--v Items below imported from FATE-->
   <section role="notoc" id="fate-314804" remap="TechInfo:IPv6">
<!-- sort_key="None"; non-rn-fate-cats="Open-iSCSI,YaST"; -->
<!-- href="https://fate.novell.com/314804" -->
    <title>YaST: IPv6 open-iscsi support</title>
    <para>
     YaST has been extended to support installation using IPv6 iSCSI target
     as root device.
    </para>
   </section>
<!--^ End of Items imported from FATE-->
  </section>
  <section id="TechInfo.Other">
   <title>Other Technical Information</title>
<!-- This section includes technical information -->
<!-- bnc#598405 -->
<!-- bnc#740474 -->
<!-- updated by ihno for SP2 -->
<!-- updated via mcowly for SP3 -->
<!-- SP4: now via fate#317597 -->
   <section>
<!-- bnc#728611 -->
    <title>YaST Support for Layer 2 Devices</title>
    <para>
     YaST writes the MAC address for layer 2 devices only if they are of the
     card_types:
    </para>
    <orderedlist>
     <listitem>
      <para>
       OSD_100
      </para>
     </listitem>
     <listitem>
      <para>
       OSD_1000
      </para>
     </listitem>
     <listitem>
      <para>
       OSD_10GIG
      </para>
     </listitem>
     <listitem>
      <para>
       OSD_FE_LANE
      </para>
     </listitem>
     <listitem>
      <para>
       OSD_GbE_LANE
      </para>
     </listitem>
     <listitem>
      <para>
       OSD_Express
      </para>
     </listitem>
    </orderedlist>
    <para>
     Per intent YaST does not write the MAC address for devices of the
     types:
    </para>
    <orderedlist>
     <listitem>
      <para>
       HiperSockets
      </para>
     </listitem>
     <listitem>
      <para>
       GuestLAN/VSWITCH QDIO
      </para>
     </listitem>
     <listitem>
      <para>
       OSM
      </para>
     </listitem>
     <listitem>
      <para>
       OSX
      </para>
     </listitem>
    </orderedlist>
   </section>
   <section>
<!-- bnc#440153 -->
    <title>Changes to Network Setup</title>
    <para>
     The script <command>modify_resolvconf</command> is removed in favor of
     a more versatile script called <command>netconfig</command>. This new
     script handles specific network settings from multiple sources more
     flexibly and transparently. See the documentation and man-page of
     netconfig for more information.
    </para>
   </section>
<!-- requested by Jiri Slaby jslaby@novell.com -->
   <section>
    <title>Memory cgroups</title>
    <para>
     Memory cgroups are now disabled for machines where they cause memory
     exhaustion and crashes. Namely, X86 32-bit systems with PAE support and
     more than 8G in any memory node have this feature disabled.
    </para>
   </section>
<!-- requested by Thomas Renninger trenn@novell.com -->
   <section>
    <title>MCELog</title>
    <para>
     The mcelog package logs and parses/translates Machine Check Exceptions
     (MCE) on hardware errors (also including memory errors). Formerly this
     has been done by a cron job executed hourly. Now hardware errors are
     immediately processed by an mcelog daemon.
    </para>
    <para>
     However, the mcelog service is not enabled by default resulting in
     memory and CPU errors also not being logged by default. In addition,
     mcelog has a new feature to also handle predictive bad page offlining
     and automatic core offlining when cache errors happen.
    </para>
    <para>
     The service can either be enabled via the YaST runlevel editor or via
     command line with:
    </para>
<screen>chkconfig mcelog on
rcmcelog start</screen>
   </section>
<!-- relnotes.t.i18n -->
   <section>
    <title>Locale Settings in <filename>~/.i18n</filename></title>
    <para>
     If you are not satisfied with locale system defaults, change the
     settings in <filename>~/.i18n</filename>. Entries in
     <filename>~/.i18n</filename> override system defaults from
     <filename>/etc/sysconfig/language</filename>. Use the same variable
     names but without the <literal>RC_</literal> namespace prefixes; for
     example, use <literal>LANG</literal> instead of
     <literal>RC_LANG</literal>. For more information about locales in
     general, see "Language and Country-Specific Settings" in the
     Administration Guide.
<!-- on sle, it is called admin guide -->
    </para>
   </section>
<!-- relnotes.g.kdump -->
   <section>
    <title>Configuration of kdump</title>
    <para>
     kdump is useful, if the kernel is crashing or otherwise misbehaving and
     a kernel core dump needs to be captured for analysis.
    </para>
    <para>
     Use YaST (<menuchoice><guimenu>System</guimenu><guimenu>Kernel
     Kdump</guimenu></menuchoice>) to configure your environment.
    </para>
   </section>
<!-- bnc#706059 -->
<!-- bnc#818576 -->
   <section>
    <title>Configuring Authentication for kdump through YaST with ssh/scp as Target</title>
    <para>
     When kdump is configured through YaST with ssh/scp as target and the
     target system is SUSE Linux Enterprise, then enable authentication
     using either of the following ways:
    </para>
    <orderedlist>
     <listitem>
      <para>
       Copy the public keys to the target system:
      </para>
<screen>ssh-copy-id -i ~/.ssh/id_*.pub  &lt;username&gt;@&lt;target system IP&gt;</screen>
      <para>
       or
      </para>
     </listitem>
     <listitem>
      <para>
       Change the <literal>PasswordAuthentication</literal> setting in
       <filename>/etc/ssh/sshd_config</filename> of the target system from:
      </para>
<screen>PasswordAuthentication no</screen>
      <para>
       to:
      </para>
<screen>PasswordAuthentication yes</screen>
     </listitem>
     <listitem>
      <para>
       After changing <literal>PasswordAuthentication</literal> in
       <filename>/etc/ssh/sshd_config</filename> restart the sshd service on
       the target system with:
      </para>
<screen>rcsshd restart</screen>
     </listitem>
    </orderedlist>
   </section>
<!-- relnotes.t.jpackage -->
   <section>
    <title>JPackage Standard for Java Packages</title>
    <para>
     Java packages are changed to follow the JPackage Standard.
     For more information, see the documentation in
     <filename>/usr/share/doc/packages/jpackage-utils/</filename>.
    </para>
   </section>
<!-- bnc#622203 -->
   <section>
    <title>Stopping Cron Status Messages</title>
    <para>
     To avoid the mail-flood caused by cron status messages, the default
     value of <literal>SEND_MAIL_ON_NO_ERROR</literal> in
     <filename>/etc/sysconfig/cron</filename> is set to
     "<literal>no</literal>" for new installations. Even with this setting
     to "<literal>no</literal>", cron data output will still be send to the
     <literal>MAILTO</literal> address, as documented in the cron manpage.
    </para>
    <para>
     In the update case it is recommended to set these values according to
     your needs.
    </para>
   </section>
  </section>
 </chapter>
 <chapter id="Documentation">
  <title>Documentation and Other Information</title>
  <itemizedlist>
   <listitem>
    <para>
     Read the READMEs on the DVDs.
    </para>
   </listitem>
   <listitem>
    <para>
     Get the detailed changelog information about a particular package from
     the RPM (with filename &lt;FILENAME&gt;):
    </para>
<screen>rpm --changelog -qp &lt;FILENAME&gt;.rpm
    </screen>
   </listitem>
   <listitem>
    <para>
     Check the <filename>ChangeLog</filename> file in the top level of DVD1
     for a chronological log of all changes made to the updated packages.
    </para>
   </listitem>
   <listitem>
    <para>
     Find more information in the <filename>docu</filename> directory of
     DVD1 of the SUSE Linux Enterprise Server 11 Service Pack 4 DVDs. This
     directory includes PDF versions of the SUSE Linux Enterprise Server 11
     Installation Quick Start and Deployment Guides.
    </para>
   </listitem>
   <listitem>
    <para>
<!-- fixme: see bnc#733012 -->
     These Release Notes are identical across all architectures, and are
     available online at <ulink url="https://www.suse.com/releasenotes/"/>.
    </para>
   </listitem>
  </itemizedlist>
  <section>
   <title>Additional or Updated Documentation</title>
   <itemizedlist>
    <listitem>
     <para>
      <ulink url="https://documentation.suse.com/sles/11-SP4/"/> contains
      additional or updated documentation for SUSE Linux Enterprise Server
      11 Service Pack 4.
     </para>
    </listitem>
    <listitem>
     <para>
      Find a collection of White Papers in the SUSE Linux Enterprise Server
      Resource Library at
      <ulink url="https://www.suse.com/products/server/#resources"/>.
     </para>
    </listitem>
   </itemizedlist>
  </section>
  <section>
   <title>Product and Source Code Information</title>
   <para>
    Visit <ulink url="https://www.suse.com/products/"/> for the latest
    product news from SUSE and
    <ulink url="https://www.suse.com/download-linux/source-code.html"/> for
    additional information on the source code of SUSE Linux Enterprise
    products.
   </para>
  </section>
 </chapter>
<!-- Legal notice copied from SLED release notes, mge@novell.com, 2010-05-07 -->
<!-- Legal notice updated, to smell more like SUSE -->
 <chapter id="Legal">
  <title>Legal Notices</title>
  <para>
   SUSE makes no representations or warranties with respect to the contents
   or use of this documentation, and specifically disclaims any express or
   implied warranties of merchantability or fitness for any particular
   purpose. Further, SUSE reserves the right to revise this publication and
   to make changes to its content, at any time, without the obligation to
   notify any person or entity of such revisions or changes.
  </para>
  <para>
   Further, SUSE makes no representations or warranties with respect to any
   software, and specifically disclaims any express or implied warranties of
   merchantability or fitness for any particular purpose. Further, SUSE
   reserves the right to make changes to any and all parts of SUSE software,
   at any time, without any obligation to notify any person or entity of
   such changes.
  </para>
  <para>
   Any products or technical information provided under this Agreement may
   be subject to U.S. export controls and the trade laws of other countries.
   You agree to comply with all export control regulations and to obtain any
   required licenses or classifications to export, re-export, or import
   deliverables. You agree not to export or re-export to entities on the
   current U.S. export exclusion lists or to any embargoed or terrorist
   countries as specified in U.S. export laws. You agree to not use
   deliverables for prohibited nuclear, missile, or chemical/biological
   weaponry end uses. Please refer to
   <ulink url="https://www.suse.com/company/legal/"/> for more information on
   exporting SUSE software. SUSE assumes no responsibility for your failure
   to obtain any necessary export approvals.
  </para>
  <para>
   Copyright © 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2018, 2020 SUSE LLC. All
   rights reserved. No part of this publication may be reproduced,
   photocopied, stored on a retrieval system, or transmitted without the
   express written consent of the publisher.
  </para>
  <para>
   SUSE has intellectual property rights relating to technology embodied in
   the product that is described in this document. In particular, and
   without limitation, these intellectual property rights may include one or
   more of the U.S. patents listed at
   <ulink url="https://www.suse.com/company/legal/"/> and one or more
   additional patents or pending patent applications in the U.S. and other
   countries.
  </para>
  <para>
   For SUSE trademarks, see the Trademark and Service Mark List
   (<ulink url="https://www.suse.com/company/legal/"/>). All third-party
   trademarks are the property of their respective owners.
  </para>
 </chapter>
</book>
